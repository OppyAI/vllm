{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f810bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 08-13 10:14:28 [__init__.py:244] Automatically detected platform cuda.\n",
      "INFO 08-13 10:14:32 [config.py:840] This model supports multiple tasks: {'reward', 'generate', 'embed', 'score', 'classify'}. Defaulting to 'generate'.\n",
      "INFO 08-13 10:14:32 [config.py:1454] Using max model len 1024\n",
      "WARNING 08-13 10:14:32 [arg_utils.py:1724] --enable-prompt-embeds is not supported by the V1 Engine. Falling back to V0. \n",
      "WARNING 08-13 10:14:33 [cuda.py:102] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used\n",
      "INFO 08-13 10:14:33 [llm_engine.py:230] Initializing a V0 LLM engine (v0.1.dev7407+gae88822.d20250716) with config: model='/project/phan/kt477/OppyAI_backend/qwen7b_enc_dec_clean_no_att_on_client_dec', speculative_config=None, tokenizer='Qwen/Qwen2.5-Coder-7B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=1024, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=/project/phan/kt477/OppyAI_backend/qwen7b_enc_dec_clean_no_att_on_client_dec, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=False, pooler_config=None, compilation_config={\"level\":0,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[],\"splitting_ops\":[],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":0,\"cudagraph_capture_sizes\":[],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"max_capture_size\":0,\"local_cache_dir\":null}, use_cached_outputs=False, \n",
      "INFO 08-13 10:14:34 [cuda.py:347] Using Flash Attention backend.\n",
      "INFO 08-13 10:14:35 [parallel_state.py:1076] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
      "INFO 08-13 10:14:35 [model_runner.py:1172] Starting to load model /project/phan/kt477/OppyAI_backend/qwen7b_enc_dec_clean_no_att_on_client_dec...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36d93a6733e14f6095a38cfefc3c9844",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 08-13 10:14:36 [default_loader.py:272] Loading weights took 0.81 seconds\n",
      "INFO 08-13 10:14:37 [model_runner.py:1204] Model loading took 2.4751 GiB and 0.874681 seconds\n",
      "Layer: DummyDecoderLayer()\n",
      "Error in RMSNorm: too many values to unpack (expected 2). Skipping RMSNorm.\n",
      "INFO 08-13 10:14:38 [worker.py:304] Memory profiling takes 0.36 seconds\n",
      "INFO 08-13 10:14:38 [worker.py:304] the current vLLM instance can use total_gpu_memory (79.32GiB) x gpu_memory_utilization (0.20) = 15.86GiB\n",
      "INFO 08-13 10:14:38 [worker.py:304] model weights take 2.48GiB; non_torch_memory takes 0.09GiB; PyTorch activation peak memory takes 1.40GiB; the rest of the memory reserved for KV Cache is 11.89GiB.\n",
      "INFO 08-13 10:14:38 [executor_base.py:113] # cuda blocks: 13920, # CPU blocks: 4681\n",
      "INFO 08-13 10:14:38 [executor_base.py:118] Maximum concurrency for 1024 tokens per request: 217.50x\n",
      "INFO 08-13 10:14:40 [llm_engine.py:428] init engine (profile, create kv cache, warmup model) took 2.57 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, PreTrainedTokenizer, PretrainedConfig, AutoConfig, AutoModel\n",
    "from transformers.modeling_utils import PreTrainedModel\n",
    "from typing import Callable, List, Optional, Tuple, Union, Dict\n",
    "from torch import nn\n",
    "from transformers.modeling_outputs import BaseModelOutputWithPast, CausalLMOutputWithPast\n",
    "from transformers.cache_utils import Cache\n",
    "from vllm import LLM\n",
    "from vllm import SamplingParams\n",
    "\n",
    "\n",
    "def register():\n",
    "    from vllm import ModelRegistry\n",
    "    from decoder import XCodeDecForCausalLM, XCodeDecConfig  # Import decoder classes\n",
    "\n",
    "    AutoConfig.register(\"xcodedec\", XCodeDecConfig)  # Register decoder config\n",
    "    ModelRegistry.register_model(\"XCodeDecModelForCausalLM\", XCodeDecForCausalLM)  # Register decoder model\n",
    "    from middle_model import XCodeForCausalLM, XCodeMiddleConfig  # Changed to absolute import\n",
    "\n",
    "    AutoConfig.register(\"xcodemiddle\", XCodeMiddleConfig)\n",
    "    ModelRegistry.register_model(\"XCodeMiddleModelForCausalLM\", XCodeForCausalLM)\n",
    "\n",
    "    from encoder import XCodeEncForCausalLM, XCodeEncConfig  # Import encoder classes\n",
    "\n",
    "    AutoConfig.register(\"xcodeenc\", XCodeEncConfig)  # Register encoder config\n",
    "    ModelRegistry.register_model(\"XCodeEncModelForCausalLM\", XCodeEncForCausalLM)  # Register encoder model\n",
    "\n",
    "    from enc_dec import XCodeEncDecConfig, XCodeEncDecForCausalLM  # Import encoder classes\n",
    "\n",
    "    AutoConfig.register(\"xcodeencdec\", XCodeEncDecConfig)  # Register encoder config\n",
    "    ModelRegistry.register_model(\"XCodeEncDecModelForCausalLM\", XCodeEncDecForCausalLM)  # Register encoder model\n",
    "\n",
    "register()\n",
    "\n",
    "# enc_model = LLM(\n",
    "#     model=\"/project/phan/kt477/OppyAI_backend/qwen7b_enc_clean_no_att_on_client\",\n",
    "#     # model=\"Qwen/Qwen2.5-Coder-32B-Instruct\",\n",
    "#     tokenizer=\"Qwen/Qwen2.5-Coder-7B-Instruct\",\n",
    "#     # skip_tokenizer_init=True,\n",
    "#     # task=\"reward\",\n",
    "#     enable_prompt_embeds=True,\n",
    "#     model_part=\"encoder\",  # Set to False for encoder\n",
    "#     gpu_memory_utilization=0.1,\n",
    "#     max_model_len=1024,\n",
    "#     tensor_parallel_size=1,\n",
    "#     # enforce_eager=True,  # Disable CUDA graphs for debugging\n",
    "# )\n",
    "\n",
    "\n",
    "# middle_model = LLM(\n",
    "#     model=\"/project/phan/kt477/OppyAI_backend/qwen7b_middle_clean_no_att_on_client\",\n",
    "#     # model=\"Qwen/Qwen2.5-Coder-32B-Instruct\",\n",
    "#     tokenizer=\"Qwen/Qwen2.5-Coder-7B-Instruct\",\n",
    "#     skip_tokenizer_init=True,\n",
    "#     # task=\"reward\",\n",
    "#     enable_prompt_embeds=True,\n",
    "#     model_part=\"middle\",  # Set to False for encoder\n",
    "#     gpu_memory_utilization=0.2,\n",
    "#     max_model_len=1024,\n",
    "#     tensor_parallel_size=1,\n",
    "#     # enforce_eager=True\n",
    "# )\n",
    "\n",
    "enc_dec_model = LLM(\n",
    "    model=\"/project/phan/kt477/OppyAI_backend/qwen7b_enc_dec_clean_no_att_on_client_dec\",\n",
    "    # model=\"Qwen/Qwen2.5-Coder-32B-Instruct\",\n",
    "    tokenizer=\"Qwen/Qwen2.5-Coder-7B-Instruct\",\n",
    "    # skip_tokenizer_init=True,\n",
    "    # task=\"reward\",\n",
    "    enable_prompt_embeds=True,\n",
    "    # model_part=\"encoder\",  # Set to False for encoder\n",
    "    gpu_memory_utilization=0.2,\n",
    "    max_model_len=1024,\n",
    "    tensor_parallel_size=1,\n",
    "    enforce_eager=True\n",
    ")\n",
    "\n",
    "# dec_model = LLM(\n",
    "#     model=\"/project/phan/kt477/OppyAI_backend/qwen7b_dec_clean_no_att_on_client\",\n",
    "#     # model=\"Qwen/Qwen2.5-Coder-32B-Instruct\",\n",
    "#     tokenizer=\"Qwen/Qwen2.5-Coder-7B-Instruct\",\n",
    "#     # skip_tokenizer_init=True,\n",
    "#     # task=\"reward\",    \n",
    "#     enable_prompt_embeds=True,\n",
    "#     model_part=\"decoder\",  # Set to False for encoder\n",
    "#     gpu_memory_utilization=0.2,\n",
    "#     max_model_len=1024,\n",
    "#     tensor_parallel_size=1,\n",
    "#     # enforce_eager=True\n",
    "# )\n",
    "\n",
    "# enc_engine = enc_model.llm_engine\n",
    "# dec_engine = dec_model.llm_engine\n",
    "# middle_engine = middle_model.llm_engine\n",
    "enc_dec_engine = enc_dec_model.llm_engine\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-Coder-7B-Instruct\", trust_remote_code=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "request_id = 0\n",
    "# prompt_embeds  = torch.load(\"test_py_files/prompt_embeds.pt\").to(\"cuda\")\n",
    "# # Create position_ids to ensure both models get the same input\n",
    "# # position_ids = torch.arange(0, prompt_embeds.shape[1], device=\"cuda:1\").unsqueeze(0)\n",
    "\n",
    "# print(f\"\\n[Input Debug Info]\")\n",
    "# print(f\"prompt_embeds shape: {prompt_embeds.shape}\")\n",
    "# print(f\"position_ids shape: {position_ids.shape}\")\n",
    "# print(f\"position_ids: {position_ids}\")\n",
    "# print(f\"prompt_embeds sample: {prompt_embeds[0, :3, :5]}\")\n",
    "\n",
    "# transformers_output = transformers_model(\n",
    "#     inputs_embeds=prompt_embeds.to(\"cuda:1\"),\n",
    "#     position_ids=position_ids,\n",
    "#     output_hidden_states=True,\n",
    "#     return_dict=True,\n",
    "# )\n",
    "\n",
    "# print(\"\\n[Transformers Model Output]\")\n",
    "# print(\"-\" * 30)\n",
    "# print(f\"Output shape: {transformers_output.last_hidden_state.shape}\")\n",
    "# print(f\"First few values: {transformers_output.last_hidden_state[0, :3, :5]}\")\n",
    "# print(transformers_output)\n",
    "# outputs = model.generate(\n",
    "#     {\n",
    "#         \"prompt_embeds\": prompt_embeds.to(\"cuda:0\"),\n",
    "#     },\n",
    "# )\n",
    "\n",
    "# import time\n",
    "# start_time = time.time()\n",
    "# print(\"Adding request to encoder engine...\")\n",
    "# i = 0 \n",
    "\n",
    "prompt = \"write a quick sort algorithm.\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(\"cuda:0\")\n",
    "# # input ids to list of integers\n",
    "input_ids = model_inputs.input_ids[0].tolist()\n",
    "tokens = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfa7adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "def send_intermediate_states(_, __, output, prefix = \"client\"):\n",
    "    hidden_states, residual = output\n",
    "    # Right now, save the hidden states and residual to file\n",
    "    if os.path.exists(\"test_py_files\") is False:\n",
    "        os.makedirs(\"test_py_files\")\n",
    "\n",
    "    torch.save(hidden_states, f\"test_py_files/{prefix}_hidden_states_tensor.pt\")\n",
    "    torch.save(residual, f\"test_py_files/{prefix}_residual_tensor.pt\")\n",
    "\n",
    "\n",
    "    # serialized_hidden_states = pickle.dumps(hidden_states.to(\"cpu\"))\n",
    "    # serialized_residual = pickle.dumps(residual.to(\"cpu\"))\n",
    "    # node.isend(serialized_hidden_states, tag=0, latency=None).wait()\n",
    "    # node.isend(serialized_residual, tag=0, latency=None).wait()\n",
    "    # logger.debug(f\"Sent hidden_states: {hidden_states.shape} ({len(serialized_hidden_states)} bytes sent) and residual: {residual.shape} ({len(serialized_residual)} bytes sent)\")\n",
    "\n",
    "\n",
    "def recv_intermediate_states(_, input, prefix = \"client\"):\n",
    "    positions, _, _ = input\n",
    "    device = positions.device\n",
    "\n",
    "    # Load the hidden states and residual from file\n",
    "    if os.path.exists(\"test_py_files\") is False:\n",
    "        os.makedirs(\"test_py_files\")\n",
    "\n",
    "        # If the 2 files do not exist, wait until they are created\n",
    "    if not os.path.exists(f\"test_py_files/{prefix}_hidden_states_tensor.pt\") or not os.path.exists(f\"test_py_files/{prefix}_residual_tensor.pt\"):\n",
    "        while not (os.path.exists(f\"test_py_files/{prefix}_hidden_states_tensor.pt\") and os.path.exists(f\"test_py_files/{prefix}_residual_tensor.pt\")):\n",
    "            pass\n",
    "                # time.sleep(10)  # Wait for 10 seconds before checking again\n",
    "    i = 0\n",
    "    # Retry loading until successful\n",
    "    while i < 5:\n",
    "        try:\n",
    "            hidden_states = torch.load(f\"test_py_files/{prefix}_hidden_states_tensor.pt\").to(device)\n",
    "            residual = torch.load(f\"test_py_files/{prefix}_residual_tensor.pt\").to(device)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            time.sleep(1)\n",
    "            i += 1\n",
    "\n",
    "\n",
    "    \n",
    "    # Delete the files after loading\n",
    "    os.remove(f\"test_py_files/{prefix}_hidden_states_tensor.pt\")\n",
    "    os.remove(f\"test_py_files/{prefix}_residual_tensor.pt\")\n",
    "\n",
    "\n",
    "    # serialized_hidden_states = node.irecv(tag=0).wait()\n",
    "    # serialized_residual = node.irecv(tag=0).wait()\n",
    "    # hidden_states = pickle.loads(serialized_hidden_states).to(device)\n",
    "    # residual = pickle.loads(serialized_residual).to(device)\n",
    "    # logger.debug(f\"Got hidden_states: {hidden_states.shape} ({len(serialized_hidden_states)} bytes sent), residual: {residual.shape} ({len(serialized_residual)} bytes sent) and positions {positions.shape}\")\n",
    "\n",
    "    return positions, hidden_states, residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9bf8de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e8db1f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x155533e69b10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_dec_engine.model_executor.driver_worker.model_runner.model.enc.layers[-1].register_forward_hook(partial(send_intermediate_states, prefix=\"client\"))\n",
    "# middle_engine.model_executor.driver_worker.model_runner.model.middle.layers[-1].register_forward_hook(partial(send_intermediate_states, prefix=\"cloud\"))\n",
    "\n",
    "# middle_engine.model_executor.driver_worker.model_runner.model.middle.layers[0].register_forward_pre_hook(partial(recv_intermediate_states, prefix=\"client\"))\n",
    "enc_dec_engine.model_executor.driver_worker.model_runner.model.dec.layers[0].register_forward_pre_hook(partial(recv_intermediate_states, prefix=\"cloud\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a91a9db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XCodeEncDecForCausalLM(\n",
       "  (enc): XCodeEncModel(\n",
       "    (embed_tokens): VocabParallelEmbedding(num_embeddings=152064, embedding_dim=3584, org_vocab_size=152064, num_embeddings_padded=152064, tp_size=1)\n",
       "    (layers): ModuleList(\n",
       "      (0): XCodeDecoderLayer(\n",
       "        (self_attn): XCodeAttention(\n",
       "          (qkv_proj): QKVParallelLinear(in_features=3584, output_features=4608, bias=True, tp_size=1, gather_output=False)\n",
       "          (o_proj): RowParallelLinear(input_features=3584, output_features=3584, bias=False, tp_size=1, reduce_results=True)\n",
       "          (rotary_emb): RotaryEmbedding(head_size=128, rotary_dim=128, max_position_embeddings=32768, base=1000000.0, is_neox_style=True)\n",
       "          (attn): Attention(head_size=128, num_heads=28, num_kv_heads=4, scale=0.08838834764831845, backend=FlashAttentionImpl)\n",
       "        )\n",
       "        (mlp): XCodeMLP(\n",
       "          (gate_up_proj): MergedColumnParallelLinear(in_features=3584, output_features=37888, bias=False, tp_size=1, gather_output=False)\n",
       "          (down_proj): RowParallelLinear(input_features=18944, output_features=3584, bias=False, tp_size=1, reduce_results=True)\n",
       "          (act_fn): SiluAndMul()\n",
       "        )\n",
       "        (input_layernorm): RMSNorm(hidden_size=3584, eps=1e-06)\n",
       "        (post_attention_layernorm): RMSNorm(hidden_size=3584, eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): PPMissingLayer()\n",
       "  )\n",
       "  (dec): XCodeDecModel(\n",
       "    (embed_tokens): PPMissingLayer()\n",
       "    (layers): ModuleList(\n",
       "      (0): DummyDecoderLayer()\n",
       "    )\n",
       "    (norm): RMSNorm(hidden_size=3584, eps=1e-06)\n",
       "  )\n",
       "  (lm_head): ParallelLMHead(num_embeddings=152064, embedding_dim=3584, org_vocab_size=152064, num_embeddings_padded=152064, tp_size=1)\n",
       "  (logits_processor): LogitsProcessor(vocab_size=152064, org_vocab_size=152064, scale=1.0, logits_as_input=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_dec_engine.model_executor.driver_worker.model_runner.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0b588fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_dec_engine.add_request(request_id=\"123\", prompt={\n",
    "        \"prompt_token_ids\": input_ids, \n",
    "    }, params=SamplingParams(max_tokens=2048, temperature=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e32d7ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.3809, -0.1367, -0.2852,  ...,  0.3066, -0.1533,  0.1250],\n",
      "        [-0.3594, -0.1338, -0.2285,  ..., -0.1572, -0.1719,  0.1963],\n",
      "        [-0.1992, -0.0483, -0.1216,  ..., -0.0113, -0.0449,  0.1367],\n",
      "        ...,\n",
      "        [-0.2207, -0.0586, -0.0820,  ...,  0.0518, -0.1206, -0.0496],\n",
      "        [ 0.0280, -0.0991, -0.1699,  ..., -0.0068, -0.0752, -0.0703],\n",
      "        [-0.0737, -0.0249,  0.0583,  ...,  0.0388, -0.0270,  0.0806]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.5742, -0.0115,  0.2324,  ...,  0.0344, -0.3594, -0.0618],\n",
      "        [-0.1201, -0.2344, -0.0623,  ..., -0.0669, -0.0030,  0.1045],\n",
      "        [-0.1182,  0.0201, -0.1138,  ..., -0.0072, -0.1406,  0.0630],\n",
      "        ...,\n",
      "        [-0.1846,  0.1387,  0.0173,  ...,  0.0659,  0.0256,  0.0140],\n",
      "        [-0.1406,  0.0542,  0.0212,  ...,  0.0183, -0.0200, -0.0776],\n",
      "        [-0.1357,  0.0134,  0.1758,  ..., -0.0275,  0.0166, -0.0791]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([35, 3584]) and residual: torch.Size([35, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.1000e+01,  1.6094e+00,  1.1406e+00,  ...,  3.8125e+00,\n",
      "          1.4188e+01, -3.4688e+00],\n",
      "        [-1.1875e+01,  2.0469e+00,  1.7500e+00,  ...,  1.9688e+00,\n",
      "          1.4625e+01, -3.8438e+00],\n",
      "        [-1.0500e+01,  2.0000e+00,  1.3125e+00,  ...,  3.7500e+00,\n",
      "          1.4375e+01, -3.2500e+00],\n",
      "        ...,\n",
      "        [-9.2500e+00, -1.8125e+00, -1.1875e+00,  ..., -1.7266e+00,\n",
      "         -4.3125e+00, -7.3438e+00],\n",
      "        [ 7.8125e-01, -1.2656e+00, -7.8125e-03,  ..., -4.5625e+00,\n",
      "         -7.5938e+00, -1.0375e+01],\n",
      "        [ 9.8438e-01, -1.3281e-01,  6.4062e-01,  ..., -3.1562e+00,\n",
      "         -5.5000e+00, -1.0125e+01]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-4.9062, -7.0000, -3.9844,  ...,  8.5625, -4.0312, 10.8125],\n",
      "        [-5.2188, -8.6875, -5.5625,  ..., 10.9375, -4.8438, 11.3750],\n",
      "        [-5.4062, -8.0000, -4.7188,  ..., 10.0000, -4.1250, 10.7500],\n",
      "        ...,\n",
      "        [ 0.9414, -1.9375,  4.8125,  ...,  0.4766, -1.8516, -4.4688],\n",
      "        [ 2.2031,  1.0703,  0.4805,  ...,  1.6719,  1.9453,  2.4688],\n",
      "        [ 0.6523,  0.8906,  0.7188,  ...,  2.7031,  3.6719,  2.4844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='Sure', token_ids=(39814,), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100470.9987304, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.00029605500458274037, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0027, -0.0082, -0.0461,  ..., -0.0491,  0.1787,  0.0513]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0121,  0.0410, -0.0298,  ...,  0.3633, -0.3359,  0.1992]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.3750,  1.3672, -0.9336,  ..., -7.7188, -5.8438,  9.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1128,  0.9531,  0.7695,  ...,  1.2891, -1.1250, -0.0064]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='Sure!', token_ids=(39814, 0), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.0272264, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0006217659974936396, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0192, -0.0374,  0.0498,  ...,  0.0044,  0.1611, -0.0530]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0120, -0.2891, -0.0610,  ...,  0.6523,  0.1826, -0.4238]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.1250, -5.4375, -6.4062,  ..., -1.7031, -0.2949, -7.4688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.5898,  1.6641, -1.6484,  ...,  2.1875,  0.9297,  0.9531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='Sure! Quick', token_ids=(39814, 0, 17251), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.0519795, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0007214530050987378, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0291,  0.0728,  0.0144,  ..., -0.0044,  0.0299, -0.0332]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2344,  0.2383,  0.0127,  ...,  0.2158,  0.3789,  0.0071]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.2500,  -0.7734,  -5.0312,  ...,   7.0000, -17.5000,   3.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.8906, -0.3125, -1.7188,  ...,  1.7656,  0.4980, -2.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='Sure! Quick sort', token_ids=(39814, 0, 17251, 3378), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.075427, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0008100990089587867, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.3301, -0.0713,  0.0332,  ..., -0.0085, -0.2246, -0.0015]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0991,  0.0109,  0.1865,  ...,  0.1963, -0.3438, -0.1235]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-14.5000,   5.9062,  -9.1250,  ...,   3.5938,  -8.8125,   2.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.3906,  1.1953,  1.8438,  ..., -1.9766, -0.7305, -0.4531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='Sure! Quick sort is', token_ids=(39814, 0, 17251, 3378, 374), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.0987573, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0008905900031095371, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1357,  0.0566, -0.1523,  ..., -0.1436,  0.0110,  0.0205]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0908, -0.0408, -0.1445,  ..., -0.2314,  0.0510, -0.0215]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.6250,  0.7656, -3.4375,  ...,  8.6875,  7.1562,  1.5938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8320,  0.5430,  1.5625,  ..., -1.4062, -2.8438, -1.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='Sure! Quick sort is a', token_ids=(39814, 0, 17251, 3378, 374, 264), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.122058, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0009659620118327439, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0918,  0.0469,  0.0105,  ..., -0.1279,  0.0559,  0.0659]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0762,  0.3828,  0.0613,  ..., -0.0522,  0.0352, -0.2090]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 4.5312, -2.3438,  5.1250,  ..., -1.6250,  2.8281, -7.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0474,  0.8672, -1.6094,  ..., -2.1406, -1.1719,  0.4199]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='Sure! Quick sort is a popular', token_ids=(39814, 0, 17251, 3378, 374, 264, 5411), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.145442, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0010470440029166639, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0569, -0.1079, -0.0417,  ..., -0.1465,  0.0635,  0.0228]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0303,  0.1309, -0.1641,  ..., -0.1768, -0.2598, -0.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.9688, -1.1875,  4.4062,  ...,  1.3906, -0.9727, -7.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.3066,  1.6953, -0.7852,  ..., -1.0469,  1.6719,  0.1416]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='Sure! Quick sort is a popular and', token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.1688235, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0011241190077271312, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0425,  0.0289,  0.0189,  ...,  0.0046,  0.0425, -0.0072]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2676, -0.2139, -0.1885,  ...,  0.0977,  0.0295, -0.0557]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 6.1250, -2.7656,  9.2500,  ...,  2.7031,  3.0312, -7.9688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.9688,  2.0000, -2.4688,  ..., -2.5156,  1.9688, -2.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='Sure! Quick sort is a popular and efficient', token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.1924279, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0012009230122203007, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0131, -0.0173, -0.1572,  ..., -0.2637,  0.0237,  0.0312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3027, -0.0776, -0.0243,  ..., -0.0884, -0.1836, -0.1572]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.0625,  5.1250, -0.5625,  ..., -1.6250, -1.0391,  0.0596]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4141,  0.8672,  1.4062,  ..., -1.2109,  1.7266, -0.0449]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='Sure! Quick sort is a popular and efficient sorting', token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.2159555, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0012780480028595775, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0417, -0.0045, -0.1035,  ..., -0.2236, -0.1484, -0.0317]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0137, -0.0820,  0.0376,  ..., -0.0503, -0.1807, -0.1455]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.4531,  3.7188, -2.8125,  ..., -2.5625, -7.0625, -2.2969]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1318,  0.0464, -2.6719,  ..., -0.2471,  2.9531, -1.6797]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='Sure! Quick sort is a popular and efficient sorting algorithm', token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.2396612, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0013540799991460517, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0889,  0.2100,  0.0236,  ..., -0.4746, -0.0308, -0.0280]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1787, -0.0361, -0.3242,  ..., -0.2930, -0.0347,  0.0962]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.8750,  1.4844, -2.8750,  ...,  0.4727, -2.7656,  5.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0266, -0.6133,  0.0542,  ..., -2.4688, -0.2949, -1.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='Sure! Quick sort is a popular and efficient sorting algorithm that', token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.2630868, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.001432798002497293, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0217,  0.1484, -0.0442,  ..., -0.1562,  0.1201, -0.0481]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0513, -0.2578, -0.3359,  ..., -0.1416, -0.1201,  0.0576]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-12.5000,  -2.6250,   0.0625,  ...,  -2.0625,  -1.0000,  -5.0000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3984, -1.3516, -0.2773,  ..., -2.2969, -0.5586, -1.1719]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='Sure! Quick sort is a popular and efficient sorting algorithm that uses', token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.286636, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0015120370080694556, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0251,  0.1201, -0.0498,  ...,  0.1187, -0.0889, -0.0762]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2324,  0.0469,  0.2100,  ...,  0.1660, -0.7227, -0.1357]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.3125,   7.8438, -11.9375,  ...,   1.8906,   4.7812,   2.3906]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.6094,  0.9219, -0.2070,  ..., -2.1875, -0.5977, -1.5156]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='Sure! Quick sort is a popular and efficient sorting algorithm that uses a', token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.3101912, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0015883000014582649, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1221, -0.0654, -0.0058,  ..., -0.0238, -0.0464,  0.0024]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3223,  0.1816,  0.1738,  ..., -0.2676, -0.3418, -0.1553]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-5.2812, -1.3906, -0.8555,  ..., -5.4375,  0.4297, -9.5625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1338,  0.4531,  0.3574,  ..., -3.8281,  0.7227, -1.9375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide', token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.333247, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0016799720033304766, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0339,  0.1104,  0.0608,  ..., -0.0498, -0.0679, -0.0859]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0190,  0.1826,  0.2754,  ..., -0.0071, -0.0869,  0.0496]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.0781,  2.0469,  1.7422,  ..., -2.0625, -2.2344, -6.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4023, -2.9062,  0.4297,  ..., -0.5312, -3.3125,  1.4844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and', token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.356373, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0017573070072103292, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.1152, -0.0493, -0.0269,  ..., -0.0530, -0.1582, -0.0913]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0996,  0.0471,  0.0996,  ..., -0.1338,  0.0251, -0.0496]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 3.3125,  6.0625,  8.2500,  ..., -0.6406,  0.6016, -3.2812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.8516, -3.3125, -1.7188,  ...,  0.6367, -6.2500, -0.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-con', token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.3794744, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0018336810026085004, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0549,  0.0278,  0.0688,  ...,  0.1030, -0.0991, -0.2178]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1001,  0.0025, -0.0046,  ..., -0.0500,  0.0801,  0.0693]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 2.2344, -2.8125, 13.6250,  ...,  2.9844,  0.5117, -4.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[  4.7812, -10.5625,  -7.3438,  ...,   8.2500,  -7.2812,   9.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer', token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.4026031, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.001910765000502579, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0281,  0.2109,  0.1777,  ..., -0.2393,  0.1064,  0.0537]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0084, -0.0649, -0.1504,  ...,  0.0684,  0.1465, -0.0255]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.1562,  3.3125,  1.9453,  ..., -2.6875,  0.8320, -0.0254]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4863, -2.6250, -0.3398,  ..., -0.1836, -0.1660, -2.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach', token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.425549, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.001988279997021891, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0171,  0.0381,  0.0200,  ..., -0.3203, -0.1006, -0.1045]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2793, -0.0178, -0.3613,  ..., -0.2373, -0.0068, -0.2305]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.3906,  3.1094, -3.0781,  ..., -3.6875, -3.8750,  6.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1934, -0.8516,  0.4258,  ..., -0.1582, -0.1562, -0.7891]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to', token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.4486415, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.00206446299853269, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0605, -0.0508, -0.0071,  ..., -0.1572, -0.0391, -0.0879]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4355,  0.2188, -0.3281,  ..., -0.0967, -0.0654,  0.1338]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.5469, -4.4062, -7.3125,  ..., -1.3750,  0.4453, -2.2812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8750, -2.2188, -0.8594,  ...,  0.7617, -0.5078,  0.6641]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort', token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.4719253, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.002141076998668723, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.2480,  0.0586,  0.0417,  ..., -0.1514, -0.1611, -0.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1201, -0.2754,  0.1079,  ...,  0.3027, -0.2490, -0.2334]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.3438,  2.1406, -6.0938,  ..., -3.3125,  0.4023,  0.3516]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2344,  0.2676, -1.1641,  ..., -0.2275, -1.4844, -0.5898]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements', token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.4950635, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0022199049999471754, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0208,  0.0283, -0.1128,  ..., -0.1221, -0.2100,  0.0260]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0019, -0.3340,  0.0630,  ...,  0.0217, -0.0251, -0.0618]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.6719,  4.0312,  3.5469,  ...,  0.4219, -7.0938,  1.3359]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.3613, -0.6719, -0.9648,  ..., -0.2852, -0.2012,  0.9375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements.', token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.5180864, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.002296788996318355, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0266,  0.0928,  0.0143,  ..., -0.0520, -0.0308, -0.0251]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1328, -0.0737,  0.1079,  ...,  0.0564, -0.0486,  0.0104]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-12.8750,  -4.7188,  -3.1406,  ...,  -1.8594,   3.2188,   1.5625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0742,  1.1719, -1.4844,  ...,  1.6797, -1.1250, -0.7891]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here', token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.5413716, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0023726219951640815, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1504, -0.0742,  0.1875,  ...,  0.1963,  0.0049, -0.0796]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1221, -0.3594,  0.3066,  ...,  0.6914, -0.0630,  0.0020]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-5.9375, -4.4062, -3.4688,  ...,  0.6055,  0.5078,  6.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.1328, -0.0938, -0.3125,  ..., -0.5977, -0.5781, -0.2109]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.564856, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0024494859972037375, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1504, -0.1660,  0.0291,  ...,  0.1445,  0.1807,  0.1084]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0322, -0.5820,  0.3105,  ...,  0.1426, -0.1953,  0.4688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 3.2500, -1.9688, -0.6602,  ...,  7.7812, 13.3750,  4.4062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.6094, -1.1797,  0.6680,  ...,  0.2520, -1.7812,  0.1641]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.5878582, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0025277130043832585, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0703,  0.0071,  0.0198,  ..., -0.0354,  0.0918,  0.0913]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2500,  0.1865,  0.1719,  ..., -0.1235, -0.0140, -0.2236]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.6406, -1.2188,  8.9375,  ...,  3.7812, 11.2500, -7.5625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.1797, -0.4648,  1.4531,  ..., -2.2031, -0.1543, -0.9062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.6110518, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.002603544999146834, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0054,  0.1836, -0.0796,  ..., -0.2305, -0.0225, -0.0830]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2500,  0.0461, -0.1797,  ..., -0.1689, -0.3262, -0.0864]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 7.1250, -7.0312,  4.4375,  ..., -2.1719, 15.7500, -6.7500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.3711,  1.1406,  0.5586,  ..., -2.2812,  1.1797, -1.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.6342702, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0026807099930010736, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.2256,  0.1484, -0.0942,  ..., -0.2090, -0.1494, -0.0981]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0972, -0.1553,  0.3164,  ..., -0.5195,  0.1562,  0.1484]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.8750, -2.0781, -2.6875,  ..., -5.2500,  3.3750,  5.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.5820,  0.4883,  0.1885,  ..., -0.9883, -0.0605, -0.5625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.657606, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0027617220039246604, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0796,  0.0552,  0.0586,  ..., -0.1504,  0.0371, -0.0718]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.3984, -0.1128,  0.0918,  ..., -0.5859,  0.1475, -0.0282]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.7188, -3.9375,  4.3750,  ..., -2.2812, 13.6250,  0.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8320, -0.4180, -1.3047,  ..., -0.3184,  0.2207,  0.6094]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.6809168, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0028383860044414178, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0608,  0.1113, -0.0078,  ..., -0.0613,  0.0073, -0.1094]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0251,  0.0302, -0.0449,  ..., -0.1309, -0.0767, -0.0850]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[  5.1875, -12.6875,   2.7500,  ...,  -4.8438,  12.1875,  -1.3594]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.6875, -0.0791, -0.5703,  ...,  0.3262,  0.0928, -0.6016]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.703982, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0029271819948917255, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0061,  0.1426, -0.1338,  ..., -0.0840,  0.1426, -0.1367]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2695,  0.4844,  0.2363,  ...,  0.0752,  0.1904,  0.2217]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -9.6875,  -5.4375,  -3.0469,  ...,   2.0312, -12.5000,   3.4219]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0908, -0.0527,  0.5273,  ...,  2.8906, -4.0625,  1.2422]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.7270362, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.003004126003361307, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.2773, -0.0420,  0.0461,  ..., -0.0898, -0.1167,  0.0090]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0613, -0.0121,  0.1641,  ...,  0.1221, -0.2871, -0.1660]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.9375, -0.5859, -3.1562,  ...,  1.2500, -4.7812,  1.6562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0508, -2.3438, -2.9375,  ..., -1.9062,  3.4375, -0.6641]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.7500324, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.003080588998273015, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1768,  0.1299,  0.0986,  ..., -0.4180,  0.0547,  0.0386]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1162, -0.0549, -0.2246,  ..., -0.3633, -0.0918,  0.2471]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.9844, -6.4375, -2.5625,  ..., -2.0469,  2.0000,  5.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.3438,  0.4141,  0.4551,  ..., -0.6602,  0.1260,  0.2295]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.772986, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.00315742299426347, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1074, -0.0004, -0.0747,  ..., -0.1709, -0.0476, -0.0986]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2061,  0.0786,  0.0610,  ..., -0.3398, -0.0549,  0.2451]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[  0.2891,  -9.6875,   2.4062,  ..., -11.1875,   5.6250,   4.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.0234, -0.5703, -0.4453,  ..., -0.1680,  0.4395,  0.2695]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.7963095, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0032336759904865175, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.2256,  0.0708,  0.0442,  ..., -0.1416,  0.0732,  0.0674]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1719, -0.7461, -0.4551,  ..., -0.3789, -0.3008,  0.3223]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.7812, -0.2148, -1.3281,  ...,  5.1250,  2.9688,  1.7734]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.6719,  0.0737,  0.0420,  ...,  0.1914,  0.5703, -0.8281]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.8192992, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0033186259970534593, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0378,  0.0325,  0.1377,  ...,  0.1318,  0.0771, -0.0806]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0053, -0.3184,  0.1182,  ..., -0.0942,  0.0986, -0.0564]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.1250,  3.8438, -0.6016,  ...,  1.7266,  8.4375,  4.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1797, -2.4219,  0.1504,  ...,  0.2441,  1.5000, -2.4219]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.8426375, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.003404848001082428, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0527, -0.0537, -0.0332,  ...,  0.1357,  0.1357, -0.1357]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1787, -0.3320, -0.0684,  ..., -0.3105, -0.2324, -0.2812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.5312,  2.8906,  1.5859,  ..., -0.4844, 10.5625,  4.5938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.6875, -0.1396,  1.5156,  ..., -0.2988,  2.1406, -2.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.8658636, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.003481532010482624, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1387,  0.0703, -0.0664,  ...,  0.0649, -0.0942, -0.0410]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4785, -0.0016, -0.0547,  ..., -0.3652, -0.3027, -0.3652]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-13.1250,   5.4062,  -2.8594,  ...,   6.4062,   5.8438,   8.5625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1670, -1.7578,  1.2500,  ...,  0.0427, -0.5273, -3.3750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\n\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.8890007, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.00355754500196781, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0211,  0.2021,  0.0226,  ...,  0.0674,  0.0474, -0.0074]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2754, -0.1377, -0.0615,  ..., -0.3223,  0.1465, -0.1279]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-18.7500,   3.3906,  -1.9141,  ...,   8.6875,  16.1250,   5.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.7734, -2.6250,  1.4531,  ..., -1.5547,  1.7500, -2.2656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.9119768, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0036368140135891736, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1211,  0.0825, -0.0918,  ..., -0.0674, -0.0420, -0.1328]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2090, -0.1060,  0.0376,  ..., -0.3789, -0.3027, -0.7656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.6875,  2.0000, -8.1250,  ...,  6.7812,  5.3750, -2.0469]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.8984,  1.1328, -3.5781,  ..., -1.1172, -3.4219, -3.4688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.9350235, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.003712356017786078, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0364,  0.1348, -0.2246,  ..., -0.0752,  0.0830, -0.0430]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4336,  0.6328,  0.2422,  ...,  0.1455,  0.1768,  0.1094]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-15.9375,   0.0508,  -1.0703,  ...,   6.5625,  -3.6719,   1.5469]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4258,  2.5156,  2.0156,  ...,  3.1719,  3.1250, -3.9219]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.9583259, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.003788118017837405, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1206, -0.0371, -0.0654,  ..., -0.1436, -0.0354,  0.1807]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0099,  0.0781, -0.1099,  ...,  0.0518, -0.1982, -0.1387]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.0625,   7.5312,  -2.5938,  ...,   4.7812,  -0.6328,  -1.5781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.3965,  0.2910,  0.7070,  ..., -2.0469,  2.5156, -3.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.9816234, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.003869942025630735, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0515,  0.0093,  0.0014,  ...,  0.0106,  0.0194, -0.0957]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4043, -0.1426, -0.0211,  ...,  0.4160,  0.1953, -0.1021]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-14.5000,   4.5938,   3.4062,  ...,   5.7500,  -9.3125,   6.7812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.9375,  2.4062, -2.1406,  ...,  0.2617, -0.6992,  0.4102]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.0046003, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.00394636501732748, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0352, -0.0271,  0.0535,  ...,  0.0295,  0.0220, -0.0317]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0942, -0.0698,  0.0361,  ..., -0.0674,  0.3203, -0.1758]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.7500, -1.1797, -1.3047,  ..., -1.3281,  0.5547,  7.4062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.2656, -2.5156,  0.1030,  ...,  2.2344,  1.0469, -2.0781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n   \", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.0276833, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0040233900072053075, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1089,  0.0002, -0.1611,  ...,  0.1235,  0.1650, -0.0435]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1045, -0.1377,  0.1318,  ...,  0.2158,  0.2412, -0.4043]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -6.8750,  -0.9766, -11.1875,  ...,   4.2500,   0.0684,  -3.0000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.5469,  0.7344, -2.0938,  ...,  0.1445, -0.8789, -1.6406]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.0511503, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0041028490086318925, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0297, -0.0359, -0.1553,  ..., -0.0097,  0.0066, -0.0752]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0830, -0.3652, -0.1445,  ..., -0.1904,  0.0023, -0.2832]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.5000,   0.7422,  -3.4062,  ...,   2.4219,   1.2109,  -1.4688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.5156,  0.7266,  0.5820,  ...,  0.5391, -1.1094, -0.7812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.0747826, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.004191194006125443, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1260, -0.1030,  0.0164,  ...,  0.0479, -0.0518, -0.0457]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0618, -0.0014, -0.0840,  ...,  0.1050,  0.0249,  0.1611]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.0000,  6.2500, -0.5352,  ...,  0.0820, -0.2031,  1.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-6.2812,  2.4062,  0.1064,  ..., -0.8672,  0.4922, -3.3750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.0982068, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.00426829801290296, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0200,  0.0139,  0.0134,  ...,  0.0640, -0.0173, -0.1279]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4961, -0.0151,  0.0461,  ...,  0.4141,  0.0786,  0.0806]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-12.7500,  -9.5625, -16.6250,  ...,   3.1406,  -3.1562,  11.9375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1226,  1.6484, -3.5312,  ..., -0.0422, -1.0625,  1.7266]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr)\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.121785, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.004347126014181413, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.1104,  0.0469,  0.0256,  ..., -0.0569,  0.2324,  0.0337]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0952,  0.0908, -0.0830,  ..., -0.1973,  0.1484, -0.0781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.3750,  -8.8750, -10.1250,  ...,   1.9844,  -5.9062,  -2.0469]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.8555,  0.3262, -0.0024,  ...,  0.4961, -0.5938,  0.2949]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <=\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.1449656, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.004423138016136363, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0605,  0.0312, -0.0762,  ..., -0.1406, -0.0092, -0.0708]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0322, -0.3398, -0.1055,  ..., -0.3320, -0.0569, -0.5469]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-13.3125,   4.8750,  -0.9688,  ...,  12.7500,   2.0000,   2.5156]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.8984,  0.1836, -0.2832,  ..., -1.2031,  0.1089, -3.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= \", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.1684923, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.004499341011978686, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0155,  0.0022,  0.0003,  ..., -0.1562,  0.0737,  0.0786]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0249, -0.0549,  0.1099,  ...,  0.0383,  0.1328, -0.1118]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.7500,  -0.2578,  -6.4688,  ...,   6.7500,  -1.9141,   5.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.5312, -4.3125,  0.3516,  ...,  2.0469, -2.4844, -9.6875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.1921282, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.004575845014187507, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0040, -0.0396,  0.0049,  ..., -0.0786,  0.1328, -0.0535]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0157, -0.0581,  0.0320,  ..., -0.0391,  0.0771, -0.0239]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -7.2500,   0.1719,  -2.8438,  ...,   8.8750, -10.1250,   9.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.3242,  1.0859, -0.1387,  ..., -0.9609,  0.4863, -2.2344]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.215716, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.004653601004974917, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0076,  0.0850, -0.0166,  ...,  0.1348,  0.0060, -0.0527]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2188, -0.0035,  0.0337,  ...,  0.0801,  0.0713, -0.1826]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.9375,  5.1250, -6.6250,  ..., -2.2500, -2.6250, 14.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.5625, -0.1221, -2.2812,  ..., -1.1250,  1.0859, -6.9375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n       \", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.2393136, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.004730284999823198, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0444,  0.0262, -0.0703,  ...,  0.0608,  0.1074, -0.0195]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2402, -0.1729,  0.0820,  ...,  0.0520,  0.1196, -0.2012]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.0000,  2.9062, -4.7500,  ...,  5.5312,  4.5312,  0.6797]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.0859,  0.1079, -0.7383,  ...,  0.9961, -1.2109, -0.1504]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.2628932, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0048162869934458286, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0811, -0.0742, -0.0728,  ...,  0.0649, -0.0278, -0.1128]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.3320, -0.1982,  0.1729,  ...,  0.0217, -0.1367, -0.2471]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.4375, -1.9844, -2.9531,  ...,  6.9688,  7.0625,  3.9844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.2344, -0.8242,  0.2354,  ...,  4.6250, -2.6719,  1.6719]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.2864337, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0048924699949566275, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0610,  0.0095, -0.0073,  ..., -0.1191, -0.1064, -0.0605]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4199,  0.0608,  0.0483,  ...,  0.2793,  0.1523,  0.0977]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-14.5000,   4.3125,  -6.2812,  ...,  -2.1719,  -7.3750,  10.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.0703, -1.3359, -0.6758,  ...,  0.2129, -0.1943, -0.5273]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.309671, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.004969403991708532, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0505,  0.0791,  0.0210,  ...,  0.0186,  0.0669,  0.0483]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1836, -0.0796, -0.0322,  ..., -0.1196,  0.1338, -0.0045]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.6875,  3.4531,  0.5977,  ..., -2.2031,  1.4062, 15.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.6719,  3.5469, -1.4219,  ...,  5.4062,  2.7656, -0.8594]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n   \", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.3338382, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0050487929984228685, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0791, -0.0113, -0.1494,  ...,  0.0728,  0.0635,  0.0063]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1367, -0.0649,  0.0471,  ...,  0.1387,  0.1504, -0.3535]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.8125,  0.2617, -1.7188,  ..., -0.1914, -7.0938,  0.0518]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.5352,  0.6797, -0.1406,  ...,  0.9141, -0.4004, -2.4688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.3574297, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0051258169987704605, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1128, -0.1221, -0.1494,  ..., -0.0342,  0.1187, -0.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1973, -0.1973, -0.2168,  ..., -0.4258, -0.0933, -0.1270]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-5.2500, -2.0156,  3.0781,  ...,  3.7969, -8.7500, 10.7500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3770,  1.4141,  0.4004,  ...,  1.6953, -0.1191, -1.6641]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.3809016, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.005201528998441063, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1152,  0.3262, -0.0530,  ...,  0.1611, -0.0366, -0.0845]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2793,  0.0635,  0.1309,  ...,  0.0723, -0.0010, -0.4453]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.8125,  3.1406, -1.8672,  ..., -0.1328, -4.7812,  9.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.4688,  0.0273, -1.6484,  ..., -0.0264,  1.5703, -7.7500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n       \", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.4044967, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.005278092998196371, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0255,  0.0459, -0.0928,  ...,  0.0693,  0.1143, -0.0089]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2441, -0.0613,  0.0542,  ...,  0.0444,  0.1621, -0.1328]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -9.3750,  -0.7227,   2.1562,  ...,   2.3438, -10.6875,   0.1504]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.8047, -1.6641,  1.2422,  ...,  0.9023, -2.5625, -1.2188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.4278271, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.005353714994271286, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0264, -0.1318,  0.0425,  ..., -0.1309, -0.0625, -0.0208]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1396,  0.0017,  0.0752,  ..., -0.0400, -0.1299,  0.0967]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.4688,  1.2266,  7.0625,  ..., -7.3438, -0.1250, -2.2031]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.7539, -0.5898,  0.2363,  ...,  0.1406, -0.5000, -1.8125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot =\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.451619, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0054418009967776015, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0298,  0.0884,  0.0503,  ...,  0.0796,  0.0630, -0.0508]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0645, -0.1299, -0.1611,  ...,  0.0199,  0.2598, -0.1592]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.9375, -2.0938, -3.3438,  ...,  3.1562,  3.2812, -1.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.7188, -0.1299, -1.4922,  ...,  3.1875, -1.2422,  0.2773]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.4751594, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.00551921600708738, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0693,  0.0137,  0.0258,  ..., -0.0591, -0.1709, -0.0474]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4434,  0.0918,  0.1128,  ...,  0.2871,  0.1226,  0.0737]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.2031,  5.8125, -4.7500,  ..., -6.5312, -6.3125,  4.7812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.3906, -2.2812,  2.7188,  ...,  2.4844,  2.3438, -0.3730]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.49884, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.005594567002844997, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0117,  0.0542, -0.0635,  ..., -0.1992,  0.0236, -0.0830]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0903, -0.1758, -0.0938,  ...,  0.2012,  0.1436,  0.0684]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.6875,   7.3125,  -0.1016,  ...,   3.0156,  -3.1875,   1.6875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-5.3125,  2.5469, -0.0684,  ...,  0.0801,  0.7930, -3.3281]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.522135, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.005669958001817577, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0562, -0.0177,  0.0415,  ...,  0.0669, -0.0396, -0.2100]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4453,  0.0640,  0.0113,  ...,  0.3750,  0.0339,  0.1543]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.7500, -6.8125, -9.9375,  ..., -5.2500,  0.6172, 22.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.4531,  3.7500, -7.3750,  ...,  1.2109,  2.5000,  3.0469]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr)\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.5456142, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.005748786003096029, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0850,  0.0248,  0.0327,  ..., -0.0469,  0.1768, -0.0121]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0571,  0.1309, -0.0518,  ..., -0.2188,  0.0767,  0.0056]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.0312, -1.0156, -2.2656,  ..., -8.3125, -3.6875,  6.7188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.5977, -0.3789, -3.9375,  ...,  0.2461,  2.6562, -0.2490]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) //\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.5690484, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.005824327003210783, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0967,  0.0957, -0.0747,  ..., -0.0143, -0.0215, -0.0376]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0554,  0.0679, -0.3125,  ...,  0.2168, -0.0825, -0.0830]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.8125,  0.3984,  2.1875,  ...,  9.3125,  0.4258,  5.6562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.5000,  0.2070, -2.8125,  ...,  1.7031,  0.8867, -0.0172]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // \", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.5928109, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.005901632001041435, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0376,  0.0991,  0.0004,  ..., -0.0277, -0.0236,  0.0903]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1250, -0.1172,  0.1328,  ..., -0.0698,  0.1113, -0.0038]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.2812, -4.7812, -6.5625,  ...,  6.0938, -0.0693,  4.7188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8281, -6.8125, -3.3594,  ...,  4.4062, -2.8750, -4.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.6163988, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.00597759400261566, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0076,  0.0742,  0.1021,  ...,  0.0234, -0.0135, -0.0664]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0231,  0.0277,  0.0439,  ...,  0.0679,  0.0693, -0.1123]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.8750,   1.5938,  -4.5625,  ...,  -5.5312,   0.5156,  10.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.5781,  0.6641, -1.4922,  ...,  0.6523, -0.1035, -1.9297]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.6400266, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0060524040018208325, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[0.0342, 0.0197, 0.0522,  ..., 0.1982, 0.0118, 0.0330]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1953, -0.1738,  0.0131,  ..., -0.0781,  0.1279, -0.0933]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-12.8750,   4.2812,  -3.2188,  ..., -10.5000,  -5.6562,  10.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3633,  1.7344, -0.6094,  ..., -0.3887, -0.4805, -4.4062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n       \", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.6672337, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.006129269007942639, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0371,  0.0522, -0.1157,  ...,  0.0869,  0.0635, -0.0349]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1680, -0.0801,  0.0569,  ...,  0.0364,  0.0986, -0.1699]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-0.9961, -0.4922,  3.6562,  ...,  0.3867,  1.7578,  3.9844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.7070,  0.7578, -2.2031,  ...,  3.7031, -1.2266, -0.7773]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.690865, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.006205672994838096, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.2109, -0.0269, -0.0122,  ...,  0.0684, -0.1260, -0.0527]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2363,  0.2080, -0.0077,  ..., -0.1670, -0.1992,  0.3184]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.9375,   2.0469,  11.0000,  ...,  -3.8438,   9.9375,   2.5781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.6250, -0.2061, -0.2188,  ...,  0.1582,  1.3828, -3.3906]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left =\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.7146187, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.006281584996031597, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1187, -0.0762,  0.0247,  ...,  0.1279,  0.0747, -0.0806]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0967, -0.1377, -0.0854,  ..., -0.0051,  0.3008, -0.1689]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -8.1250,   4.9375,  15.5625,  ..., -10.8750,   5.1875,  10.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.6367,  0.8945, -3.2031,  ...,  0.3574, -1.4062,  0.1855]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.7381005, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.006356024998240173, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0513,  0.1143,  0.0957,  ..., -0.0649, -0.1074,  0.1064]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0615, -0.2754,  0.0928,  ...,  0.0811, -0.0247,  0.0013]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-17.0000,  11.3750,   4.8750,  ..., -11.1875,   1.8594,   0.5156]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.4375,  0.3789,  3.8906,  ..., -1.9922,  3.7031, -2.2969]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.761614, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.006436275987653062, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0454, -0.0918,  0.1465,  ...,  0.0698, -0.0879,  0.0591]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1865, -0.1680, -0.0398,  ..., -0.0562, -0.0806, -0.0156]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-12.8750,   5.8125,  -3.6250,  ...,  -3.5312,  -0.3340,  -0.3457]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.5430,  0.0698,  0.0221,  ...,  0.6484, -0.3633, -1.0391]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.7855568, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.006511416984722018, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0054,  0.0669, -0.0284,  ...,  0.0032, -0.0542, -0.1123]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3164, -0.2129,  0.0018,  ..., -0.5547, -0.1904,  0.1328]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.5000,   1.7969,  -2.6406,  ...,   1.0781,  -1.1016,  -7.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.1172,  3.1719,  1.3125,  ...,  2.5625, -0.5938,  2.9219]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.8094003, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.006591457989998162, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0610, -0.0074,  0.1279,  ..., -0.0215, -0.1562, -0.0898]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1914, -0.0131, -0.1279,  ..., -0.1167, -0.0118,  0.1104]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.7188,  3.0469,  1.9844,  ...,  1.3203,  3.0625,  1.3281]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.7344,  0.2471, -2.0781,  ..., -1.0625, -1.7344, -0.5781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.8330178, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.006678981982986443, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0635,  0.0034,  0.0066,  ...,  0.0481, -0.0986, -0.1738]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1865, -0.4512, -0.1416,  ..., -0.4434, -0.1914, -0.3496]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.6875,  2.2812, -1.5391,  ...,  1.9922,  2.6406, -3.9844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2188, -1.1328, -0.3945,  ...,  5.2500, -1.2266,  0.1914]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.8565893, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.006755374983185902, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0664,  0.0137,  0.0649,  ..., -0.0245, -0.1318, -0.0845]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3457,  0.0972,  0.0349,  ...,  0.3203,  0.1084,  0.1338]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-0.3281,  2.6562, -4.6562,  ..., -5.0312,  4.6875,  1.6484]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.9492, -1.7188, -0.8867,  ..., -0.8984,  0.0084, -0.6758]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.8801584, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.006830265992903151, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0006, -0.0332, -0.0251,  ..., -0.0059, -0.0253, -0.0942]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1089, -0.3887,  0.0659,  ..., -0.1504, -0.0889,  0.0776]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.9375,   1.0391,  -2.5781,  ...,   1.1406,   1.0781,  -0.8828]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1836,  1.9531,  0.9258,  ...,  1.9688, -0.6836,  3.7500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.9037504, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.006904634996317327, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0640,  0.0046,  0.1113,  ...,  0.0508, -0.0938, -0.0317]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2832, -0.0574, -0.1650,  ..., -0.1387,  0.0098,  0.1387]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-13.5625,   5.1250,  -1.2266,  ...,  -6.9688,  -1.4062,   6.2812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.8672, -0.7461, -2.3750,  ...,  1.1250,  0.7344, -1.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x <\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.9273725, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.006980909005505964, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0049,  0.0986, -0.0520,  ...,  0.0918, -0.0608, -0.0703]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1465, -0.4141, -0.1426,  ...,  0.0645,  0.1572, -0.3359]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.2500, -0.8750,  2.9062,  ..., 10.0625, -7.1562, -3.7812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.7422, -0.8203,  2.3750,  ...,  2.4062, -5.0938, -4.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.9508476, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.007056400994770229, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0154, -0.0815,  0.0635,  ..., -0.0400,  0.0287,  0.0115]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1060, -0.0522,  0.0942,  ..., -0.0089, -0.1562,  0.0308]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.3125,   5.5000,   1.6719,  ...,  -3.3594,  -0.8438,   9.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.9609, -0.9688, -0.9688,  ...,  1.2969, -0.8984, -3.4844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.9744153, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.007133706007152796, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.1216,  0.0835,  0.0693,  ...,  0.2100, -0.0723,  0.0193]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1553, -0.0806,  0.0212,  ..., -0.0361,  0.1089, -0.0386]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -5.2812,  -1.4375,   1.6875,  ..., -13.1250,   2.3906,  15.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.4219,  0.1113, -1.9609,  ...,  0.6758, -0.6914, -7.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n       \", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.9979098, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.007210029012640007, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0287,  0.0757, -0.1377,  ...,  0.1196,  0.0469, -0.0576]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1699, -0.0525,  0.0430,  ...,  0.0425,  0.1040, -0.1279]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.1094, -1.2188, 10.0625,  ..., -3.6875, -4.2500,  6.5938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.5938,  0.2109, -2.5156,  ..., -1.4844, -1.1719, -3.5938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.0213614, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.007285791012691334, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0104, -0.0840, -0.0052,  ...,  0.2314, -0.0732, -0.0820]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3555,  0.1719,  0.2383,  ...,  0.0859,  0.2002,  0.1514]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-5.7500,  8.0625,  7.4375,  ...,  0.4453,  5.1562, -0.5391]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.1484, -0.0645, -1.9375,  ...,  0.1108,  2.5469, -2.6562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle =\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.0448523, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.007362545016803779, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0605, -0.0444,  0.0190,  ...,  0.1689,  0.0295, -0.0903]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0996, -0.0742, -0.0688,  ...,  0.0386,  0.2158, -0.0864]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.3125,  5.6562, 12.6250,  ..., -2.5469, 10.3750,  1.2578]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 3.9062e-03,  1.6797e-01, -8.1875e+00,  ..., -1.6309e-01,\n",
      "         -2.4688e+00,  1.9609e+00]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.0682018, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.007438738030032255, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0449,  0.1108,  0.1050,  ..., -0.0178, -0.1465,  0.1143]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0977, -0.2295,  0.1069,  ...,  0.0947, -0.0317,  0.0095]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-18.7500,   2.9062,   5.8125,  ...,  -5.5000,   7.5000,   3.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.9375,  3.2500,  1.2656,  ...,  0.6406,  4.9688, -1.8984]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.0916603, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.007513338030548766, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0015, -0.0996,  0.1504,  ...,  0.1064, -0.1279,  0.1084]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1660, -0.0383, -0.0337,  ..., -0.0131, -0.0532, -0.0009]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.5000,  6.5625, -0.3359,  ..., -8.0000,  3.6875, -0.1309]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.1719,  0.8516, -0.5117,  ...,  0.5547, -0.4707, -0.4609]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.11513, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.007589461034513079, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0014,  0.0713, -0.0106,  ...,  0.0188, -0.0649, -0.1152]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2949, -0.1973,  0.0089,  ..., -0.5234, -0.1973,  0.1187]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.1250,  3.3438, -0.6133,  ..., -2.7656, -1.1953, -1.0469]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8711,  3.8125,  1.5625,  ...,  3.4062, -0.2100,  3.4531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.138643, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.007668149031815119, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0417, -0.0137,  0.1270,  ...,  0.0229, -0.1895, -0.0356]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1816,  0.0334, -0.1250,  ..., -0.0684, -0.0154,  0.1006]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-5.4375,  6.5312,  3.9062,  ..., -5.5312,  1.7500,  1.8594]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.7188, -0.0596, -1.6406,  ..., -0.4199, -1.3516, -0.9922]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.162049, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0077458850282710046, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0559,  0.0102,  0.0098,  ...,  0.0684, -0.0986, -0.1885]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1797, -0.4609, -0.1235,  ..., -0.4453, -0.1973, -0.3809]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.0000,  2.2812, -0.3398,  ...,  3.7812,  2.5625, -4.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.8047, -0.5977, -0.5352,  ...,  6.6250, -1.0234,  0.9141]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.1855106, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.00782462302595377, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0513,  0.0178,  0.0547,  ..., -0.0110, -0.1445, -0.0859]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3340,  0.1167,  0.0505,  ...,  0.3242,  0.1050,  0.1201]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.1562,  4.3438, -0.4043,  ..., -3.9062,  4.8438, -0.5781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.5625,  0.0596, -2.4062,  ..., -1.5234, -0.2871, -0.3945]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.2092748, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.007910154017736204, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0227, -0.0337, -0.0234,  ...,  0.0135, -0.0183, -0.0947]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1279, -0.3848,  0.0874,  ..., -0.1826, -0.1016,  0.0417]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.3750,   5.9375,  -0.0566,  ...,   0.4688,  -0.8984,  -2.2188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4219,  2.7031, -0.0713,  ...,  1.8906, -0.1216,  4.7188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.2330456, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.007991978010977618, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0547,  0.0023,  0.1191,  ...,  0.0845, -0.1230,  0.0139]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2891, -0.0288, -0.1641,  ..., -0.0972,  0.0253,  0.1279]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-12.2500,   9.6875,   1.9844,  ...,  -3.2188,  -7.3750,  -1.3594]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.6406, -0.8203, -3.0469,  ..., -1.7266,  0.3770, -1.8672]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x ==\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.2567499, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.00806956400629133, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0405,  0.0291,  0.1021,  ..., -0.0522,  0.0569, -0.1206]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1826, -0.1357,  0.1504,  ..., -0.3164,  0.0913, -0.4023]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.8750,  1.4297,  3.3281,  ...,  8.5000, -9.5000, -6.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1738,  1.4688,  2.9219,  ...,  1.2891, -6.3750, -6.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.2804155, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.008144515013555065, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0486, -0.1211,  0.0298,  ..., -0.0840, -0.0442, -0.0157]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0757,  0.0003,  0.0659,  ..., -0.0388, -0.1318,  0.0378]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.0625,  3.1875, -0.4590,  ..., -8.3750,  2.2031,  5.9062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.8828, -1.6328, -1.3359,  ...,  2.9219, -1.5938, -4.6875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.304186, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.008220247022109106, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0801,  0.0496,  0.0493,  ...,  0.1650, -0.1113,  0.0100]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1846, -0.0723,  0.0601,  ..., -0.0586,  0.0967, -0.0522]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -7.6250,   2.4375,   1.1250,  ..., -10.1875,  -0.3867,  11.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.8828,  0.5078, -3.3125,  ...,  1.2969,  1.2031, -6.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n       \", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.3277755, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.008297452019178309, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0571,  0.0723, -0.1396,  ...,  0.1089,  0.0349, -0.0603]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1553, -0.0486,  0.0449,  ...,  0.0337,  0.1118, -0.1240]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.9375,   4.0000,  10.3125,  ...,   4.9062,   0.6523,   4.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1797,  0.2363, -0.6602,  ...,  2.0000, -2.7812, -0.0854]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.3515222, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.008373053016839549, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0491, -0.0386,  0.0135,  ...,  0.0762, -0.1611, -0.0854]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2051,  0.4238, -0.1001,  ..., -0.0640, -0.0041,  0.2295]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.5000,   3.4531,   6.8125,  ...,   1.6719,   4.8750,   1.2969]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.3672, -0.3828, -3.4844,  ...,  1.9844,  1.4453, -2.3594]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right =\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.3751738, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.008449496017419733, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0669, -0.0723,  0.0033,  ...,  0.0742,  0.0476, -0.0525]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1157, -0.0815, -0.0273,  ...,  0.0261,  0.2490, -0.1377]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.4375,  2.0312,  7.7500,  ...,  0.3906,  5.4688,  1.9375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.3516,  0.5703, -8.3125,  ...,  1.1641, -2.6406,  1.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.3991642, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.008528945021680556, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0297,  0.1079,  0.1025,  ..., -0.0635, -0.1338,  0.1201]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0581, -0.2373,  0.0840,  ...,  0.0933, -0.0240, -0.0007]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.9375,  -0.0273,   0.3008,  ...,  -2.7500,   3.0312,   1.6641]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4707,  4.4688,  0.9766,  ...,  0.6094,  3.3281, -2.0469]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.422943, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.008606411021901295, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0046, -0.1016,  0.1514,  ...,  0.1089, -0.1118,  0.1177]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1719, -0.0104, -0.0251,  ..., -0.0151, -0.0498,  0.0123]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -4.7188,   5.2812,  -6.9375,  ..., -11.3750,   2.6250,  -3.5469]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.1562,  0.9062, -1.1719,  ...,  1.3125, -2.2031, -1.0312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.4466016, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.00868452801660169, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0071,  0.0771, -0.0084,  ...,  0.0137, -0.0396, -0.1123]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2949, -0.1992,  0.0148,  ..., -0.4980, -0.2012,  0.0854]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.5625,  3.3438,  1.0234,  ..., -2.8125, -2.3438, -3.4219]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.6367,  3.0781,  0.3926,  ...,  5.1250, -0.7695,  2.7812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.470255, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.008760200013057329, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0562, -0.0062,  0.1299,  ...,  0.0300, -0.1768, -0.0193]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1885,  0.0322, -0.1123,  ..., -0.0540, -0.0130,  0.1055]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-13.0000,   3.1250,   3.6094,  ...,  -6.7500,   3.0469,   0.4102]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.7500,  0.8320, -1.4688,  ...,  0.8672, -2.6094, -1.9219]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.4941304, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.008843777002766728, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0569,  0.0164,  0.0121,  ...,  0.0664, -0.0815, -0.1836]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1934, -0.4531, -0.1328,  ..., -0.4473, -0.1982, -0.3887]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.8125,  1.8750, -1.6250,  ...,  2.3750,  2.9375, -0.6172]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.2812, -1.3359,  0.0400,  ...,  5.9375, -2.2031,  1.2969]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.5177, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.008921924003516324, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0674,  0.0220,  0.0557,  ..., -0.0094, -0.1318, -0.0796]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3398,  0.1099,  0.0466,  ...,  0.3105,  0.1074,  0.1099]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.7188,  1.1484, -5.4062,  ..., -5.3438,  3.0469, -1.2031]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.9453, -1.0703, -1.1406,  ..., -0.7617, -1.7812, -0.7266]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.5413804, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.008998377015814185, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0239, -0.0262, -0.0258,  ...,  0.0119, -0.0002, -0.0854]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1367, -0.3594,  0.1016,  ..., -0.1768, -0.1060,  0.0591]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.7812,  2.5625, -2.9531,  ...,  2.2188, -3.5625, -1.4844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4707,  2.4062,  2.0312,  ...,  2.9531, -0.1885,  4.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.565191, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.009074831017642282, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0576,  0.0080,  0.1133,  ...,  0.0933, -0.1201,  0.0168]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2871, -0.0249, -0.1475,  ..., -0.0820,  0.0232,  0.1240]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.4375,   5.3438,   5.0000,  ...,  -0.7500,  -4.1562,   4.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.8945,  1.8906, -1.2266,  ...,  0.9688, -0.2471, -0.9531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x >\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.5887873, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.009161273017525673, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0127,  0.0508,  0.0796,  ..., -0.0156,  0.0106, -0.0498]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1660, -0.0317, -0.0439,  ...,  0.2012, -0.0620, -0.1436]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.4375,  3.5781,  5.3438,  ...,  7.3125, -4.8438, -3.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2812,  1.6250,  2.8438,  ...,  4.0625, -5.8438, -6.4062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.6125057, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0092402510199463, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0806, -0.1416,  0.0500,  ..., -0.0742, -0.0334,  0.0095]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1396,  0.0530,  0.0972,  ...,  0.0240, -0.1631,  0.0364]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-14.0000,   5.2188,  -1.3203,  ...,  -3.7344,   4.4062,  10.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.0391, -0.4570,  0.6211,  ...,  1.0547, -2.3750, -3.2969]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.6362565, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.009320362019934691, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0830,  0.0850,  0.0757,  ...,  0.1982, -0.1182,  0.0364]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1729, -0.0574,  0.0542,  ..., -0.0408,  0.1108, -0.0742]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-15.9375,   3.5000,  -0.5547,  ...,  -6.6875,   3.3750,  15.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.9492, -0.1680,  0.1826,  ...,  0.7500, -1.3359, -3.4531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n       \", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.6599343, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.009405261007486843, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0679,  0.0659, -0.1445,  ...,  0.1138,  0.0520, -0.0527]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1504, -0.0320,  0.0488,  ...,  0.0364,  0.1143, -0.1226]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.6875,   1.0859,   3.2812,  ...,   3.3125,   7.3125,  -0.9219]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1592, -0.2178, -0.6602,  ..., -0.7500, -0.8984, -0.3906]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.6836627, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.009484309004619718, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0635, -0.0415, -0.0757,  ...,  0.0684, -0.0698, -0.1240]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2236, -0.1094,  0.1147,  ...,  0.0757, -0.0771, -0.1484]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.6406, -3.5625,  0.2344,  ...,  3.3125,  3.4375,  5.5625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2891, -0.0918, -0.1758,  ...,  4.2500, -2.8125, -1.8984]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.7074287, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.009560712016536854, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0474,  0.0791, -0.0986,  ..., -0.0231,  0.1562, -0.0259]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3242,  0.5195,  0.1768,  ...,  0.1875,  0.1924,  0.1660]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.9375,  -0.3594,   3.9219,  ...,  -0.7188,  -2.5000,  -2.5938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ -1.1641,   7.2812,   1.0000,  ...,  10.6875,  -1.9219, -10.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.7311647, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.009637556009693071, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0874, -0.0317, -0.0869,  ..., -0.0952,  0.0004,  0.2012]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0181,  0.1504, -0.1182,  ...,  0.0361, -0.0947, -0.1260]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.4375,  6.0625,  6.9062,  ..., -4.1875,  0.6406, -1.7266]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4668,  6.0000,  3.4688,  ..., -2.6562,  1.9062, -5.4688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.7550209, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.009713329010992311, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1475,  0.0128, -0.0211,  ...,  0.1816, -0.0938, -0.0510]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4570,  0.1279, -0.0097,  ...,  0.0530, -0.1494,  0.2559]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.3750, -3.4062, -2.1094,  ..., -0.7812, 10.5000, 18.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.0156,  0.7500, -4.4375,  ...,  0.2227,  0.8438,  2.2344]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left)\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.7787025, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.009788520008441992, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0417, -0.0894, -0.0630,  ..., -0.0133,  0.0840,  0.0090]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0146,  0.0432,  0.0276,  ..., -0.2109,  0.0129, -0.0708]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.5312, -3.9531,  3.9219,  ..., -2.5469, 11.0000,  2.6562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2188, -1.5000, -3.4375,  ...,  0.5586,  1.2266, -2.4531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) +\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.8024678, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.009863811006653123, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1318, -0.0908,  0.0923,  ..., -0.0415,  0.0393,  0.0057]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2373, -0.1445, -0.1387,  ..., -0.1094,  0.0718, -0.0344]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-0.7617, -5.1875, 10.3750,  ..., 12.8750,  6.2812, -1.1094]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.7930, -1.7656, -1.8438,  ...,  2.1250,  1.4766,  0.0527]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.8262386, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.009942339005647227, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0781, -0.0084,  0.0166,  ...,  0.2295, -0.0830, -0.0742]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3496,  0.1582,  0.2422,  ...,  0.0183,  0.1855,  0.1670]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.0000,  0.6484, -0.3594,  ..., -4.9688, 14.9375,  0.4180]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8164, -0.6797, -4.6875,  ...,  1.5312,  1.3438, -1.3359]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle +\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.850032, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.010017249005613849, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0864, -0.0325,  0.0537,  ...,  0.0104,  0.0544, -0.0106]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3672,  0.0281, -0.0452,  ..., -0.0215,  0.0271,  0.1367]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 1.8125e+00, -3.7812e+00,  5.5312e+00,  ...,  7.8125e-03,\n",
      "          5.3750e+00,  9.0000e+00]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.5742,  1.5625,  0.0410,  ...,  6.0312, -4.9375, -0.4141]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.8735495, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.010093681994476356, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0073,  0.0693, -0.0967,  ...,  0.0151,  0.1182, -0.0972]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2852,  0.4648,  0.1611,  ...,  0.1260,  0.1992,  0.1592]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.8125,  -0.6211,   0.8281,  ...,  -5.2500,  -2.6250,  -4.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.4375,  3.6562,  1.2422,  ..., 10.0000, -2.1250, -8.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.8973706, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.010169673987547867, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1240, -0.0306, -0.0806,  ..., -0.0918, -0.0217,  0.2080]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0106,  0.1338, -0.1138,  ...,  0.0157, -0.0728, -0.1235]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.0000e+00,  6.6250e+00,  1.1312e+01,  ..., -6.6875e+00,\n",
      "         -3.9062e-03,  5.7812e+00]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.3438,  3.5156,  3.1094,  ..., -0.4004,  2.6719, -3.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.9213688, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.010246998979710042, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 1.2207e-04,  7.9346e-03,  1.5625e-02,  ...,  1.4648e-01,\n",
      "         -3.3936e-02,  4.2236e-02]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4375,  0.2988,  0.0035,  ..., -0.0129,  0.2275, -0.0007]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.6875,   2.2031,  -3.5938,  ...,  -0.8945,  -2.0312,  12.6875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[0.6367, 2.0781, 1.8750,  ..., 0.0151, 0.2168, 0.9766]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.9452314, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.010323181981220841, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0344, -0.0693,  0.1543,  ...,  0.1187,  0.0598, -0.0058]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0933, -0.1445,  0.0330,  ...,  0.0398,  0.1982, -0.0009]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.3438,  4.6875,  3.9375,  ...,  1.3906,  9.9375,  5.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.1016, -0.9375,  0.7031,  ..., -1.5859, -0.4629, -1.0859]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n#\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.9692028, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.010414031974505633, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0640, -0.0052, -0.0231,  ...,  0.0233, -0.0557, -0.0918]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0047,  0.0913, -0.3477,  ...,  0.1973, -0.0552, -0.3672]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.0938,  3.3438,  4.6875,  ..., 10.9375,  2.8594,  2.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.6719, -0.5312, -2.7031,  ...,  2.0625,  0.9609, -1.3203]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.99308, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.010490314976777881, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0293,  0.0258, -0.0688,  ...,  0.0444,  0.0581,  0.0070]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0869, -0.1904, -0.1895,  ..., -0.0073,  0.1123,  0.0228]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.0938,  9.1875,  6.3750,  ...,  6.1250, -3.1406,  2.7500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1914, -0.1885, -0.5625,  ..., -0.2969,  0.9062, -1.8594]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.0165567, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.010567699981038459, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1729,  0.0130,  0.0549,  ...,  0.2832, -0.0938, -0.1992]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.3535, -0.0442, -0.0718,  ...,  0.1050, -0.0669, -0.3965]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.4375, -5.5625,  8.5000,  ...,  5.1875, -8.2500,  3.3594]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3906,  0.8125, -0.9219,  ...,  1.0312, -0.6641, -0.0303]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\n\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.0402765, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.010646958980942145, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0635, -0.0405,  0.0923,  ...,  0.1875, -0.1650,  0.0101]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0004,  0.0918, -0.0659,  ..., -0.0204, -0.2217,  0.0376]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-13.3750,   6.6250,   5.5625,  ...,   5.6875,  11.9375,   3.7656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.4531, -1.4766, -0.2344,  ..., -1.1719,  0.1914, -1.4062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.0641193, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.010728591980296187, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1621, -0.0281,  0.1108,  ..., -0.1050, -0.0022, -0.0161]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3555, -0.0938, -0.0344,  ...,  0.2539,  0.1709,  0.0513]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.2500,   9.1875,   2.8594,  ...,   6.4375,   5.8438,   2.9531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1836,  0.2266, -0.9062,  ..., -1.3125,  2.4688, -0.5508]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr =\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.0880344, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.010804734978592023, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1348, -0.0229,  0.0688,  ...,  0.1562,  0.0508, -0.0309]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1123, -0.1484, -0.1206,  ...,  0.0532,  0.1436,  0.0135]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-13.1875,   9.4375,   7.0000,  ...,   2.3438,   6.5938,  -4.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.5664,  0.9727, -3.7969,  ...,  0.2041, -1.3828, -0.7500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.1119237, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.010882149974349886, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0664,  0.1348,  0.0869,  ..., -0.0649, -0.0972,  0.1260]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0640, -0.2432,  0.1094,  ...,  0.0654, -0.0347, -0.0498]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-12.2500,   4.0312,   7.7500,  ...,  -2.5625,   5.1875,  -1.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2109,  1.3438,  0.5781,  ..., -3.0156, -1.6797, -5.2188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.1356385, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.010959264967823401, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0352, -0.0291,  0.0820,  ...,  0.0325, -0.0610, -0.0210]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1445, -0.0588,  0.0559,  ..., -0.1367,  0.0767,  0.1138]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.6250, -0.1953,  3.2969,  ...,  0.0156, -6.9688,  2.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0161,  0.2256,  0.9297,  ..., -1.6328, -1.3203, -2.7188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3,\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.1594148, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.011035868970793672, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0259, -0.0515,  0.0291,  ...,  0.0474, -0.0669, -0.0190]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0703, -0.1289,  0.1328,  ...,  0.1348,  0.0806, -0.0649]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.4375, -1.3594,  5.4688,  ...,  1.1562, -7.0625,  2.1094]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.4688,  1.1797, -4.2812,  ..., -1.6875,  1.2812, -5.5938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, \", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.1831932, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.011111269966932014, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0250,  0.0562,  0.0447,  ..., -0.0415,  0.0181,  0.0087]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1045, -0.0513,  0.1084,  ..., -0.0801,  0.1562, -0.0378]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.5234, -2.0156,  3.9375,  ..., -3.6094, -4.4062,  3.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.0156,  0.7305, -5.0938,  ..., -2.2344, -1.8359, -7.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.2070353, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.011186270974576473, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0269,  0.0454,  0.1953,  ..., -0.0347, -0.0845, -0.1230]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0938, -0.0588, -0.0312,  ...,  0.2422,  0.0698, -0.0525]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 1.9375,  0.2617, -2.0625,  ...,  2.4062, -9.4375,  3.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3535,  0.9531, -2.9531,  ..., -1.7422,  0.9492, -0.9492]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6,\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.2318947, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.011262714979238808, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0488, -0.0033,  0.0620,  ...,  0.0640, -0.0305,  0.0135]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0181, -0.0148,  0.0923,  ...,  0.0339,  0.0771, -0.1001]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 5.0938,  1.3750, -9.1875,  ..., 11.6250, -2.0000,  5.3438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ -2.7500,   2.4844,  -4.0625,  ...,  -2.5000,   5.0625, -10.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, \", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.255904, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.011339888980728574, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0332,  0.0410,  0.0435,  ..., -0.0444,  0.0356,  0.0131]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1377, -0.0014,  0.0957,  ..., -0.0732,  0.1455, -0.0586]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 6.6875,  7.7812, -7.0938,  ...,  7.7812,  2.1250, 12.8125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1504,  1.4609, -4.5938,  ..., -7.6250, -1.2656, -7.9062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.2797635, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.011415870991186239, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0623,  0.1201,  0.1465,  ..., -0.0125, -0.0226, -0.1309]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0066, -0.0615,  0.0032,  ...,  0.2285,  0.0457,  0.1152]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 1.8828,  3.1250,  1.1562,  ...,  3.5469, -0.7852, -4.7500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2031,  1.8906, -3.8750,  ..., -0.0742,  0.7109, -0.5781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8,\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.303686, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.011491351993754506, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0544,  0.0085,  0.0552,  ...,  0.0250, -0.0654,  0.0095]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0471,  0.0229,  0.1104,  ...,  0.0141,  0.0845, -0.1187]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -1.3750,  -4.5625, -13.2500,  ...,  17.0000,   2.8438,  -8.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.6094, -1.3516, -4.9688,  ...,  3.4375,  3.6250, -4.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, \", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.327352, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.011568386005819775, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0386,  0.0430,  0.0417,  ..., -0.0488,  0.0408,  0.0025]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1680,  0.0398,  0.0967,  ..., -0.0640,  0.1357, -0.0806]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[  2.0312,  -5.0000, -17.0000,  ...,  10.7500,   7.3438,  -4.0000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 3.4062, -0.3320, -3.2969,  ...,  3.1094, -1.5234, -5.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 1\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.3509674, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.011656151007628068, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0223, -0.0259,  0.0874,  ..., -0.0486,  0.0586, -0.1084]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0439,  0.0493,  0.0659,  ..., -0.0315,  0.0640,  0.0214]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[  6.7188,   1.6719,  -9.5625,  ...,   3.0312, -12.0625,  -5.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.1797, -2.9531, -1.1719,  ..., -4.2500,  1.3750, -1.9297]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.3745756, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0117312119982671, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0767, -0.0859,  0.0437,  ...,  0.0640,  0.0679, -0.0825]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1484, -0.1201,  0.2236,  ..., -0.0203,  0.1035, -0.0684]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 2.7812, -1.3672, -1.7969,  ...,  7.3438, -1.8125, -1.6016]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.7031,  1.9844, -1.9141,  ..., -1.7344,  0.0469, -1.0781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10,\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.398248, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.011806412992882542, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0703,  0.0212,  0.0854,  ...,  0.0052, -0.0053, -0.0035]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0603,  0.0150,  0.0417,  ..., -0.0186,  0.0898, -0.1016]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.7188,  3.1406, -6.6250,  ..., 16.1250, -4.3750,  4.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 4.2188, -3.6094, -4.1562,  ..., -0.2090,  2.2656, -5.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, \", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.4220314, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.011892053982592188, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0095,  0.0491,  0.0430,  ..., -0.0559,  0.0598,  0.0038]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1680,  0.0376,  0.0762,  ..., -0.0327,  0.1348, -0.0864]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.1875,  6.4375, -1.6562,  ..., 13.1875, -5.0625,  8.0000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 5.5312, -1.4922, -0.1875,  ..., -5.1562, -2.1094, -5.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.4456935, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.011968877995968796, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0042, -0.0366,  0.0801,  ..., -0.0500,  0.0723, -0.0986]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0386,  0.0645,  0.0786,  ..., -0.0339,  0.0791,  0.0311]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -0.3516,   2.2188,  -7.1562,  ...,   4.2500, -10.3125,   3.4062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.0625,  0.3262,  0.6250,  ..., -4.6562,  0.8945, -2.2344]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1,\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.4695883, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.012051922996761277, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0420,  0.0154,  0.0698,  ...,  0.0371,  0.0256,  0.0028]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0898,  0.0167,  0.0437,  ...,  0.0228,  0.0598, -0.1089]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -9.3750,   6.7188, -21.0000,  ...,   9.4375, -10.2500,  -0.1680]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.1562, -1.3516, -3.4219,  ...,  1.3281,  2.2188, -4.7500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, \", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.4935439, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.012127996000344865, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0317,  0.0403,  0.0400,  ..., -0.0540,  0.0645,  0.0029]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1904,  0.0422,  0.0869,  ..., -0.0292,  0.1318, -0.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.1875,  14.6250, -26.1250,  ...,   3.3906,  -6.8125,   9.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 5.1875, -0.0527, -3.4688,  ...,  1.9688, -5.3125, -6.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.5174317, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.012205200997414067, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0052,  0.0211,  0.1367,  ..., -0.0199, -0.0408, -0.0913]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0102,  0.1074,  0.0894,  ...,  0.0618,  0.0874, -0.0237]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 2.5312, -4.5312,  1.3203,  ...,  3.6406, -4.5938,  9.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.6641,  2.2344, -2.0938,  ..., -0.4453, -0.6953, -0.8945]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2,\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.5413532, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.012280862996703945, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0635, -0.0089,  0.0679,  ..., -0.0019,  0.0001,  0.0166]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0820,  0.0162,  0.0625,  ...,  0.0021,  0.0859, -0.1367]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-12.8750,  10.8125,  -2.5625,  ...,   8.6875,  -0.4414,  11.5625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.8125, -2.5312, -0.8984,  ..., -2.7812,  0.4199, -1.5781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, \", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.5652595, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.012358218998997472, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0237,  0.0322,  0.0393,  ..., -0.0645,  0.0562,  0.0038]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2051,  0.0461,  0.0908,  ..., -0.0236,  0.1309, -0.0884]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-12.3125,  16.5000,  -3.6719,  ...,   3.1250,   0.6211,  20.3750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.9297, -1.2500,  2.4531,  ..., -4.1562, -5.6562, -3.1094]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.5892034, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.012443077997886576, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0081, -0.0388,  0.0972,  ..., -0.0452,  0.0549, -0.0991]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0315,  0.0608,  0.0630,  ..., -0.0232,  0.0845,  0.0310]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -3.1250,  -2.1562, -14.9375,  ...,   1.9766, -22.7500,   3.4688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2246,  0.4082,  2.5000,  ..., -1.5078, -1.2734, -2.9531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\n\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.613148, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01251978198706638, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0552,  0.0044,  0.0703,  ...,  0.1602, -0.0400, -0.0649]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2441, -0.1235,  0.0281,  ..., -0.0737,  0.1377, -0.0322]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-13.6875,  -7.2188,   2.8281,  ...,   5.4688,   2.8281,   1.1484]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0488,  0.5234,  3.6250,  ...,  0.4199,  4.4688, -2.5938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.6370966, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.012597336986800656, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0359, -0.0422, -0.0938,  ...,  0.1309, -0.1289, -0.1846]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0415,  0.1387, -0.0889,  ...,  0.1445,  0.1494,  0.1001]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-14.0625,   2.8750,   9.0000,  ...,  -2.0312,   5.7500,   0.9258]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.3203,  1.6406,  3.4219,  ..., -1.2344,  0.0947, -1.1328]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.660747, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.012676645987085067, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0635, -0.0454, -0.0184,  ..., -0.1436,  0.0635, -0.1846]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2598, -0.0913, -0.2109,  ...,  0.2578,  0.3457, -0.0591]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.4375, -0.7422,  6.8125,  ...,  1.9844,  3.3438,  1.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.7734,  0.6953, -1.3047,  ...,  0.6211,  2.4844, -2.5781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr =\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.6846032, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.012756565993186086, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0679, -0.0347,  0.0437,  ...,  0.1123,  0.0540, -0.1040]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1318, -0.1367, -0.1621,  ...,  0.0222,  0.1963, -0.0674]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.1719, -8.0625,  5.9375,  ...,  3.7656, 10.1875,  2.3906]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.6094,  3.3594, -0.9492,  ...,  5.1875, -6.0312, -2.8594]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.708422, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.012831736996304244, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0166,  0.0752, -0.0776,  ..., -0.0101,  0.1572, -0.0591]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3652,  0.4648,  0.2090,  ...,  0.2051,  0.1289,  0.2207]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-12.1250,  -1.3828,   1.8750,  ...,  -1.3047,  -1.8984,  -3.2188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.3672,  4.6875,  2.4062,  ..., 10.7500, -1.7969, -9.9375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.732338, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.012917276995722204, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1108,  0.0035, -0.0752,  ..., -0.0850,  0.0019,  0.1641]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0295,  0.1367, -0.0903,  ...,  0.0557, -0.1289, -0.1001]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.6875,  2.2188,  2.3438,  ..., -1.6562,  4.6562,  2.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-4.5312,  3.9375,  0.5703,  ..., -2.0781,  1.6484, -2.2031]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.7563102, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.012993068987270817, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0430, -0.0004,  0.0762,  ...,  0.0527,  0.0044, -0.0605]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4219,  0.0089, -0.0142,  ...,  0.3301,  0.1494,  0.0035]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.3125,   2.1250,  -7.1562,  ...,  -2.5469,   3.4062,  12.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3828,  1.1875, -0.0869,  ..., -0.1582,  0.0640, -0.2852]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\n\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.7804692, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.013076364994049072, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0128, -0.0190,  0.0889,  ...,  0.0938,  0.1279, -0.0115]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0613, -0.1230,  0.0201,  ..., -0.1445,  0.2188, -0.0354]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-15.1250,  -1.2500,   0.4980,  ...,  -2.0000,   4.5625,   0.2754]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1797,  0.1895,  2.1406,  ...,  1.7578,  3.2656, -3.1719]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.8044834, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01315161699312739, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0374, -0.1396, -0.1387,  ...,  0.0417, -0.0093, -0.1387]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2734, -0.3164, -0.2832,  ..., -0.3320, -0.3789, -0.0483]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.2500, -2.5156,  7.4062,  ..., -1.0469,  2.0625,  2.4844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.7734,  0.3086,  1.0625,  ..., -2.4219, -0.3164,  0.2715]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.8283687, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.013227769988588989, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0049,  0.0299, -0.1099,  ...,  0.3105, -0.0564, -0.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2637,  0.2773,  0.0693,  ...,  0.1045,  0.0222, -0.0253]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-15.3750,   5.6250,   2.5000,  ..., -10.1250,   4.6250,   3.0156]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2207,  4.0312,  3.9688,  ..., -0.4668, -0.6328,  3.4844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.8522902, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.013303822983289137, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0371, -0.0654,  0.0057,  ..., -0.1328,  0.0613, -0.1157]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2236,  0.0181, -0.2461,  ...,  0.2734,  0.2812,  0.0510]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.3750,  -0.3242,  -5.6875,  ...,  -2.6719,  -0.4883,   8.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.3477,  1.0078, -2.6875,  ..., -0.1240,  0.1211,  0.7656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.8758073, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.013386287988396361, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0014, -0.0566,  0.0498,  ...,  0.0295,  0.0742,  0.0025]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1055, -0.0830, -0.0139,  ..., -0.1406,  0.1748, -0.0430]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-14.5625,   2.5312,   2.3906,  ...,   0.0664,  -2.2812,  10.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2734, -1.6875,  2.2344,  ..., -0.4727, -0.2852, -2.3281]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n``\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.8997939, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01346493598248344, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0275, -0.0879, -0.0281,  ...,  0.0366, -0.0378, -0.1465]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0859, -0.1162,  0.2412,  ..., -0.4141, -0.1465, -0.1494]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.7500,  -1.0312,  -1.0312,  ...,  -5.6875,  -1.5078,  10.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2031,  1.0703, -1.2500,  ..., -1.3516, -5.0625, -5.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.9236786, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.013540567990276031, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-3.1006e-02,  4.5898e-02,  8.6914e-02,  ...,  1.5234e-01,\n",
      "         -2.7710e-02,  1.2207e-04]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4961,  0.0732, -0.0786,  ..., -0.2090,  0.3418, -0.0311]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-12.6250,   1.3750,  -4.6250,  ...,  -0.2266,   0.8750,   1.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.2344, -1.7109, -1.2344,  ...,  1.8438, -0.5234, -0.8398]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n###\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.947527, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.013617361983051524, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0442, -0.0248,  0.0141,  ...,  0.1533,  0.1504, -0.0942]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.3145,  0.1895,  0.2295,  ..., -0.0566, -0.1982, -0.0996]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.7812, -3.4219, -0.4863,  ...,  5.7188,  7.4062, -1.9062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3672,  0.6992, -3.0312,  ..., -1.1016,  0.8125,  0.2734]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.971491, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.013695318979443982, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.2295, -0.2207, -0.0649,  ..., -0.0718, -0.0923,  0.1074]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0064, -0.2021, -0.1973,  ..., -0.4062,  0.0801,  0.2236]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.2500, -0.7188,  2.7500,  ..., -0.0391, -5.0312,  7.7188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2773,  1.3750,  0.8516,  ...,  0.3047,  0.6055, -0.8594]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.9951422, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01377111098554451, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1201,  0.0327,  0.0294,  ...,  0.2188, -0.1846, -0.1211]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1235,  0.0080, -0.0635,  ..., -0.1475, -0.1680,  0.0598]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-15.4375,   0.1016,   1.7344,  ...,   3.3594,  -1.9766,  -1.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1162, -1.4297, -0.0513,  ...,  1.0625, -2.2031, -1.1953]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.018772, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.013846882982761599, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0145, -0.0177,  0.0205,  ...,  0.0430,  0.1504, -0.1279]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0820,  0.0029,  0.0178,  ..., -0.0640,  0.0352,  0.0820]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.7500, -2.5781,  1.4766,  ...,  2.0625,  5.3750, 10.9375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.6250,  0.2285, -2.2656,  ..., -2.4219,  2.3906, -2.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1.\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.042531, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.013924017985118553, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1406, -0.0908,  0.0466,  ...,  0.0312,  0.0267,  0.0444]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2715,  0.1064,  0.0728,  ...,  0.0840, -0.0510,  0.0923]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-17.2500,  -9.8125,  -4.0938,  ...,   6.5000,   0.0625,   4.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3828, -0.7617, -4.3438,  ..., -2.0938, -0.7617, -2.7656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.066297, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.013999709975905716, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0254, -0.0308,  0.0713,  ...,  0.0791, -0.0344, -0.2207]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2559,  0.0840, -0.0801,  ...,  0.0131, -0.3262,  0.2891]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-13.3125,  -6.8750,  -3.0000,  ...,   7.5000,  -0.9414,   8.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-4.4375, -0.5898, -0.8984,  ..., -0.6484,  1.4375, -5.5938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.0899184, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.014082655980018899, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0121,  0.0052, -0.0405,  ...,  0.1064, -0.1533, -0.0693]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0557, -0.1836,  0.0071,  ..., -0.1787, -0.0183, -0.0322]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-14.0625,  -0.9141, -10.8750,  ...,   7.6875,   6.4062,   8.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.7930, -1.3906, -1.1797,  ...,  6.0000,  2.3594, -2.7188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.1138258, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.014173255985951982, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.2090,  0.0422, -0.0266,  ...,  0.1953,  0.0400, -0.0649]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1055, -0.0079,  0.0879,  ...,  0.5273,  0.1064, -0.2148]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-14.7500,   3.9375,  -6.9062,  ...,   8.4375,   2.1250,   3.2344]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8750,  2.4062, -3.7031,  ...,  1.5000,  0.1758, -0.3945]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**:\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.1377585, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01424960898293648, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0378, -0.2236, -0.0425,  ...,  0.2852,  0.0820, -0.1357]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1016,  0.1079, -0.1123,  ..., -0.0420,  0.0840,  0.1123]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -4.8438, -10.2500,  -6.4375,  ...,   7.3125,   2.4219,  -1.9297]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.5625, -0.7891, -1.5938,  ...,  0.2539, -1.3125, -3.2031]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.1617856, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.014326572985737585, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0884, -0.0625,  0.0178,  ...,  0.0522, -0.0459, -0.0820]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1602, -0.1650, -0.1553,  ...,  0.0664,  0.1523,  0.0703]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.9688, -4.6875,  0.7109,  ...,  5.7188,  9.3750, -6.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2109, -0.4648, -1.4766,  ..., -2.1875, -3.1875,  0.6406]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.1857188, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01440294599160552, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0718,  0.0967, -0.0025,  ...,  0.0957,  0.0457, -0.0371]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0133,  0.0188,  0.0359,  ..., -0.1621, -0.0522,  0.1680]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.2500,  1.8594,  6.8750,  ..., -2.5625,  6.0625,  0.6602]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.9531, -1.5703, -3.1406,  ..., -0.8594, -0.3652, -0.0381]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.2097385, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01448042098490987, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0498, -0.0120, -0.0415,  ..., -0.0267,  0.0344, -0.1143]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1147,  0.0156,  0.0996,  ...,  0.0032,  0.0033,  0.0874]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.2188, -5.4688,  0.9922,  ..., -1.6328, -9.1250, -2.8125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2344, -0.6055,  0.2812,  ..., -2.5312, -0.2988,  0.1045]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.2335987, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.014556933980202302, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1787,  0.2139,  0.0083,  ..., -0.0581, -0.0072, -0.1582]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1045, -0.0708, -0.1475,  ..., -0.1523,  0.0121, -0.0928]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.9062, -7.9375, -4.5938,  ..., -0.1250, -7.0938, -0.8281]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4453, -1.2031, -1.3359,  ..., -2.6250, -1.4062, -0.7461]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has \", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.2574766, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.014633587983553298, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0557, -0.0625,  0.0015,  ..., -0.1133,  0.0200,  0.0304]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2070,  0.0679, -0.0146,  ...,  0.1157,  0.1138, -0.1104]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.0000, -6.4688, -5.0625,  ...,  6.7500, -6.6250,  8.3750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.2969, -3.1406, -3.8281,  ...,  2.7031, -3.3438, -4.7500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.2813213, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01471033199049998, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1206, -0.0952,  0.0859,  ..., -0.0371, -0.0078, -0.0679]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0118, -0.0977, -0.0192,  ...,  0.1309,  0.0728, -0.0084]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -5.4688,  -4.5000, -13.4375,  ...,   3.9844,   4.2812,  -1.0078]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.7734,  2.1719, -1.7812,  ..., -1.6406, -3.7969, -0.5039]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.3048458, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.014786053987336345, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0003, -0.0223,  0.0947,  ...,  0.0269, -0.0747, -0.0737]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3613,  0.1030, -0.0625,  ..., -0.1992,  0.2031, -0.1035]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-0.0586, -6.8750, -6.1250,  ...,  5.6250,  0.3320,  4.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8047,  0.8359, -5.6562,  ...,  0.3066, -0.9727, -2.5938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or \", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.3287392, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.014863589982269332, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0347,  0.0820,  0.1069,  ..., -0.0928,  0.0327, -0.0038]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1738,  0.0022,  0.0209,  ...,  0.0398,  0.0645, -0.0483]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.7812, -1.9922, -1.1094,  ...,  6.5312,  1.7344,  9.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.0781, -3.3438, -4.0312,  ...,  4.5000, -3.0156, -7.3438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.3523507, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.014939011991373263, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0101, -0.0310,  0.0374,  ..., -0.0248,  0.0588, -0.0972]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0243,  0.0483,  0.0471,  ..., -0.0439,  0.0703,  0.0225]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -2.0625,   6.8438, -10.1875,  ...,  -0.8438,   3.7188,  -2.4062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.1406,  0.7656, -3.4219,  ..., -1.2422, -1.2422, -1.1016]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.3761096, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.015015144992503338, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0261,  0.0211, -0.1226,  ..., -0.0240, -0.0713,  0.0182]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0050, -0.2812,  0.1089,  ..., -0.0972,  0.0781, -0.1187]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.2500,  0.4727, -2.5312,  ..., -1.2188, -0.5625,  6.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.3516,  0.4043, -0.8906,  ..., -0.1191, -0.8672, -0.2051]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements,\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.399911, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01509085699217394, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0278, -0.0342,  0.0014,  ..., -0.0276,  0.0496, -0.0293]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1079, -0.1396, -0.1138,  ..., -0.0674,  0.1187,  0.1035]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -6.9375,  -0.2773, -11.5000,  ...,   2.4688,   1.2812,   2.9062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.3906, -1.2109, -1.4766,  ..., -1.2891, -1.7969, -0.3984]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.4238496, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01516660898050759, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0513, -0.0189,  0.0771,  ..., -0.1338,  0.0918, -0.0203]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0216, -0.0508,  0.0908,  ..., -0.0728,  0.0117, -0.1025]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.8125,  4.5000, -5.0312,  ...,  6.4375, -9.1875,  5.5938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.3672,  2.1562, -1.0000,  ..., -0.2090, -1.4219, -0.9297]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.447839, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.015242871988448314, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1572,  0.1162, -0.0645,  ..., -0.1660, -0.0317, -0.1357]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1641,  0.1406, -0.1719,  ..., -0.0454, -0.1738,  0.2109]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 5.5000, -3.0469, -4.2188,  ...,  2.9375, -0.7891,  6.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8984, -0.5781, -2.2812,  ...,  0.1367, -1.4531,  0.8008]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.4717636, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01531955599784851, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1914, -0.1011, -0.1113,  ...,  0.0991,  0.0027, -0.1240]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0552, -0.1060, -0.5508,  ...,  0.0635,  0.0010,  0.0469]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 2.3438, -2.7188, -1.6328,  ...,  7.4375,  3.2500, -4.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.2344, -2.0469,  2.9688,  ...,  0.8750, -2.1562,  1.2812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.4957435, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.015406098988023587, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0269, -0.1162, -0.1279,  ...,  0.0317, -0.1875, -0.1064]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0293, -0.1211, -0.0554,  ...,  0.1406,  0.2188, -0.1523]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.7578, -2.2812,  0.6836,  ...,  7.8750,  2.4688, 10.3750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0112,  1.1562, -0.7539,  ..., -0.9805, -0.2441, -0.6641]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted,\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.5194519, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.015483944982406683, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0141,  0.0535,  0.0339,  ..., -0.0366, -0.0325,  0.0173]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1172, -0.0762, -0.0684,  ..., -0.0806,  0.0957,  0.0115]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.1211, -1.9531, -8.0000,  ...,  1.2344,  2.8750,  4.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.9023, -1.3594, -0.9531,  ..., -0.7734, -0.1602,  0.6719]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.5434983, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.015561910986434668, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0322, -0.1309, -0.0139,  ..., -0.0581,  0.0099, -0.1055]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1641, -0.2734,  0.0684,  ...,  0.0596,  0.1787, -0.0060]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.4062, -1.1562, -9.0625,  ...,  3.8750,  3.9062,  3.1094]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.0156, -0.4707, -1.2812,  ..., -0.8672, -1.1406,  0.2773]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.567293, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.015638443976058625, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0188,  0.1138,  0.0850,  ..., -0.1377,  0.0322, -0.1367]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2520,  0.1572, -0.0991,  ..., -0.1289,  0.0278,  0.2969]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.4375, -6.1250, -9.9375,  ...,  1.0312,  2.4375,  3.7812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.1016, -0.0588,  0.0527,  ..., -1.7500, -1.3359, -0.3105]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.5911462, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.015721659976406954, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0077,  0.0459, -0.0118,  ..., -0.0659, -0.0806, -0.2021]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1426, -0.0532,  0.0776,  ...,  0.1230, -0.0698,  0.2178]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.3281,  3.4219, -5.5938,  ...,  5.5625,  5.3438,  4.0312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.6172, -0.6641, -0.2021,  ..., -2.3906, -2.0469,  0.1279]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.6150331, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01579852397844661, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.1191,  0.0542,  0.1016,  ..., -0.1846,  0.0723, -0.0129]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0747, -0.1455,  0.2461,  ...,  0.0588, -0.1235, -0.1367]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.3281, -0.8633, -4.4688,  ...,  1.4453,  3.3906,  0.9297]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8125,  1.3984,  0.3125,  ..., -0.9062,  0.1221,  0.5781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.6389887, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01587480698071886, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0173,  0.0708,  0.1211,  ..., -0.1484,  0.1162, -0.0903]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0771, -0.1157,  0.1953,  ..., -0.1377,  0.0723,  0.1230]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.7812, -4.4375, -2.1562,  ...,  6.6562, -0.9141,  6.8125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.9219, -0.9570, -1.7344,  ..., -1.8203, -2.6250, -0.8633]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.6629136, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.015951149980537593, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0850, -0.0009, -0.0737,  ..., -0.1514, -0.0610, -0.0405]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0879,  0.2793,  0.0630,  ..., -0.1895, -0.2021,  0.0825]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.2188,  0.3945, -3.0938,  ...,  2.2344, -3.7969,  5.0312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.5625,  1.5625,  1.1328,  ..., -0.0088, -1.0703, -1.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.6866353, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01602773298509419, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0723,  0.0090,  0.0737,  ...,  0.0391,  0.0654, -0.0388]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0574, -0.1436, -0.0649,  ..., -0.0208,  0.1611,  0.1089]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.5625,  -2.4688,  -3.0938,  ...,   0.9219,   1.3750,   5.2812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.5859, -4.1562, -1.2500,  ...,  4.5000, -0.2578, -2.6875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.710387, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01610456699563656, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0266,  0.0045,  0.0518,  ..., -0.0148,  0.0019, -0.1719]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0894,  0.1138,  0.0718,  ...,  0.1289,  0.0859, -0.0518]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.8125,   0.9531,  -4.1250,  ...,   0.9219,  -3.6875,   6.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 3.9844,  0.0894, -7.2500,  ..., -0.4375,  4.9062, -4.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2.\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.7339618, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.016180809994693846, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1006,  0.0017,  0.1025,  ..., -0.0459, -0.0135, -0.0295]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1152,  0.2754, -0.0388,  ...,  0.0559, -0.0698,  0.0708]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.0625,  -2.8906,  -6.7812,  ...,  -3.7812,  -1.4062,  -0.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.1406, -3.1094, -4.5938,  ..., -0.9844,  1.0312, -3.4219]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.757817, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.016257894996670075, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0034,  0.0786,  0.1689,  ...,  0.0786,  0.0271, -0.2148]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2578,  0.1660, -0.1406,  ...,  0.0938, -0.2793,  0.3398]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.6250,   0.9727,  -1.7734,  ...,   2.2969,  -0.9453,  -3.4062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-5.0625, -1.7578, -0.1875,  ...,  6.3125,  4.4688, -3.3281]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **P\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.7817078, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01633502999902703, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1592, -0.1045,  0.1914,  ...,  0.1543,  0.0072, -0.0459]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0442, -0.2314,  0.0262,  ..., -0.1484,  0.0781, -0.0427]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-13.4375,  -2.7188,  -0.3203,  ...,   7.5000,  -6.2500,  -6.0312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ -4.5312,   1.7891,  -1.7266,  ..., -10.5000,  -3.0938, -15.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.8055007, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01640984100231435, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1104,  0.0806,  0.0972,  ..., -0.2891,  0.0352, -0.1299]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0952, -0.1650,  0.1279,  ..., -0.1621, -0.1299, -0.0289]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.4375,  -0.2422,  -6.0938,  ...,   4.4062,   3.4531,  -5.4062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.1094, -2.4375, -1.1406,  ...,  5.7500,  1.4062, -1.7734]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.8295515, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.016484481006045826, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0116,  0.0306,  0.1143,  ..., -0.0610,  0.0164, -0.2617]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1416,  0.0972,  0.0184,  ...,  0.1934,  0.2773, -0.0786]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.5625,   1.0469,   1.1875,  ...,   2.9844,   3.7188,   1.7578]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.9141,  1.2031, -2.3438,  ...,  2.6406, -0.5547, -2.5781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**:\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.853532, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01655992300948128, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0503, -0.1465, -0.0308,  ...,  0.2178,  0.0996, -0.1572]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1357,  0.0579, -0.1670,  ...,  0.0228,  0.1465,  0.0664]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -5.8125,  -6.3438, -10.8750,  ...,   3.7500,   3.7500,   2.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.9297, -4.3750, -0.3203,  ...,  1.2969,  0.5586,  0.6523]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.8773386, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01664615501067601, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0649, -0.0378,  0.0535,  ..., -0.0884, -0.0205, -0.0630]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3613,  0.3379,  0.2461,  ..., -0.0028, -0.0038,  0.3809]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -4.7812,  -2.4688, -14.8125,  ...,   2.7656,   0.5195,  -1.7969]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.4531, -3.0156, -0.0547,  ...,  2.9531, -2.8125,  0.2393]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.90117, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.016723279011785053, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.1084,  0.0352, -0.0210,  ...,  0.1123,  0.0635, -0.1006]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0603, -0.3633,  0.1553,  ...,  0.4434,  0.0547, -0.1152]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.7188,  2.9062, -6.3438,  ...,  8.7500,  4.8438,  5.4688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.5938, -1.0625, -0.1299,  ..., -2.4844, -4.2500, -1.8828]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.924937, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.016799632998299785, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0317,  0.0398,  0.0200,  ..., -0.1328,  0.0103, -0.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0413, -0.1011,  0.2266,  ..., -0.1475, -0.0757, -0.0381]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.2500, -7.1250,  6.2500,  ...,  3.6250,  1.5625, -0.9844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4023, -0.8906, -1.0938,  ..., -1.4141, -3.2344, -1.0156]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.9485116, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.016875174987944774, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0276, -0.1035,  0.0542,  ..., -0.1592, -0.0403, -0.0422]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0532, -0.0732,  0.1030,  ..., -0.0496, -0.0403,  0.0306]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.6875,  3.3438,  4.6875,  ..., -5.4688, -5.0312,  1.7109]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2734, -1.3203,  0.6953,  ..., -1.2891, -0.5430, -0.0298]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.9724045, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.016957398984231986, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0055,  0.1250, -0.0396,  ..., -0.0474,  0.0518, -0.0264]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0449, -0.3613,  0.1152,  ...,  0.0118,  0.0014, -0.1406]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.5625, -1.9688,  0.4434,  ..., -1.9141, -5.7500, -0.4141]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8398, -0.8984, -0.0801,  ..., -0.2930, -0.8047, -0.4688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element.\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.9962132, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01703430397901684, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0369,  0.0596,  0.0466,  ..., -0.0334,  0.0879, -0.0884]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1025, -0.0767,  0.0381,  ...,  0.0045,  0.0075, -0.0134]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.5312, -9.0000, -9.7500,  ...,  4.1562, -0.4980,  5.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.8906, -2.0781, -1.8203,  ...,  2.1406, -1.6016, -0.6523]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.020097, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.017112690984504297, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1201, -0.0488,  0.0227,  ...,  0.0605, -0.1045, -0.1787]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0009,  0.1328, -0.0374,  ..., -0.1084, -0.1436,  0.2109]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.9375, -1.6250, -6.7188,  ...,  1.1172,  4.1250,  5.2188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3203, -1.3516,  0.4414,  ..., -1.8438, -0.3555,  0.0864]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.0441368, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.017188803991302848, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.1206,  0.0879,  0.1777,  ...,  0.2520,  0.0791, -0.0127]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0209, -0.1680, -0.3281,  ...,  0.3242,  0.1709, -0.1299]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.2812,  3.2812, -3.3125,  ...,  7.8125,  2.1562, -1.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.9883, -1.0469, -1.6328,  ..., -2.1406,  1.2188, -0.9570]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.0680163, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.017264886992052197, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1553,  0.1738,  0.0493,  ...,  0.0033,  0.0309, -0.0090]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2676, -0.1807,  0.4961,  ..., -0.4355,  0.0439,  0.2109]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -5.7812,   1.0938, -10.5000,  ...,   1.2422,   5.0938,   8.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.9375, -0.0198, -0.1777,  ...,  0.1201, -0.3965, -1.3047]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation,\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.0921693, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01733998798590619, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0110,  0.0265,  0.0586,  ..., -0.0178, -0.0039, -0.1064]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0830, -0.1318, -0.0515,  ..., -0.0718, -0.0056,  0.1367]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -8.5000,  -2.0625, -14.3750,  ...,   1.6875,   7.1875,   6.8125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.4531, -0.7930,  0.4805,  ..., -0.2480, -1.6953,  0.3496]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.1169484, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.017415298978448845, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0325,  0.0486,  0.0074,  ..., -0.0444,  0.0198, -0.1162]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2383,  0.1143, -0.0037,  ..., -0.0432,  0.0498,  0.1572]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -9.3750,  -5.7188, -12.8750,  ...,   5.8125,   1.0938,   0.1416]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2539, -1.8984, -0.6133,  ...,  1.8594, -2.9375, -0.0146]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.140981, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.017491681981482543, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-7.9102e-02,  1.9775e-02, -8.5449e-02,  ...,  3.3691e-02,\n",
      "          1.8311e-04, -2.2656e-01]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0393, -0.0869,  0.2598,  ...,  0.2832, -0.0684, -0.2178]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.4629, -3.6250, -3.5625,  ...,  5.6250,  7.8125,  0.6016]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.3906, -0.4473, -0.5391,  ..., -3.6875, -3.6250, -0.2773]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.16469, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01756683297571726, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0004,  0.0503,  0.0476,  ..., -0.1084, -0.0118, -0.1494]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0938, -0.0091,  0.2656,  ..., -0.1836, -0.0121, -0.0781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.2969, -6.7812,  8.3125,  ...,  3.5469,  3.0156, -1.5938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.7031, -0.4258, -1.5625,  ..., -2.8281, -2.2188, -0.8984]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.1886737, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01764621197071392, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0067,  0.0164, -0.0167,  ...,  0.1787, -0.1172, -0.0510]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2832,  0.1182,  0.2695,  ...,  0.0049,  0.1641,  0.0488]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.3125,  7.7188, -0.5859,  ...,  2.6250,  4.3125, -0.1074]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.0859,  0.4492, -1.6094,  ..., -1.1328,  0.5703, -2.1719]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.2127016, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01772269597859122, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0977, -0.0532, -0.0732,  ...,  0.0471, -0.0479, -0.0801]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0481, -0.3965,  0.1592,  ...,  0.0150,  0.0457, -0.0879]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.6250,  7.0625, -2.7031,  ..., -1.6250,  2.4688,  2.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2363,  0.6016, -0.1279,  ..., -0.8594, -0.7422, -0.9219]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.2365334, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.017797695982153527, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1367, -0.1367, -0.0420,  ...,  0.0317, -0.0620, -0.2275]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1943, -0.4434,  0.1079,  ..., -0.0645, -0.3047,  0.0889]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.2500,  1.2812,  5.0938,  ...,  3.2500,  3.6562,  2.5156]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2578,  0.1650, -1.1484,  ..., -2.7656, -3.5625, -1.3750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.2605164, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01788672296970617, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0234,  0.0444,  0.0315,  ..., -0.0344,  0.0238, -0.1455]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1338,  0.0315, -0.0210,  ..., -0.1494, -0.0040, -0.1299]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.5625,  4.3438, 13.4375,  ...,  4.6875,  6.9375,  2.6094]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.9180, -3.2812, -1.6875,  ..., -1.1094,  0.7500, -0.1885]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.2845273, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.017961563979042694, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0615, -0.0332,  0.0010,  ..., -0.0598, -0.0483, -0.1240]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0491,  0.0645,  0.0664,  ...,  0.0209, -0.0654,  0.0645]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.9062,  2.6875, -2.2812,  ...,  3.2344, -1.3438,  2.4844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4258,  0.9688,  0.1523,  ..., -0.1001, -1.3672, -0.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.3085294, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01803781697526574, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0664,  0.0361,  0.0874,  ...,  0.0618,  0.0825, -0.0684]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1133, -0.1406, -0.0708,  ..., -0.0840,  0.1543,  0.0776]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-5.5000, -1.2812, -1.9219,  ..., -8.1250,  1.9844, 11.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.3281, -1.1406, -0.6992,  ...,  1.5859, -1.7344, -0.9688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.3324354, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.018113538972102106, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0137, -0.0452,  0.0129,  ..., -0.0325, -0.0408, -0.2197]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1279, -0.0239,  0.0718,  ...,  0.0339,  0.0354,  0.0103]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.2812, -1.7422,  0.3008,  ...,  2.4688, 10.5000,  2.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 3.7344,  1.4375, -7.6250,  ..., -2.0625,  5.4062, -1.9141]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3.\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.3562615, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01818868998088874, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0713,  0.0087,  0.0430,  ..., -0.0513,  0.0073, -0.0825]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0825,  0.3750,  0.0073,  ...,  0.0231, -0.0840,  0.1143]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-5.8125, -2.3125, -5.9375,  ..., -9.3125,  9.5625, -0.9453]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.8906,  0.5859, -5.6875,  ..., -0.9180,  2.0156, -0.4336]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.3800995, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01827319797303062, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0376,  0.0996,  0.1855,  ...,  0.0708,  0.0593, -0.2100]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2598,  0.1699, -0.1650,  ...,  0.1270, -0.2793,  0.3594]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.7969,  0.0234, -2.9219,  ...,  3.3125, 16.0000, -0.2656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.8906,  1.1719, -5.0312,  ...,  4.3125,  1.9844,  2.7344]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partition\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.4042516, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.018351414968492463, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0674, -0.0062,  0.0330,  ..., -0.1865,  0.0479, -0.1641]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1167, -0.0483,  0.1338,  ..., -0.0947, -0.0889,  0.0806]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.0000, -2.9531, -3.1562,  ...,  9.2500, -2.9062, -3.7969]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.0781, -1.2969, -2.5000,  ...,  0.6875,  0.8281, -2.6562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.4281778, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.018432115961331874, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1777,  0.1084,  0.0554,  ..., -0.2412,  0.0254, -0.2910]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0229, -0.0291,  0.0012,  ..., -0.2773,  0.0286,  0.0747]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.9375,  2.6875, -0.3828,  ...,  8.3750, -2.1562,  2.9062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.0469,  0.2637, -5.5312,  ...,  0.6641,  0.2773, -0.9180]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**:\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.4523246, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01850752795871813, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0586, -0.1738, -0.0016,  ...,  0.2344,  0.0986, -0.2012]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0820,  0.1006, -0.1426,  ...,  0.0270,  0.1299,  0.0918]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.4941, -4.0938, -5.7500,  ..., -7.7188, 11.5000,  0.5273]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.6016, -0.7578, -0.7656,  ...,  0.4375, -0.5234, -0.6094]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.476308, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.018583891956950538, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0288, -0.0525,  0.0801,  ..., -0.0664, -0.0182, -0.0659]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3770,  0.3809,  0.2256,  ...,  0.0265,  0.0229,  0.4004]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 4.9375, -1.3047, -3.3594,  ..., -5.6875,  8.7500, -0.1475]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0747, -0.2207, -1.7266,  ...,  2.3125, -1.2734, -1.4844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.5002928, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01866809994680807, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0000,  0.0908, -0.0277,  ..., -0.0100, -0.1338, -0.1641]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4570, -0.1963, -0.0123,  ..., -0.5742, -0.2402, -0.0295]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 5.1250, -0.8906, 14.8750,  ..., -4.2500,  1.9297, 11.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.0469,  0.0723,  1.0234,  ..., -0.2012, -4.4062, -0.5742]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.5241387, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.018750473944237456, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0452,  0.0732,  0.1357,  ..., -0.0630,  0.0679, -0.1689]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0552, -0.1055, -0.0835,  ...,  0.0432,  0.0554, -0.0304]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.7812, -2.7812, 14.1875,  ...,  1.0312, -3.7812,  4.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.9297,  2.4531, -0.0752,  ...,  0.5547, -2.3750,  0.8086]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.5482304, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.018827267951564863, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0203,  0.0864,  0.1592,  ..., -0.0791, -0.0449, -0.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0967,  0.0938,  0.1826,  ...,  0.1206,  0.1040, -0.0142]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 5.7500, -4.6562,  4.1562,  ...,  8.3750,  2.0625, -1.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.3457,  0.9961,  8.0000,  ..., -5.5625, -4.2812,  3.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.5721982, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.018904953947640024, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0044, -0.0996, -0.0099,  ..., -0.0967,  0.0081, -0.0159]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0359, -0.1084,  0.0522,  ...,  0.1660,  0.2256, -0.0364]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 3.0938, -3.8125,  1.9375,  ...,  2.6562,  1.3750,  0.6719]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.5156, -3.5156, -2.2500,  ..., -4.5625, -0.5234, -2.4531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.5962863, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01898188894847408, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0845, -0.0160, -0.0090,  ..., -0.1011, -0.0762,  0.0330]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1895, -0.0023, -0.0085,  ..., -0.0269, -0.0820, -0.1133]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 4.9062, -1.1953,  4.1250,  ...,  2.4844, -1.4844,  9.7500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.9219,  0.8789,  0.4473,  ..., -1.8516, -1.1875, -1.5234]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.6203156, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.019067449946305715, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0020,  0.0603,  0.0977,  ...,  0.1147, -0.0261, -0.0889]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0542, -0.1138, -0.1348,  ..., -0.0933,  0.0277,  0.0659]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-0.0469, 10.5000,  3.9531,  ..., -7.4375,  4.5000, 13.9375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.3594, -4.9688, -1.2891,  ...,  0.2070,  0.0299, -2.7344]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n  \", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.6440723, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.019154643945512362, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1035,  0.0688, -0.0112,  ...,  0.1826,  0.0262, -0.0474]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1147, -0.2236,  0.3105,  ..., -0.0029, -0.0605,  0.0349]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.6875,  2.4219,  0.3203,  ..., -5.7500,  4.7500, 13.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.5000, -2.3438, -4.2188,  ..., -0.9297, -0.0762, -0.8984]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   -\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.667959, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.019230214951676317, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1030,  0.0015,  0.0364,  ...,  0.1953,  0.1299, -0.0264]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0938, -0.1533,  0.0669,  ...,  0.0383, -0.0513,  0.3223]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.6406, -3.8906,  1.3906,  ..., -1.0547,  8.4375,  6.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.1016, -1.8125, -3.5938,  ..., -1.7188, -2.4531,  0.0977]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.6918857, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.019307849943288602, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0049,  0.0630,  0.0227,  ...,  0.1074, -0.0233,  0.0045]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0093, -0.1865,  0.0781,  ..., -0.1445, -0.3105, -0.0099]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-5.0000,  0.5547,  7.2500,  ...,  0.4766, 10.7500,  4.7188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.7188,  1.3281, -0.2812,  ..., -3.4531, -3.2656, -1.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.7158477, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.019383822931558825, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1040,  0.1006,  0.0201,  ..., -0.1079, -0.0879, -0.1035]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2656,  0.2051, -0.0781,  ..., -0.0830, -0.2617,  0.3105]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-15.1875,  -1.3125,  -1.0312,  ...,   6.5312,  -1.0156,  10.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.7148,  0.9297, -2.4375,  ...,  0.2070,  2.5469, -1.5234]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`:\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.739749, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.019459294926491566, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0283, -0.1279,  0.0229,  ...,  0.1670,  0.2539, -0.1328]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2373,  0.2275, -0.2598,  ...,  0.0791,  0.4648, -0.1914]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.1641,  0.5078, -5.5312,  ...,  2.0312,  5.9688, -1.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2520, -4.7812, -0.1475,  ..., -0.0248, -2.3594,  0.2188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.7637627, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.019534826918970793, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0320, -0.0063,  0.0215,  ..., -0.1904,  0.0610, -0.1504]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2188,  0.0287,  0.0013,  ..., -0.0591, -0.1494,  0.3262]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.9062,  9.0625, -4.4062,  ...,  1.0781,  2.1875,  0.3516]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2539, -0.9375,  1.0781,  ...,  0.5234, -1.4297, -2.2344]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.787863, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.019610598916187882, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0366,  0.0386, -0.1582,  ..., -0.0640, -0.0874,  0.0430]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0830, -0.4863,  0.0315,  ..., -0.0464,  0.0864,  0.1514]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 2.1562,  1.0859, -1.6016,  ..., -4.0625, -6.5938,  4.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.5430,  0.6211,  1.4062,  ...,  1.5469, -1.6953, -1.7109]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.811661, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01968670092173852, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0256, -0.0107, -0.0942,  ..., -0.0193, -0.0305, -0.0972]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2598, -0.1963, -0.0009,  ..., -0.0879, -0.1514,  0.2188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.1250, -1.9453, -1.9297,  ..., -1.7891, -5.7500,  4.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.8438, -0.7031, -1.7500,  ..., -0.0352, -5.8750, -0.7070]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.8356454, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.019765949924476445, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0108,  0.1035, -0.1143,  ...,  0.0776,  0.0947, -0.1816]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4277, -0.3965, -0.4316,  ..., -0.5039,  0.2832,  0.2949]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.7500, -2.1094, -5.4375,  ...,  2.7188,  0.1758,  6.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.3750, -0.9219, -1.7969,  ..., -1.5000, -4.1562, -1.0547]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.8596034, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.019841952933347784, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0269,  0.1021,  0.0598,  ..., -0.0559, -0.0359, -0.1377]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0459,  0.2715,  0.0620,  ..., -0.2275, -0.0010, -0.1201]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.3750,  2.5938,  0.6172,  ...,  3.0469, -9.4375,  6.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0623, -1.4688, -0.4082,  ..., -0.4336, -3.8125, -5.7812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.883619, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.019918856938602403, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0179, -0.0967,  0.0334,  ..., -0.1104, -0.0106, -0.0216]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0801, -0.0825,  0.1094,  ..., -0.0613, -0.0388,  0.0547]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.7188,  2.0312,  1.1406,  ..., -0.3984, -3.1406,  1.8828]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.5156,  0.7344, -0.9688,  ..., -0.5859, -1.1094, -1.1953]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.9076712, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01999412894656416, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0493,  0.0996,  0.0884,  ...,  0.0610,  0.1187, -0.0549]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1396, -0.1089, -0.0498,  ..., -0.1221,  0.1475,  0.0547]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.1602,  0.8047,  4.1875,  ..., -5.5625,  5.9062,  6.4062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.2734, -1.8594, -2.2500,  ...,  4.3438, -0.5273, -4.0000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n  \", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.9315984, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02007041194883641, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0820,  0.0581, -0.0192,  ...,  0.1689, -0.0243, -0.0618]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0435, -0.1035,  0.2832,  ..., -0.0133, -0.0172,  0.0304]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.6250, -1.5469,  3.3125,  ..., -2.9375,  8.4375,  3.0781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.6016, -0.9688, -4.5625,  ...,  3.0469,  0.4922,  0.3164]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   -\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.9555387, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.020146003953414038, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0184,  0.0576,  0.0488,  ...,  0.1357,  0.1445, -0.0684]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1816,  0.0708,  0.0292,  ..., -0.0081, -0.0747,  0.2969]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.2656, -2.2812,  4.0312,  ..., -0.4219,  3.1719,  6.4688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.7734, -0.6523, -5.7188,  ..., -1.2578, -3.4844, -1.3750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.9797988, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02022133495484013, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0088,  0.1011,  0.0635,  ...,  0.0703, -0.0100,  0.0129]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0046, -0.0630,  0.0552,  ..., -0.1025, -0.2969, -0.0017]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.1367,  2.6094, 15.4375,  ...,  0.9375,  4.5625,  0.0801]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-6.1562, -0.6055,  0.3633,  ..., -2.8438,  2.8125, -3.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.0037255, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.020297066948842257, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.1089, -0.0037,  0.0791,  ...,  0.1123,  0.0044, -0.0669]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4355,  0.2129,  0.2158,  ...,  0.1338,  0.0781,  0.2275]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-13.4375,   0.8125,  -0.7891,  ...,   4.3125,  -3.3750,   7.2188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.5625, -1.4297, -3.7969,  ...,  3.9531,  1.4922, -3.2344]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`:\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.0271833, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02038414095295593, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.1108, -0.1348,  0.0815,  ...,  0.2070,  0.2148, -0.1279]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2109,  0.2109, -0.2422,  ...,  0.1631,  0.3809, -0.1206]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.5625, -3.9531, -6.4375,  ..., -7.4375,  8.3750, -1.8125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-4.5938, -2.8125, -5.0000,  ..., -2.9531, -1.1875,  0.3926]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.0510242, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.020463810957153328, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0092, -0.0317,  0.0583,  ..., -0.1348, -0.0233, -0.1348]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.3535e-01,  1.6309e-01,  1.4404e-02,  ...,  2.8229e-04,\n",
      "         -7.5195e-02,  3.5156e-01]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.6562,  6.8438, -4.5625,  ..., -3.2500,  0.8398, -3.2812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8008, -1.4219, -0.6758,  ..., -0.5703, -2.2344, -3.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.074739, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.020538760960334912, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0757,  0.0076, -0.1113,  ..., -0.0791, -0.1260,  0.0435]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1099, -0.4238,  0.0476,  ..., -0.0148,  0.1025,  0.1426]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 5.5625,  2.6875, -1.9922,  ..., -2.9688, -9.7500,  2.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.8906, -1.0156, -1.2500,  ..., -1.6953, -0.6523, -1.7344]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.0985084, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.020614121967810206, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0874,  0.1826, -0.0272,  ..., -0.0825,  0.0635, -0.1523]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1416, -0.3398, -0.0928,  ..., -0.2490,  0.2695,  0.1152]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.7500,  0.8516, -1.3516,  ..., -3.6562,  3.3438, -1.0781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.8594,  1.8672,  0.5273,  ..., -1.7891, -4.6562,  0.9531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.1223266, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.020691206969786435, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0562, -0.1367,  0.0801,  ...,  0.0052, -0.0342, -0.0116]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.3691, -0.2617, -0.0028,  ..., -0.6445,  0.4414, -0.1475]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.2969,  0.5078, -6.2812,  ..., -1.6094, -2.2500,  6.7500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.7031, -0.4473, -1.3984,  ..., -0.8203, -5.2500, -1.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.1462052, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02076785996905528, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0728,  0.0835, -0.0132,  ..., -0.0593,  0.0461, -0.1050]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0378,  0.0830,  0.1182,  ..., -0.1172, -0.0510, -0.1318]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.1250,  3.4062,  0.8828,  ...,  2.6719, -9.5625, -1.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.6250,  0.2910, -0.1416,  ..., -0.6094, -4.1250, -9.0000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.170079, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02084794096299447, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0679, -0.0996,  0.0063,  ..., -0.1074, -0.0055, -0.0103]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0889, -0.1094,  0.1235,  ..., -0.0281, -0.0374,  0.0220]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.0234,  1.8281, -3.8438,  ...,  0.4961,  2.6094,  3.8906]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.0938,  1.5234,  0.2988,  ...,  0.8906, -2.2188, -1.4531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.194051, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02092432497011032, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0591,  0.0962,  0.0542,  ...,  0.0654,  0.1279, -0.0684]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1309, -0.1147, -0.0481,  ..., -0.1299,  0.1475,  0.0476]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.2832,  3.6250,  3.0156,  ..., -5.3750,  0.8555,  7.9375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0952, -1.8359, -2.5625,  ...,  2.9844, -0.7188, -3.2656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n  \", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.2182217, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.021000016975449398, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0811,  0.0557, -0.0396,  ...,  0.1719, -0.0134, -0.0864]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0476, -0.0801,  0.2949,  ..., -0.0127, -0.0183,  0.0654]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.9062, -0.4648,  1.7734,  ..., -7.5625,  4.2500,  3.0781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3906, -1.5234, -3.2656,  ...,  1.3125, -1.9766, -0.9883]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   -\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.2419372, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.021076640972751193, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0240,  0.0591,  0.0352,  ...,  0.1338,  0.1621, -0.0757]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1943,  0.0967,  0.0371,  ..., -0.0011, -0.0679,  0.3086]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.6562, -1.6406,  3.1562,  ..., -4.3438, -0.5664,  4.9375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.9922, -0.3398, -4.8750,  ..., -0.3789, -2.7031, -2.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.2661002, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.021155678972718306, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0201,  0.1074,  0.0544,  ...,  0.0684, -0.0049,  0.0060]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0099, -0.0530,  0.0518,  ..., -0.0972, -0.3008,  0.0099]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.6562,  3.1094, 10.3125,  ..., -3.0625,  3.4219,  4.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.5625,  2.0469,  2.4219,  ..., -0.5039,  0.5352, -0.9766]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.2900207, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.021232252969639376, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0177,  0.1099, -0.0228,  ..., -0.0127,  0.0449, -0.1758]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2617,  0.3340, -0.0825,  ..., -0.0762,  0.1069,  0.1182]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-14.6875,   0.8594,   0.2656,  ...,   3.7188,  -2.8906,   9.6875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-4.2500, -0.5898, -3.4688,  ...,  6.4375,  0.2637, -1.4062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`:\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.3138812, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.021309557967470028, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0583, -0.1504,  0.0698,  ...,  0.1807,  0.2637, -0.1279]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2285,  0.3379, -0.1128,  ...,  0.1641,  0.4746, -0.1865]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -5.1875,  -6.6250,  -3.8125,  ..., -10.6250,   4.3438,   2.7344]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-4.8750,  1.2500, -3.9062,  ..., -3.2812, -3.2969, -0.3594]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.337891, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.021386050968430936, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0503, -0.0125,  0.0413,  ..., -0.1738,  0.0317, -0.1221]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1924,  0.1670,  0.0142,  ..., -0.0182, -0.1040,  0.3535]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.8281,  8.8750, -6.1562,  ..., -3.9531, -0.5859, -3.5781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.7305, -1.0938, -0.0923,  ...,  0.3867, -3.8750, -6.5938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.3617632, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.021461141965119168, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0767,  0.0488, -0.1123,  ..., -0.0542, -0.1104,  0.0601]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1216, -0.4004,  0.0466,  ..., -0.0398,  0.0669,  0.1611]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 5.5000,  0.1562, -0.9375,  ..., -1.1250, -3.3438, -4.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.6445, -0.6289, -0.6719,  ...,  2.7500, -3.9062, -1.5078]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.385884, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.021536512969760224, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0476, -0.0083, -0.0206,  ...,  0.0337,  0.0330, -0.0820]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1113, -0.2695,  0.2520,  ..., -0.1514, -0.1641, -0.2148]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.9375, -1.5078, -4.0938,  ..., -4.0625, -0.9766,  1.7812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.8984,  1.3359, -0.3555,  ...,  0.5273, -5.8438, -1.1406]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.4098966, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.021621641964884475, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0439,  0.1162, -0.1611,  ...,  0.1553, -0.0198, -0.0388]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0479, -0.3574, -0.2393,  ..., -0.4551,  0.2305,  0.1709]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.0547,  2.3750, -6.9688,  ..., -0.2451, -1.1641,  4.8125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2070,  0.0146, -1.1016,  ..., -0.5078, -4.4688, -1.2578]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.4337566, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02169841597788036, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0096,  0.0928,  0.0532,  ..., -0.0352, -0.0603, -0.1367]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0747,  0.2539,  0.0547,  ..., -0.2246, -0.0118, -0.1592]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.2344,  0.9102,  1.1641,  ...,  4.9688, -7.7188,  0.0234]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.7109,  0.4922,  0.6758,  ...,  0.8125, -4.3750, -8.9375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.4574835, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.021775971981696784, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0310, -0.1074,  0.0457,  ..., -0.1035, -0.0216, -0.0327]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1094, -0.1147,  0.1221,  ..., -0.0488, -0.0317,  0.0396]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.4375,  1.6562, -1.2969,  ...,  2.7500,  7.8750,  5.9062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.8047,  1.9766,  1.8984,  ...,  0.1162, -1.0703, -1.9297]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.4813144, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02185449897660874, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0571,  0.0879,  0.0674,  ...,  0.0613,  0.1318, -0.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1416, -0.1089, -0.0486,  ..., -0.1436,  0.1602,  0.0242]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.9688, -1.1641,  1.2031,  ..., -3.5312, -1.1172,  9.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.5859,  0.6172,  1.9609,  ...,  0.7109, -1.3047, -1.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.505211, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.021931943978415802, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0298,  0.0806, -0.0190,  ..., -0.0532, -0.0679, -0.2217]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0923,  0.1465,  0.0035,  ..., -0.0111,  0.0613,  0.0376]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.9375, -0.8984, -6.1875,  ..., -0.8555,  4.3438, -0.5508]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.5938, -0.1982, -6.1562,  ..., -1.6562,  5.1875, -3.0469]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4.\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.5290442, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02200933897984214, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0317,  0.0090,  0.0820,  ..., -0.0247, -0.0322, -0.0364]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0981,  0.3613, -0.0027,  ..., -0.0017, -0.0884,  0.1611]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.7812, -6.6875, -4.5938,  ..., -6.1875,  2.6406, -3.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.3125, -1.0156, -2.7812,  ..., -0.8555,  0.5039, -3.0000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.5530927, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02208511198114138, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0219,  0.1196,  0.1914,  ...,  0.0708,  0.0515, -0.1689]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2676,  0.2188, -0.1709,  ...,  0.1270, -0.2500,  0.3555]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 5.3750, -6.7812, -4.3750,  ...,  6.4688,  7.1562, -1.3203]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-5.1250,  3.4375, -2.4062,  ...,  3.8906,  2.7344,  1.9141]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.5768108, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02216170498286374, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0273, -0.0435, -0.0129,  ..., -0.1904, -0.0874,  0.1006]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1162, -0.1562, -0.0962,  ..., -0.2451, -0.2393,  0.0747]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.7578,  0.7188, -3.1562,  ..., 14.0000,  0.2988,  0.3633]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.7656,  0.2451, -1.4531,  ...,  3.3438,  1.6406,  1.7578]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.6005602, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02223796797625255, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1016,  0.0618,  0.0422,  ..., -0.3457, -0.0297, -0.1973]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0466, -0.1904,  0.0972,  ..., -0.2559,  0.0410, -0.1895]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.7812, -2.6562,  0.5938,  ...,  7.1562, -0.2852,  1.1719]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.9023,  1.7812, -4.4375,  ...,  2.0156,  0.8711, -2.6562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**:\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.6245835, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02231399097945541, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0684, -0.1318, -0.0249,  ...,  0.2188,  0.1133, -0.1963]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1147,  0.1069, -0.1426,  ..., -0.0271,  0.1572,  0.1206]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -0.4453, -10.0000,  -0.7852,  ...,  -2.7031,   2.7500,  -4.0000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1201, -1.8281, -1.4688,  ..., -0.2656,  1.4062, -0.8945]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.6483202, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.022389732985175215, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0366, -0.0557,  0.0796,  ..., -0.0884, -0.0156, -0.0352]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3418,  0.3984,  0.2227,  ...,  0.0212,  0.0349,  0.3594]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[  1.6875,  -6.5312,   4.3438,  ...,  -3.2969,  -4.3438, -14.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.2188, -1.6797, -2.8125,  ...,  0.2754, -1.0312,  0.7148]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.671773, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0224688909802353, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0618, -0.1904,  0.0126,  ..., -0.1924, -0.1787,  0.0762]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1235, -0.2217, -0.2754,  ..., -0.2910, -0.1924,  0.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.2734, -2.5469, -3.1094,  ...,  0.8281,  4.1562, -2.7188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.2812, -1.3125, -3.1406,  ...,  0.6719, -1.9531, -2.2188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.6957066, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02254788897698745, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0737,  0.1338,  0.1182,  ...,  0.0132, -0.1328, -0.1699]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1299,  0.1406, -0.0437,  ...,  0.0251, -0.0630, -0.1416]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.5312,  2.5312, -7.5625,  ..., -0.4102,  2.2500, 11.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8633,  0.5078, -2.1875,  ..., -1.9922, -1.9297, -0.3242]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.7216597, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.022623710974585265, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0151,  0.1245, -0.0167,  ..., -0.1641, -0.0703, -0.1426]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0071, -0.0583,  0.3105,  ..., -0.1885, -0.0145,  0.0164]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 7.6875,  0.7734, -1.6406,  ...,  0.0518, -2.4219,  6.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2832,  1.8906, -2.0312,  ..., -0.7656, -1.4609, -0.8945]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.7474616, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.022700404966599308, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0112,  0.0879,  0.0106,  ...,  0.0201, -0.0186, -0.0293]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0009, -0.1143, -0.0466,  ..., -0.2598, -0.4375, -0.0032]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-0.2578, -0.5586,  0.5625,  ..., -0.3496,  6.4688,  6.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.4062,  2.8594, -1.3828,  ...,  0.0820,  2.7500, -2.7969]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.7714107, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02278236897836905, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.1631,  0.1108, -0.0266,  ...,  0.0109,  0.1299, -0.0459]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3555,  0.2988,  0.0099,  ..., -0.0869,  0.2178,  0.0167]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.7500,  -4.8750,  -2.1719,  ...,  -0.2520,  -7.7188,   3.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1670,  3.8438, -1.2500,  ...,  8.3750, -1.1094, -7.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.7952862, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.022872167974128388, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1348, -0.0510, -0.0762,  ..., -0.1108,  0.0150,  0.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0540,  0.1138, -0.0166,  ...,  0.0659, -0.0018, -0.1006]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-14.1250,  -6.8125, -10.3125,  ...,   4.0625,  -0.1602,   4.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.2969,  2.1094, -1.8906,  ..., -3.6250,  1.3828, -3.6406]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort`\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.8189988, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02295518397295382, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.2168,  0.0233,  0.0273,  ...,  0.0330,  0.1582, -0.0840]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0154, -0.3125, -0.1270,  ..., -0.3301,  0.0287, -0.1699]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.6406, -6.6875, -1.4062,  ...,  4.6250,  1.1406, -3.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4863, -0.5234, -0.2969,  ..., -2.0000,  1.8438,  0.7578]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.843355, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.023033269972074777, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0198,  0.1406,  0.0649,  ..., -0.0564, -0.0479, -0.1191]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2500, -0.1738,  0.0129,  ..., -0.2217, -0.0649, -0.0679]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 6.4688, -5.5938, -2.7500,  ...,  2.8750,  5.8125, -1.7656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.9688, -0.1621, -0.5000,  ..., -1.3047, -1.1484,  0.1211]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.8675199, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.023109141970053315, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0532,  0.0967, -0.0732,  ..., -0.0952,  0.0469, -0.1050]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2188, -0.0272, -0.2734,  ..., -0.0684,  0.1162, -0.3145]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 2.5938, -5.0000, -3.5781,  ...,  1.0469,  1.5859,  4.9062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.3984, -1.1328, -1.9375,  ..., -0.4355, -5.7188, -0.5664]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.8923392, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.023184363963082433, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0879,  0.1006,  0.0160,  ..., -0.1011,  0.0315, -0.1484]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0118,  0.0581,  0.1240,  ..., -0.1387, -0.0684, -0.0913]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.4336,  0.5938,  1.0938,  ...,  0.5352, -1.8516,  6.3438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1182, -1.1250, -2.1875,  ..., -1.5703, -2.4375, -0.8984]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.916582, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02326192996406462, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0195,  0.0835, -0.0437,  ...,  0.0781,  0.0073, -0.0752]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0061, -0.1631,  0.0096,  ..., -0.3008, -0.4219,  0.0188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-5.8438,  0.3516,  5.6875,  ..., -0.7266,  3.2969,  2.5469]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.8750,  3.7031, -1.3047,  ..., -4.0938, -3.6094, -1.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.9403841, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.023338743951171637, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1113,  0.1279,  0.0405,  ..., -0.1992, -0.1016, -0.0928]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2148,  0.3203, -0.0410,  ..., -0.0361, -0.2148,  0.3379]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-12.5625,  -6.4062,  -1.2969,  ...,   2.0000,   5.1250,   3.6094]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.3281,  3.0781, -2.2812,  ..., -1.5000, -2.8125, -2.9844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left`\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.9641774, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.023414856957970187, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.2080,  0.0128, -0.0256,  ...,  0.0654,  0.1270, -0.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0542, -0.2734, -0.0923,  ..., -0.3672,  0.0820, -0.1895]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.9688, -9.0625,  7.6562,  ...,  6.9062, 10.3125, -6.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.2266,  1.6641, -2.4688,  ..., -1.7656, -4.0938,  1.2422]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.9881833, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.023489626953960396, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0500,  0.0623,  0.0282,  ...,  0.0586, -0.0444, -0.1484]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0552, -0.0479,  0.1582,  ..., -0.1953,  0.1475, -0.0815]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 5.1250,  3.7188,  1.8828,  ...,  1.1016, -2.7031,  1.6484]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.3047, -1.5234, -5.5625,  ..., -1.3906, -2.4219, -0.9805]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.0121274, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02356696195784025, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0076,  0.1118, -0.0072,  ...,  0.1250, -0.0732, -0.0815]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0679, -0.0918,  0.1777,  ..., -0.1797, -0.5391, -0.0105]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-5.0625,  0.6953,  9.7500,  ..., -2.2656,  1.0312,  1.4766]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.9375,  2.5938,  1.8594,  ...,  1.4531,  0.3867,  0.1221]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.036021, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02364348496485036, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0109,  0.1050, -0.0408,  ...,  0.0012, -0.0074, -0.1641]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2471,  0.3691, -0.0383,  ..., -0.0649,  0.0801,  0.1670]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-18.2500,  -9.3125,  -5.0625,  ...,   5.6875,  -6.5000,   7.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.5469,  2.3281, -0.9062,  ..., -1.3438, -1.7422, -3.3594]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right`\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.0601742, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02372009896498639, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.2139, -0.0271,  0.0024,  ...,  0.1064,  0.1318, -0.0608]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0115, -0.2559, -0.0386,  ..., -0.3359,  0.1270, -0.2061]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.7500,  -5.6562,   7.0312,  ...,   6.2812,  -5.5625,  -0.3867]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.8594,  1.6094,  2.7812,  ...,  0.7305, -3.7500,  0.6680]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.084094, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.023795119966962375, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1279,  0.0610,  0.1250,  ...,  0.0605, -0.0815, -0.3320]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0305,  0.1807,  0.1807,  ...,  0.0732,  0.0415, -0.0752]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.4375,  0.9141,  1.3359,  ..., 11.5625, -3.4219,  1.3281]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.9766, -1.3125, 10.6875,  ..., -3.4531, -0.9375,  1.9922]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.1081402, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.023874979975516908, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0347, -0.0566, -0.0342,  ..., -0.0513,  0.0564, -0.0610]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0288, -0.0859,  0.0654,  ...,  0.1221,  0.1973,  0.0806]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 1.1562,  7.3125, -1.4688,  ..., -0.3555, -9.6875,  1.0781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.7266, -4.2500, -2.7344,  ...,  0.1006,  3.1719,  2.8906]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.1320362, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0239505819772603, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1006, -0.0095, -0.0255,  ..., -0.0576, -0.0486,  0.0120]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1885,  0.0564,  0.0041,  ..., -0.0168, -0.0879, -0.1025]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 3.3125,  0.5469, -4.4688,  ...,  3.5625,  1.9688,  0.2637]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2637,  1.4453,  0.1514,  ..., -0.2871, -1.5469, -1.1406]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.1559138, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.024024960977840237, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0732,  0.0796,  0.0369,  ...,  0.0688,  0.1069, -0.0645]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1001, -0.0991, -0.0293,  ..., -0.1211,  0.1660,  0.0449]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.9375, -1.1562, -1.0312,  ..., -6.0312,  2.4844, 13.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.3633, -0.9688,  2.0469,  ...,  3.5781, -1.2969,  1.5625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.1798306, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.024110831989673898, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0674,  0.0728,  0.0099,  ...,  0.0098, -0.0146, -0.2793]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1289,  0.0012, -0.0649,  ...,  0.0815,  0.1240,  0.0012]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -2.7812,  -0.7578, -10.8125,  ...,   6.2812,  -1.2266,   2.1406]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.5312, -0.2139, -5.4062,  ..., -1.8438,  4.5625, -3.3750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5.\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.2037988, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.024187716990127228, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0645,  0.0752,  0.0420,  ..., -0.0378, -0.0062, -0.0771]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1211,  0.3203,  0.0135,  ..., -0.0082, -0.1045,  0.1475]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.1875, -5.5938, -9.1250,  ...,  4.6250, -1.0859,  0.5117]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8203, -1.7656, -2.2031,  ...,  0.6602,  2.3750, -2.4531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.227593, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0242642199882539, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0226,  0.1387,  0.1787,  ...,  0.0791,  0.0752, -0.1914]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2500,  0.1973, -0.1475,  ...,  0.1367, -0.2158,  0.3516]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 1.6562, -6.0625, -9.2500,  ..., 15.1875, 10.2500,  0.4531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-4.9688,  1.4062, -3.9062,  ...,  3.5938,  2.3750,  4.2188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Comb\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.251398, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.024341674987226725, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0012,  0.1348,  0.0447,  ...,  0.1445, -0.0183, -0.0005]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2002, -0.1030,  0.1514,  ...,  0.1582,  0.0026, -0.2451]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.3750,  -7.3438,  -8.0625,  ...,  12.4375,  -3.7969,  -4.5625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.5547,  5.2188,  2.7969,  ...,  0.6797, -0.0674, -8.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.275257, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.024418167988187633, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0947, -0.0052,  0.0195,  ...,  0.0913, -0.3398, -0.0388]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0432, -0.0513,  0.0962,  ..., -0.0189,  0.0396,  0.0237]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-5.4688, -3.6250, -0.8984,  ...,  6.1250, -3.2656, -3.9844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.9141,  0.8945, -1.3125,  ...,  3.4219, -3.4219, -1.0234]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**:\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.2988372, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02450268599204719, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0762, -0.1689, -0.0317,  ...,  0.2656,  0.0908, -0.2207]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0703,  0.0942, -0.1436,  ...,  0.0193,  0.1523,  0.0952]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.7031, -7.8125, -5.8438,  ...,  4.5938,  4.0625,  1.9219]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.5781, -1.3906, -0.6914,  ...,  0.4375,  0.4785, -0.3457]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.322617, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02458167399163358, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0288, -0.0356,  0.0762,  ..., -0.0459, -0.0674, -0.0193]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3398,  0.3789,  0.1895,  ..., -0.0210,  0.0732,  0.3379]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.5391, -7.7500, -4.0000,  ..., 10.8125, -2.0000, -0.6953]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.6875, -2.4375, -3.0625,  ...,  0.6211, -1.2578,  1.5703]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.3464081, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02465998099069111, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0767, -0.0359, -0.0537,  ...,  0.0771, -0.1289, -0.0674]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1797, -0.1865,  0.0121,  ...,  0.0698,  0.0118, -0.0286]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.6719, -0.8047, -4.9062,  ...,  6.8125,  2.7812,  2.3438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.2500, -0.4570, -1.2969,  ..., -2.6875, -3.4531,  0.6133]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.3702164, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02473735598323401, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0200,  0.1289,  0.0327,  ..., -0.0608, -0.0337, -0.0684]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0332, -0.0344,  0.1934,  ..., -0.1465, -0.0430, -0.0967]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[10.6875, -3.6719, -3.6875,  ...,  8.3750,  1.2188,  6.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-4.7188, -0.7031,  0.1465,  ..., -2.9688, -0.9023,  2.7500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.3939815, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02481363898550626, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0054, -0.0664, -0.1309,  ...,  0.0214, -0.1543, -0.1230]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0559,  0.1904, -0.0004,  ...,  0.2275,  0.0544,  0.1045]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 2.3594, -5.6875,  3.9844,  ...,  6.1562, -1.3828,  7.5625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.1406, -0.9258, -1.3125,  ..., -1.9062, -3.0938, -0.4121]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.4177897, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.024890723987482488, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.1162,  0.1377,  0.0588,  ...,  0.0713, -0.0361, -0.0391]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0342, -0.0493,  0.0762,  ..., -0.1855, -0.5352, -0.0038]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.0625, -2.2188,  5.5938,  ..., -0.8398,  1.5469,  2.3750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.4062,  4.0312, -0.9180,  ..., -2.0312, -2.7500, -2.1719]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.4417331, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02496563499153126, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0933,  0.1128,  0.0693,  ..., -0.1865, -0.1045, -0.0718]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2334,  0.3105, -0.0630,  ..., -0.0250, -0.1924,  0.3633]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.5625,  -9.6250,  -0.8203,  ...,   3.4844,  -2.6562,  10.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1992,  1.3672, -3.0156,  ..., -0.1895, -0.2227, -1.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left`\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.4654484, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02504001499619335, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.2354, -0.0171, -0.0503,  ...,  0.0532,  0.1201, -0.0752]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0444, -0.2363, -0.0928,  ..., -0.3438,  0.0776, -0.2031]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -7.3125, -12.1875,   7.2500,  ...,   2.2656,   2.1406,   3.9219]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4180,  0.4590, -0.6484,  ..., -0.5703, -0.8203,  0.9219]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.4894354, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.025115936994552612, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1387,  0.0425,  0.1504,  ...,  0.0625, -0.0781, -0.2637]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0381,  0.1719,  0.1729,  ...,  0.0771,  0.0410, -0.0645]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.7031, -2.5938,  1.8906,  ...,  7.6250,  2.5938,  2.7656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4473,  1.0078,  4.7500,  ..., -1.0312, -2.2500,  1.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.5129302, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.025192039989633486, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0010, -0.1572, -0.0649,  ...,  0.0625,  0.2139,  0.0232]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0625,  0.0036, -0.0859,  ...,  0.2480,  0.5195, -0.0337]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 1.0781, -1.7422, -1.0234,  ...,  4.4062, -0.0391,  2.7969]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0554,  0.7695, -0.7578,  ..., -0.6133, -1.3906, -0.8984]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array,\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.5368536, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.025270967991673388, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0444,  0.0332,  0.0046,  ..., -0.0212,  0.0623, -0.0684]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0640, -0.0693, -0.0415,  ..., -0.1504,  0.0903, -0.0571]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-0.9219, -3.2031,  0.5391,  ...,  4.2500,  0.0820, 10.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.9844, -0.6797, -1.4531,  ..., -1.8125, -2.2812,  0.2656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.560751, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02535699898726307, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0186,  0.0253,  0.0117,  ..., -0.0874,  0.0732, -0.1426]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0615,  0.0513, -0.0618,  ...,  0.0188,  0.0708,  0.1025]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 1.5547, -1.0469,  6.8125,  ...,  2.9531,  2.4062,  6.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0459, -1.0234, -3.2188,  ..., -1.6328, -2.2500, -0.0081]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.58463, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.025433412985876203, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0540,  0.0527, -0.0386,  ...,  0.0664,  0.0022, -0.0742]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0240, -0.1709, -0.0282,  ..., -0.3086, -0.3984,  0.0074]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.5000, -0.7656, 12.1875,  ...,  6.1875,  4.1875, -0.4570]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-4.6250,  0.8750,  1.3438,  ..., -0.9258,  0.9219, -1.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.6083503, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02550977598002646, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.1030, -0.0023,  0.0203,  ...,  0.0850,  0.0026, -0.1064]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4336,  0.2637,  0.1865,  ...,  0.1060,  0.1064,  0.2090]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.4688, -6.6250, -3.4531,  ...,  0.6602, -1.6172,  6.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0854,  0.9961, -1.7812,  ..., -0.4199, -1.5156, -1.8047]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle`\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.6321537, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.025584806979168206, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.2471, -0.0618, -0.0034,  ...,  0.1357,  0.1436, -0.0820]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0233, -0.3008, -0.1611,  ..., -0.2832,  0.0168, -0.1748]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.4062, -6.6562,  7.9375,  ...,  2.7500,  5.3750,  0.5586]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0417, -0.4922,  0.5352,  ..., -0.2617, -2.3281,  0.5430]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.6559057, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.025661189982201904, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0752,  0.0269,  0.1523,  ...,  0.0583, -0.1494, -0.3008]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0168,  0.1836,  0.0923,  ...,  0.0825,  0.0583, -0.0786]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.9297, -0.1719, -0.7578,  ...,  6.3125,  1.7500,  4.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8789, -1.1250,  3.6719,  ...,  1.7734, -0.9141,  1.0781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.6797068, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.025742572979652323, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0182, -0.1689, -0.0547,  ...,  0.0217,  0.1631, -0.0033]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0286,  0.0023, -0.0654,  ...,  0.2734,  0.5156, -0.0344]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[5.6875, 0.1289, 2.8594,  ..., 1.2500, 1.4062, 0.2656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0659,  0.7109,  0.1562,  ..., -1.1172, -0.9180, -0.6484]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array,\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.7034268, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02581966698926408, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0549,  0.0332,  0.0099,  ..., -0.0184,  0.0518, -0.0703]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0376, -0.0659, -0.0549,  ..., -0.1289,  0.0723, -0.0737]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 5.1875, -3.2812, -0.4141,  ...,  1.1328,  1.9219,  0.7773]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.9492, -0.4336, -2.9062,  ..., -0.8516, -2.3594, -0.9336]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.727219, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.025895949991536327, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0201,  0.0184,  0.0352,  ...,  0.0082,  0.0265, -0.1133]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0918, -0.0588,  0.1465,  ..., -0.0466,  0.0124, -0.0879]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 2.3125, -3.1250, -1.3125,  ...,  5.4062,  0.4961,  5.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.1484, -0.9688, -1.1094,  ..., -1.9688, -5.0312, -0.1621]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.7512074, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.025982582999859005, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0193,  0.0452, -0.0125,  ..., -0.0120,  0.0055, -0.1445]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0393,  0.1719, -0.0400,  ..., -0.0732, -0.0047, -0.2139]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -0.2734, -10.0625,   0.3867,  ...,   5.6250,  -7.6875,   4.8125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.6406, -1.0234,  2.0312,  ...,  0.5117, -3.4062,  4.3438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.7749681, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.026058976000058465, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0359, -0.0718, -0.1514,  ...,  0.0386, -0.0801, -0.1494]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0664,  0.2441,  0.0903,  ...,  0.2598,  0.0879,  0.0850]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.7969,  4.0625,  3.8594,  ..., -1.9688, -4.1562,  7.4688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.2031, -0.1260, -4.3125,  ..., -1.0078, -1.7500, -1.0312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.7988884, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02613503900647629, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.1094,  0.0815, -0.0178,  ...,  0.0918,  0.0176, -0.0698]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0586, -0.0369,  0.1084,  ..., -0.1875, -0.5000, -0.0019]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-5.1875,  0.7656, 11.2500,  ..., -5.6250,  1.1875,  3.7031]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.7070,  4.5938,  2.2344,  ...,  0.4590, -0.0068, -0.8789]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.8229473, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.026210971002001315, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0076,  0.0562,  0.0022,  ..., -0.0474,  0.0284, -0.1689]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2324,  0.3555, -0.0986,  ..., -0.0830,  0.1240,  0.1592]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-12.3750,  -9.6250,  -3.3594,  ...,   2.3438,  -7.2812,  10.0000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3984,  2.0156, -3.7969,  ...,  0.6758, -2.5000, -2.9062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right`\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.846756, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.026287083004717715, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.2393, -0.0815, -0.0216,  ...,  0.0889,  0.1406, -0.0908]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0190, -0.2344, -0.0752,  ..., -0.2988,  0.1523, -0.2363]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -8.5625, -13.8125,   4.3438,  ...,  -0.2676,  -1.4844,   4.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.4609,  1.1562,  1.7891,  ...,  2.5000, -2.3906,  3.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.8707376, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02636293500836473, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1221,  0.0261,  0.1299,  ...,  0.0630, -0.0918, -0.3203]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0513,  0.1865,  0.1562,  ...,  0.0654,  0.0383, -0.0669]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.2969,  0.1484, -3.4219,  ...,  8.2500,  4.0312,  7.4062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.9805, -2.7188,  3.7188,  ...,  0.7969, -0.0273,  3.0312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.8946636, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.026439178007422015, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0099, -0.1631, -0.0752,  ...,  0.0723,  0.1934, -0.0046]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0009,  0.0422, -0.0898,  ...,  0.2598,  0.4883,  0.0179]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 2.0156, -1.1172, -6.3438,  ...,  5.8750,  0.0371,  7.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3008,  0.2812,  0.8047,  ..., -0.1650, -1.1797, -0.8633]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.9180613, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.026514359007705934, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1099,  0.0027,  0.0383,  ..., -0.0232,  0.0923, -0.0679]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0320, -0.0339, -0.0654,  ..., -0.0601,  0.1875, -0.2344]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[  1.2969, -12.3125, -12.0000,  ...,   7.2188,   3.1406,  -0.1094]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.0938,  0.3789, -2.9531,  ...,  1.6797, -0.6289,  0.2539]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.941552, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.026602524012560025, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0762,  0.1074,  0.0518,  ...,  0.1270, -0.0227, -0.2051]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1553, -0.3750,  0.0454,  ..., -0.0811,  0.1416, -0.1006]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 4.9375, -7.3750, -6.9688,  ...,  9.1250,  7.3750,  4.2812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.9688, -2.0781, -2.2656,  ..., -4.2500, -4.5625, -1.7734]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.9654737, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.026682735013309866, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0579,  0.0874, -0.0493,  ..., -0.1338,  0.0413, -0.1113]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1865, -0.0718,  0.2422,  ..., -0.1631, -0.0781, -0.1138]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 7.3750, -9.4375, -3.2188,  ...,  9.7500,  9.4375,  0.7070]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.9531,  0.2734, -1.8750,  ..., -1.8984,  0.0215,  0.4941]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.9893572, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.026758648018585518, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0508, -0.0854, -0.0040,  ..., -0.0007,  0.0693, -0.2383]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2598, -0.2168,  0.0530,  ..., -0.1465, -0.1455,  0.0074]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 1.9062, -9.4375, -2.0938,  ..., 18.6250,  5.7188,  1.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8008, -0.0542,  2.8750,  ..., -1.8750,  0.3125,  3.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.0133228, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02683546202024445, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0830,  0.1348, -0.0884,  ...,  0.0559, -0.0918, -0.1152]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1270,  0.2422,  0.1235,  ...,  0.3594,  0.1133,  0.0874]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.3125, -5.4375,  9.1875,  ...,  7.7812,  2.5781,  1.7344]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.7344, -1.5000, -1.7656,  ..., -0.1504,  1.2734, -0.3730]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.0372024, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02691162501287181, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0155,  0.0210,  0.0356,  ..., -0.0613,  0.1416, -0.1299]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0437,  0.0105, -0.0072,  ...,  0.1157,  0.1147,  0.0055]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 1.0938, -1.9453, -2.7031,  ...,  4.6250,  2.7031,  5.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.8125,  0.5273,  0.2119,  ...,  0.7578, -0.1709, -0.9102]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\n\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.061067, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.026987628007191233, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0732,  0.0284,  0.1709,  ...,  0.1689,  0.0952, -0.0237]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0986, -0.1484, -0.0060,  ..., -0.0986,  0.1914, -0.0522]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.9375,   1.6172,  -0.0391,  ...,  -5.9688,  -2.2500,  -1.3672]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.2500, -0.4863,  0.0781,  ...,  1.3203,  3.2188, -0.7188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.0848842, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.027064663008786738, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0212, -0.0703,  0.1025,  ...,  0.1021, -0.0850, -0.1396]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0171, -0.0498, -0.2207,  ...,  0.0391, -0.0527, -0.0179]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.6250, -5.1250,  7.6875,  ...,  3.2656,  4.0938, -1.4219]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.5391, -0.7344, -1.0625,  ..., -2.1875,  1.5078, -1.2656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.1087656, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.027141297003254294, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.2559,  0.1875, -0.0498,  ..., -0.0312,  0.0388, -0.0098]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3027, -0.0640,  0.4062,  ..., -0.5078,  0.1904,  0.1836]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.1250, -8.5625,  7.8125,  ...,  0.5000,  3.3906, -1.8047]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.7578, -0.7656,  2.5625,  ..., -1.5703,  0.0635, -0.8125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.1326554, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.027218000002903864, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1035,  0.1895, -0.1348,  ..., -0.0796, -0.0898, -0.1055]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1050, -0.2217, -0.1094,  ..., -0.2578,  0.0703, -0.1226]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.6562, -7.5625, 21.6250,  ...,  5.4062,  1.1719,  0.1074]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.7500, -3.2500,  1.2031,  ..., -2.8594, -0.7188, -1.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.1562338, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.027293591992929578, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0723,  0.1206, -0.1206,  ..., -0.1953, -0.0688, -0.0806]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1494, -0.2441, -0.2275,  ..., -0.1738, -0.0938, -0.0996]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.1719, -9.0000,  2.7188,  ...,  0.7305,  3.1875, -3.2031]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2031,  0.0698, -0.8516,  ..., -0.8828,  0.1074,  0.4902]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.1801734, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.027377840000553988, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0942, -0.0012, -0.0439,  ..., -0.0369, -0.0140, -0.0579]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1030, -0.0217, -0.1523,  ..., -0.0077,  0.1562, -0.0947]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[  2.0312, -16.2500,  27.8750,  ...,   1.1719,  11.5000,  -2.6875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.4062, -1.9688,  2.3281,  ..., -0.5781, -0.9961, -0.9609]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.2040823, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.027453270988189615, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0413,  0.0129, -0.0437,  ..., -0.0786, -0.1162, -0.1030]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2852,  0.1797, -0.3887,  ..., -0.2637, -0.2344,  0.2656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 5.0000, -8.7500, -2.9844,  ...,  4.1562,  1.4688, -0.6406]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4766,  1.6172, -0.0854,  ..., -1.3359, -1.1250,  1.1641]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.2281132, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.027529653991223313, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0303, -0.0435, -0.1475,  ..., -0.0703, -0.0211, -0.0200]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.6094, -0.1226, -0.0938,  ..., -0.1807, -0.1206,  0.6289]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 7.5312, -5.8438,  5.9688,  ..., 12.3125, -4.9375,  3.9219]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.0469,  0.7812,  1.1641,  ...,  1.0781, -2.1406, -0.5352]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.2518485, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.027605595998466015, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0586, -0.1641,  0.1133,  ...,  0.0767, -0.0427,  0.0317]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0630,  0.0786,  0.1553,  ...,  0.1128, -0.2041, -0.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.6250, -2.7812,  1.8047,  ..., -1.8281, -6.3125,  1.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.9844,  0.7773, -1.2500,  ...,  0.1641,  0.1748,  0.3535]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand,\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.2756414, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02768181898863986, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0608, -0.0129,  0.0122,  ...,  0.0076,  0.1226,  0.0276]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0708, -0.1338, -0.0889,  ..., -0.0206,  0.0352,  0.0289]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.6562, -7.1875,  2.5156,  ..., -8.6875, -3.8906, -1.2578]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.8594, -0.1201, -2.0000,  ..., -0.4492,  1.2578,  1.7422]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.299623, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.027757460993598215, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0674, -0.0439, -0.0591,  ..., -0.0391,  0.0884, -0.1035]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4590, -0.4512,  0.0554,  ...,  0.0747, -0.1299,  0.1455]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-5.9062, -6.6250, 10.1250,  ..., -2.1719,  0.3555,  0.1309]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.5430, -1.3672, -0.8438,  ..., -0.4688,  0.6094, -0.3242]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.3237708, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.027841918999911286, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0540,  0.0596,  0.0623,  ..., -0.0381,  0.0376,  0.0908]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3359,  0.0786,  0.2207,  ..., -0.2012,  0.0067, -0.0085]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-14.8125, -15.8125,  12.0000,  ...,  -5.9375,  -1.5000,   2.2656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.7188, -0.5820,  0.6289,  ..., -1.2969,  0.2344, -2.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.347414, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.027918523002881557, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.2773,  0.2227,  0.0238,  ...,  0.0247,  0.0349, -0.0703]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2490,  0.3574,  0.0471,  ..., -0.1709, -0.4297, -0.1108]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-16.5000, -12.6250,   1.4297,  ...,  -7.5000,   4.1562,   4.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.4062,  0.6641, -1.0547,  ..., -1.3125, -1.4297, -3.3438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.371197, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.027994495001621544, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.2451,  0.1758, -0.0195,  ..., -0.0205,  0.0457,  0.0684]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1787, -0.1328, -0.2578,  ...,  0.5273, -0.3828, -0.1826]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -6.0938, -12.7500,  -6.4375,  ...,   2.8906,   4.5000,   1.9922]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3398, -1.0625, -1.6719,  ...,  1.4688, -0.9492, -3.3281]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.3950334, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02807315200334415, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0879,  0.1221,  0.0918,  ..., -0.1729, -0.0498, -0.0645]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0728,  0.0177, -0.1318,  ...,  0.1807,  0.2461, -0.1406]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -3.9062, -13.1250,  -0.8086,  ...,   1.7656,   7.6875,  -6.6875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2773, -0.8750, -0.4375,  ..., -3.1406, -0.1709, -2.7656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.4187887, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02814880399091635, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0962,  0.0115,  0.0175,  ..., -0.0393,  0.0106, -0.2012]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0674,  0.2178,  0.0227,  ..., -0.1045, -0.1963, -0.0464]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -0.2734, -17.8750,  -0.9297,  ...,  -3.5938,  -7.9062, -11.6875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.7695,  0.1035, -1.4766,  ..., -3.2031,  0.6719, -1.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.4426644, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.028224705994944088, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1562, -0.0378,  0.0182,  ...,  0.1494,  0.0625, -0.0918]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3359,  0.2305, -0.3789,  ...,  0.4258,  0.2188, -0.1924]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -7.3125,  -6.0312,   6.8750,  ...,   1.9375,   2.1250, -12.6875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.9062, -1.8594, -1.3125,  ..., -1.2969,  2.6406, -3.0781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.4665194, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02829955698689446, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0598,  0.0107, -0.0742,  ..., -0.2295,  0.1069,  0.0403]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.5078, -0.2363, -0.0669,  ..., -0.2314, -0.0986, -0.0238]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.5000, -0.0898,  4.7188,  ..., -2.6562,  0.9609,  3.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2676, -2.4531, -2.4844,  ..., -2.2031, -1.2578,  0.3672]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.4902892, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.028375970985507593, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0349,  0.0054, -0.1611,  ..., -0.0718,  0.0250,  0.0086]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0013,  0.0413, -0.1226,  ..., -0.3438, -0.0850, -0.0205]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-13.3750,  -1.7188,   5.6875,  ...,  -5.1875,   9.8125,   3.5156]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.5469, -1.9766,  0.1289,  ..., -1.4531, -0.2061, -2.0781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.5146, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.028459096982260235, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.1807, -0.1709,  0.0364,  ...,  0.0598,  0.0195,  0.0640]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2520,  0.2080, -0.1641,  ...,  0.1455,  0.1533, -0.2275]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.0000,  2.5938,  1.1719,  ..., -6.3750,  6.4375,  4.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.5938,  0.0427, -1.8594,  ..., -3.8594, -1.5469, -1.6406]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.538669, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.028562069972394966, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.3223,  0.0064, -0.0708,  ...,  0.0276, -0.0275, -0.0544]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0064, -0.1230, -0.5664,  ..., -0.6328, -0.3828, -0.1816]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.8438, -1.8672,  7.5000,  ..., -0.9336,  4.5000,  3.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.0781, -2.8281, -1.2969,  ..., -2.0781, -1.7109, -1.4844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.562401, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02863785198132973, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0957, -0.0430,  0.0432,  ..., -0.0498,  0.0767, -0.1660]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1074, -0.0771, -0.1147,  ..., -0.0253,  0.2275,  0.0713]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-14.0625,   6.5625,   2.3750,  ..., -13.1250,   2.8438,   4.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.7656, -2.5156,  1.3281,  ..., -1.0078, -0.3672, -1.1328]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.5859363, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.028712861982057802, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1445, -0.1128, -0.1245,  ...,  0.1221,  0.0303,  0.0027]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4629, -0.0864,  0.0703,  ...,  0.5273, -0.0967,  0.1182]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-12.7500,  -0.3594,   6.1562,  ...,   0.1953,   1.3594,  -1.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.4766, -1.0859, -1.1172,  ..., -2.2188,  0.0085, -1.2422]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.6097744, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02879184998164419, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1060,  0.1123,  0.0186,  ..., -0.1992, -0.0320, -0.2559]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1514,  0.1572, -0.1187,  ...,  0.1924,  0.1816,  0.0850]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -5.3750,   3.2812,  -1.8750,  ..., -12.3750,   8.5000,   7.9688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.5000,  1.2422, -0.9453,  ..., -2.9844,  0.1021, -0.8047]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.6335618, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.028868001987575553, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0630,  0.1514,  0.1553,  ..., -0.1582,  0.0019, -0.1660]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2471, -0.1099,  0.0723,  ...,  0.3711, -0.4961,  0.5625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-17.7500,   1.0312,   0.1992,  ...,   4.0938,   4.3750,   9.8125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.5625, -0.1094, -5.4062,  ..., -1.8984, -0.5820,  1.3906]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.6573033, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.028947330996743403, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0574,  0.0723, -0.0420,  ..., -0.0859,  0.0359, -0.1504]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0352,  0.1021,  0.1250,  ..., -0.0732, -0.1011, -0.1162]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.1250,  8.1875, -0.6719,  ...,  2.4219,  5.7500, 12.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.0078,  1.5781, -1.8438,  ...,  0.5859, -0.0566,  0.5547]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.6811917, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.029022853006608784, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0386,  0.0879, -0.0522,  ...,  0.0427, -0.0110, -0.1523]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1133, -0.0112,  0.0364,  ...,  0.1602, -0.3848,  0.4844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -8.2500,   0.9219, -12.6250,  ...,   4.2188,   7.0000,   3.5625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.2891,  2.0156, -2.8281,  ..., -3.8281, -0.8047, -2.5938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.7050457, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.029114655015291646, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0260, -0.1514, -0.1475,  ..., -0.0159, -0.0226, -0.1021]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0510, -0.3652, -0.0342,  ...,  0.0187, -0.2676, -0.0977]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.5469,  1.3438,  5.7188,  ...,  5.8125,  2.0469,  8.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.6523,  2.4375, -3.6094,  ..., -1.0938,  1.4531,  3.0781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.7289076, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02919089801434893, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1738,  0.0767, -0.0840,  ..., -0.2275, -0.0659, -0.0513]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0212, -0.0106,  0.4824,  ...,  0.2852, -0.0461, -0.2383]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.2188,  2.3750,  3.4844,  ...,  9.9375, -0.4727,  3.8281]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.1250,  0.5898, -1.1719,  ..., -0.6016, -0.0420,  0.9844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.7527108, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.029266059005749412, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1582, -0.1445,  0.0620,  ..., -0.0869, -0.0208, -0.0674]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2832,  0.0023,  0.0089,  ..., -0.0242,  0.0898, -0.0095]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.1250,  3.2500, -0.5547,  ..., 11.5000,  3.2188, -0.5352]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2275,  0.6250, -1.0469,  ..., -0.0859, -1.0625, -0.9570]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists.\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.7765646, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.029342402995098382, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0918,  0.0801,  0.0544,  ..., -0.0211,  0.0549, -0.0649]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0952, -0.1040,  0.0491,  ...,  0.0072,  0.0238,  0.0171]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 3.9375, -0.7656,  0.8594,  ..., -0.7305, -9.1250, -6.5938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.5977, -0.3730, -0.0225,  ...,  1.2656,  0.9297, -2.6094]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.8005419, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.029417894998914562, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1167, -0.0281,  0.0610,  ..., -0.0327, -0.0043, -0.1030]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1436, -0.1426, -0.0371,  ..., -0.0386, -0.0344,  0.2197]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 3.3750, -1.5547, 11.2500,  ..., -3.2656,  2.8906, -4.9062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8477, -0.2539,  1.5938,  ..., -3.1250, -0.1426, -3.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.8242943, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.029495189985027537, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1060,  0.0415,  0.0581,  ...,  0.0417,  0.0078, -0.0286]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1309,  0.0332, -0.1396,  ..., -0.4316, -0.1396,  0.0139]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 1.8828, -4.5312,  4.1250,  ..., -1.6562,  4.2188, -7.0000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.3125,  0.7148, -1.3828,  ..., -7.6250,  4.3750, -6.4062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.8482041, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02957966798567213, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0415, -0.0096,  0.1021,  ...,  0.0776,  0.0815, -0.1279]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1279, -0.0050, -0.1221,  ..., -0.3262, -0.1348,  0.4609]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.4688, -4.8750,  7.4688,  ...,  1.4062,  5.8438, -8.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0703, -2.7031, -1.0391,  ..., -2.7812,  4.6562, -1.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304, 41661), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.8720703, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.029654597979970276, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0762, -0.1172, -0.0063,  ..., -0.0023, -0.1035,  0.0486]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4141, -0.4551,  0.1147,  ...,  0.1235,  0.0574, -0.3574]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 1.5000,  4.0312,  6.4375,  ..., -1.4062, -0.3789, -0.7266]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.1406,  1.1094,  1.7188,  ..., -0.5039,  0.7148, -1.9531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place version\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304, 41661, 2319), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.895753, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.029729778980254196, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0337,  0.1206,  0.1475,  ..., -0.2578,  0.0342, -0.3164]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0251,  0.0282,  0.0811,  ..., -0.0454,  0.0123, -0.0094]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-0.2734,  5.0625, -2.7344,  ...,  0.8086, -3.0312,  7.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1328,  0.7188,  0.2021,  ..., -0.3730, -1.0000, -1.3750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place version of\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304, 41661, 2319, 315), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.9195607, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02980459897662513, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0684,  0.0291, -0.0141,  ..., -0.2676,  0.2520, -0.3145]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1631, -0.1387, -0.2373,  ..., -0.2490, -0.1162, -0.0156]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[2.7656, 0.9336, 2.6562,  ..., 0.2188, 5.0000, 0.8789]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2148,  0.8984, -1.0781,  ...,  0.7930, -0.0137, -1.2188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place version of quick\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304, 41661, 2319, 315, 3974), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.9433067, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02987988997483626, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0090,  0.1108, -0.0554,  ..., -0.0361,  0.1943, -0.1235]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2441,  0.6289,  0.2275,  ...,  0.2041,  0.2197,  0.2432]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -7.1250,  -0.7500,   0.2363,  ...,   3.2969, -11.5625,   0.7734]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.3047,  0.3848,  0.3164,  ...,  5.1562, -5.5312,  0.8555]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place version of quick sort\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304, 41661, 2319, 315, 3974, 3378), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.967086, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.029955231977510266, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.2461, -0.0544,  0.0674,  ..., -0.0610, -0.0144,  0.0054]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0557, -0.0081,  0.0859,  ...,  0.1299, -0.2852, -0.1338]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.9375,  4.5000, -0.5391,  ...,  1.3750, -4.6875,  4.9375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.9297,  0.2812,  0.2314,  ..., -0.7969, -1.5156, -0.5703]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place version of quick sort,\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304, 41661, 2319, 315, 3974, 3378, 11), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.9911635, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.03003165496920701, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0664, -0.0178,  0.0728,  ..., -0.0322,  0.0532, -0.0099]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0322, -0.1416, -0.1738,  ..., -0.0430,  0.0239,  0.0415]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.5234,  4.8750,  1.5469,  ..., -0.4570, -6.0938,  8.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.6719,  0.2988,  0.0669,  ..., -0.1436, -0.8555,  0.0708]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place version of quick sort, you\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304, 41661, 2319, 315, 3974, 3378, 11, 498), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100480.0149488, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.030107697966741398, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0996, -0.0209,  0.1465,  ..., -0.0757,  0.0540,  0.0403]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2324, -0.0859,  0.1348,  ..., -0.3613, -0.0996, -0.0398]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-5.8125,  7.4062,  5.3125,  ...,  6.2188, -3.4375, -0.4609]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.7344, -1.3672, -1.2422,  ...,  0.4141, -0.6641, -1.8828]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place version of quick sort, you can\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304, 41661, 2319, 315, 3974, 3378, 11, 498, 646), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100480.0387342, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.030190593970473856, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0215,  0.1338,  0.0410,  ..., -0.0957, -0.1006, -0.0200]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0295,  0.0009, -0.3359,  ..., -0.1670, -0.4277,  0.4121]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.7891,  2.6875,  6.7188,  ...,  7.1250, -9.3750,  2.4844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0066,  0.7031, -2.0156,  ...,  0.9688, -0.4707, -1.8516]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place version of quick sort, you can modify\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304, 41661, 2319, 315, 3974, 3378, 11, 498, 646, 5602), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100480.0623264, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.030265694978879765, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0177, -0.0170,  0.2275,  ..., -0.1553,  0.0057, -0.0432]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1631, -0.0938, -0.1016,  ..., -0.1602, -0.0435, -0.3184]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.6875, -0.5234, -1.7656,  ...,  8.5000, -1.2422,  8.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8906, -0.5039, -0.8945,  ..., -1.9609, -1.4844, -0.2207]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place version of quick sort, you can modify the\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304, 41661, 2319, 315, 3974, 3378, 11, 498, 646, 5602, 279), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100480.0861878, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.030352066969498992, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0002,  0.0420, -0.0060,  ..., -0.1206,  0.0767, -0.0864]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0201,  0.0253,  0.2930,  ..., -0.0767, -0.0199,  0.0149]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.6250,  2.5625,  1.8672,  ...,  6.5000, -5.3750,  6.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2656, -1.2109, -1.2422,  ..., -2.2969, -0.1973,  0.2354]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place version of quick sort, you can modify the algorithm\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304, 41661, 2319, 315, 3974, 3378, 11, 498, 646, 5602, 279, 12111), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100480.1100254, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.03042795897636097, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0957,  0.0454,  0.0359,  ..., -0.3926,  0.1367, -0.0366]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0613, -0.0630, -0.0469,  ..., -0.3848, -0.1592,  0.2773]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -2.8281,   3.9688,  -2.0000,  ...,   2.5312, -14.2500,   7.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3320,  0.0850, -0.5547,  ..., -0.4473, -0.9648,  0.9297]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place version of quick sort, you can modify the algorithm to\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304, 41661, 2319, 315, 3974, 3378, 11, 498, 646, 5602, 279, 12111, 311), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100480.1337886, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.030505303977406584, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1123, -0.0038,  0.0229,  ..., -0.2793,  0.0962, -0.0080]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1221, -0.0410, -0.0894,  ..., -0.0298,  0.1982, -0.2393]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.8438, -5.9375, -3.8125,  ..., -0.3125, -4.8438,  2.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.8750, -0.6250, -1.7891,  ...,  1.2578, -1.4453, -1.0234]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place version of quick sort, you can modify the algorithm to sort\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304, 41661, 2319, 315, 3974, 3378, 11, 498, 646, 5602, 279, 12111, 311, 3378), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100480.157694, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.030580945982364938, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.2617,  0.0400,  0.0618,  ..., -0.1680, -0.0003, -0.1602]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1104, -0.2949,  0.1084,  ...,  0.1895, -0.1719, -0.2539]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.4375, -0.2031,  3.8750,  ...,  2.3750, -1.0312,  3.8281]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0493, -1.1484,  0.4688,  ..., -1.4219, -1.3672,  1.5859]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place version of quick sort, you can modify the algorithm to sort the\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304, 41661, 2319, 315, 3974, 3378, 11, 498, 646, 5602, 279, 12111, 311, 3378, 279), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100480.1815693, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0306617079913849, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0227, -0.0476,  0.0127,  ..., -0.1367,  0.0796, -0.1289]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1670, -0.0444,  0.2988,  ...,  0.0427, -0.1104,  0.0116]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-0.7188, -1.5312,  9.4375,  ..., -4.6562, -5.9062,  6.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1172,  0.1016, -1.0859,  ..., -1.5156,  0.0703, -0.1025]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place version of quick sort, you can modify the algorithm to sort the array\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304, 41661, 2319, 315, 3974, 3378, 11, 498, 646, 5602, 279, 12111, 311, 3378, 279, 1334), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100480.2054832, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.03073869198851753, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0327, -0.0640, -0.0123,  ..., -0.1001,  0.0176, -0.1045]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0008,  0.0757,  0.1025,  ...,  0.0762, -0.0491,  0.1084]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.4375,  6.1562,  6.3750,  ..., -1.3750, -3.0312,  1.3359]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4355,  0.0134, -0.7930,  ..., -1.3906,  1.1406,  1.7656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place version of quick sort, you can modify the algorithm to sort the array in\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304, 41661, 2319, 315, 3974, 3378, 11, 498, 646, 5602, 279, 12111, 311, 3378, 279, 1334, 304), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100480.2293215, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.030815685997367837, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0942, -0.0447, -0.0603,  ..., -0.0703, -0.0245, -0.1104]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2188,  0.0522, -0.0640,  ..., -0.2793, -0.0306,  0.0786]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.2500,  5.0625,  9.1250,  ..., -5.1250,  1.0234,  1.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.4062, -2.8906, -0.6445,  ...,  1.0234,  1.0547, -1.3672]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place version of quick sort, you can modify the algorithm to sort the array in place\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304, 41661, 2319, 315, 3974, 3378, 11, 498, 646, 5602, 279, 12111, 311, 3378, 279, 1334, 304, 1992), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100480.2532783, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.030896166994352825, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1787, -0.1191,  0.2100,  ...,  0.1465, -0.0291, -0.0830]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1270, -0.2246,  0.1992,  ...,  0.1045, -0.0183, -0.3184]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 1.9531,  3.1562, -0.0391,  ...,  1.2969, -3.6250,  6.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2500, -0.2168, -0.1426,  ..., -0.3027, -0.8477, -0.3203]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place version of quick sort, you can modify the algorithm to sort the array in place without\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304, 41661, 2319, 315, 3974, 3378, 11, 498, 646, 5602, 279, 12111, 311, 3378, 279, 1334, 304, 1992, 2041), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100480.2771206, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.03097930298827123, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0114,  0.0356,  0.0056,  ..., -0.1289,  0.0879, -0.1621]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0173,  0.1099,  0.3516,  ..., -0.0435, -0.3496,  0.2520]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.7500,  1.6953, -7.7812,  ...,  4.0938, -1.1094,  3.6406]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0718,  0.2598, -1.6484,  ..., -0.8633, -2.0312,  2.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place version of quick sort, you can modify the algorithm to sort the array in place without using\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304, 41661, 2319, 315, 3974, 3378, 11, 498, 646, 5602, 279, 12111, 311, 3378, 279, 1334, 304, 1992, 2041, 1667), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100480.300802, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.031054122984642163, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0762,  0.0154,  0.1089,  ..., -0.1455, -0.1245, -0.1846]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1572, -0.0182,  0.3906,  ..., -0.0058, -0.1689,  0.3867]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[1.6641, 3.2812, 0.8984,  ..., 5.5312, 3.2188, 4.5625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1895,  2.2188, -3.3281,  ..., -1.4766,  1.6953,  1.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place version of quick sort, you can modify the algorithm to sort the array in place without using extra\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304, 41661, 2319, 315, 3974, 3378, 11, 498, 646, 5602, 279, 12111, 311, 3378, 279, 1334, 304, 1992, 2041, 1667, 4960), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100480.3248794, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.031129493974731304, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1167, -0.0854,  0.0197,  ..., -0.1748, -0.0942, -0.1553]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0698, -0.1543,  0.5625,  ...,  0.2148,  0.0034, -0.2988]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.3438e-02,  2.9844e+00, -6.4453e-01,  ...,  1.2812e+01,\n",
      "         -1.1719e-02,  1.6953e+00]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.4609,  1.2969, -1.0781,  ...,  0.7852, -2.5781,  1.4141]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place version of quick sort, you can modify the algorithm to sort the array in place without using extra space\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304, 41661, 2319, 315, 3974, 3378, 11, 498, 646, 5602, 279, 12111, 311, 3378, 279, 1334, 304, 1992, 2041, 1667, 4960, 3550), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100480.3483107, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.031205886974930763, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1206,  0.0203,  0.1504,  ..., -0.0659, -0.0781, -0.2139]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1953, -0.3574, -0.0820,  ...,  0.1738,  0.3066, -0.1855]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-0.8555,  9.0000, -4.0625,  ...,  7.0625,  2.2344,  3.4531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.7812,  0.2383,  0.2852,  ...,  0.9141, -1.1172, -0.1484]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place version of quick sort, you can modify the algorithm to sort the array in place without using extra space for\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304, 41661, 2319, 315, 3974, 3378, 11, 498, 646, 5602, 279, 12111, 311, 3378, 279, 1334, 304, 1992, 2041, 1667, 4960, 3550, 369), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100480.372078, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.031282189971534535, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0771,  0.0625,  0.0144,  ..., -0.1943,  0.0601, -0.1387]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2363, -0.1445, -0.0403,  ..., -0.3516, -0.0908,  0.0850]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-0.6641,  8.7500,  2.0312,  ...,  7.0625, -4.2500, -0.2520]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.6953,  0.3438, -0.9766,  ..., -1.0938, -2.1094,  0.5859]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place version of quick sort, you can modify the algorithm to sort the array in place without using extra space for sub\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304, 41661, 2319, 315, 3974, 3378, 11, 498, 646, 5602, 279, 12111, 311, 3378, 279, 1334, 304, 1992, 2041, 1667, 4960, 3550, 369, 1186), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100480.395808, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.031358382970211096, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1128,  0.0117,  0.1963,  ..., -0.0376, -0.0874, -0.2559]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[0.0013, 0.2061, 0.1387,  ..., 0.1162, 0.0574, 0.0244]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.9375, -2.9375,  0.3203,  ..., 17.1250, -4.9062, -1.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.9492, -0.6992,  7.5312,  ..., -6.7188, -2.8906,  0.5586]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place version of quick sort, you can modify the algorithm to sort the array in place without using extra space for sub-\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304, 41661, 2319, 315, 3974, 3378, 11, 498, 646, 5602, 279, 12111, 311, 3378, 279, 1334, 304, 1992, 2041, 1667, 4960, 3550, 369, 1186, 12), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100480.4196804, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.03143473598174751, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0374, -0.0938,  0.0074,  ..., -0.0928,  0.0437, -0.0014]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0215, -0.0178,  0.0752,  ...,  0.1631,  0.1758, -0.0107]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 1.9531e-03,  1.3359e+00, -1.2578e+00,  ...,  4.9375e+00,\n",
      "         -2.6406e+00, -3.5938e+00]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.6875, -3.6719, -1.4141,  ..., -4.2500,  3.4531, -1.4844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place version of quick sort, you can modify the algorithm to sort the array in place without using extra space for sub-arrays\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304, 41661, 2319, 315, 3974, 3378, 11, 498, 646, 5602, 279, 12111, 311, 3378, 279, 1334, 304, 1992, 2041, 1667, 4960, 3550, 369, 1186, 12, 66893), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100480.4432218, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.03151054798217956, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0664, -0.0327,  0.0162,  ..., -0.0835, -0.0378,  0.0028]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1514,  0.0977,  0.0483,  ...,  0.0200, -0.0908, -0.0991]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.4375,  1.5312, -1.5625,  ...,  6.8438, -0.9727, -0.5469]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.7656,  0.5703, -0.8086,  ..., -0.2061, -1.4453, -1.1797]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place version of quick sort, you can modify the algorithm to sort the array in place without using extra space for sub-arrays.\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304, 41661, 2319, 315, 3974, 3378, 11, 498, 646, 5602, 279, 12111, 311, 3378, 279, 1334, 304, 1992, 2041, 1667, 4960, 3550, 369, 1186, 12, 66893, 13), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100480.467087, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.031605204989318736, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0234,  0.0674,  0.0364,  ..., -0.0530,  0.0537, -0.0184]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1465, -0.0742,  0.0479,  ..., -0.0052,  0.0254,  0.0199]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -4.7500,   1.5156,   2.7812,  ...,   2.5156, -13.9375,  -9.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.7188,  0.4277, -0.1523,  ...,  1.1328, -0.5234, -0.8867]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place version of quick sort, you can modify the algorithm to sort the array in place without using extra space for sub-arrays.\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304, 41661, 2319, 315, 3974, 3378, 11, 498, 646, 5602, 279, 12111, 311, 3378, 279, 1334, 304, 1992, 2041, 1667, 4960, 3550, 369, 1186, 12, 66893, 13, 151645), cumulative_logprob=None, logprobs=None, finish_reason=stop, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100480.491065, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=1755100480.4911935, scheduler_time=0.031681798995123245, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n"
     ]
    }
   ],
   "source": [
    "while enc_dec_engine.has_unfinished_requests():\n",
    "    enc_dec_output = enc_dec_engine.step()\n",
    "    print(enc_dec_output)\n",
    "\n",
    "# Create file terminate.json\n",
    "with open(\"test_py_files/terminate.json\", \"w\") as f:\n",
    "    f.write(\"{}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95cd0d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_dec_engine.abort_request(\"123\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "323213fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0d4d35eb7d54507bb59192bf55fb831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6559de474a6648a0b5179f7cb065d117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positions: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34],\n",
      "       device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.3809, -0.1367, -0.2852,  ...,  0.3066, -0.1533,  0.1250],\n",
      "        [-0.3594, -0.1338, -0.2285,  ..., -0.1572, -0.1719,  0.1963],\n",
      "        [-0.1992, -0.0483, -0.1216,  ..., -0.0113, -0.0449,  0.1367],\n",
      "        ...,\n",
      "        [-0.2207, -0.0586, -0.0820,  ...,  0.0518, -0.1206, -0.0496],\n",
      "        [ 0.0280, -0.0991, -0.1699,  ..., -0.0068, -0.0752, -0.0703],\n",
      "        [-0.0737, -0.0249,  0.0583,  ...,  0.0388, -0.0270,  0.0806]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.5742, -0.0115,  0.2324,  ...,  0.0344, -0.3594, -0.0618],\n",
      "        [-0.1201, -0.2344, -0.0623,  ..., -0.0669, -0.0030,  0.1045],\n",
      "        [-0.1182,  0.0201, -0.1138,  ..., -0.0072, -0.1406,  0.0630],\n",
      "        ...,\n",
      "        [-0.1846,  0.1387,  0.0173,  ...,  0.0659,  0.0256,  0.0140],\n",
      "        [-0.1406,  0.0542,  0.0212,  ...,  0.0183, -0.0200, -0.0776],\n",
      "        [-0.1357,  0.0134,  0.1758,  ..., -0.0275,  0.0166, -0.0791]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([35, 3584]) and residual: torch.Size([35, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.1000e+01,  1.6094e+00,  1.1406e+00,  ...,  3.8125e+00,\n",
      "          1.4188e+01, -3.4688e+00],\n",
      "        [-1.1875e+01,  2.0469e+00,  1.7500e+00,  ...,  1.9688e+00,\n",
      "          1.4625e+01, -3.8438e+00],\n",
      "        [-1.0500e+01,  2.0000e+00,  1.3125e+00,  ...,  3.7500e+00,\n",
      "          1.4375e+01, -3.2500e+00],\n",
      "        ...,\n",
      "        [-9.2500e+00, -1.8125e+00, -1.1875e+00,  ..., -1.7266e+00,\n",
      "         -4.3125e+00, -7.3438e+00],\n",
      "        [ 7.8125e-01, -1.2656e+00, -7.8125e-03,  ..., -4.5625e+00,\n",
      "         -7.5938e+00, -1.0375e+01],\n",
      "        [ 9.8438e-01, -1.3281e-01,  6.4062e-01,  ..., -3.1562e+00,\n",
      "         -5.5000e+00, -1.0125e+01]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-4.9062, -7.0000, -3.9844,  ...,  8.5625, -4.0312, 10.8125],\n",
      "        [-5.2188, -8.6875, -5.5625,  ..., 10.9375, -4.8438, 11.3750],\n",
      "        [-5.4062, -8.0000, -4.7188,  ..., 10.0000, -4.1250, 10.7500],\n",
      "        ...,\n",
      "        [ 0.9414, -1.9375,  4.8125,  ...,  0.4766, -1.8516, -4.4688],\n",
      "        [ 2.2031,  1.0703,  0.4805,  ...,  1.6719,  1.9453,  2.4688],\n",
      "        [ 0.6523,  0.8906,  0.7188,  ...,  2.7031,  3.6719,  2.4844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([35], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0027, -0.0082, -0.0461,  ..., -0.0491,  0.1787,  0.0513]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0121,  0.0410, -0.0298,  ...,  0.3633, -0.3359,  0.1992]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.3750,  1.3672, -0.9336,  ..., -7.7188, -5.8438,  9.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1128,  0.9531,  0.7695,  ...,  1.2891, -1.1250, -0.0064]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([36], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0192, -0.0374,  0.0498,  ...,  0.0044,  0.1611, -0.0530]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0120, -0.2891, -0.0610,  ...,  0.6523,  0.1826, -0.4238]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.1250, -5.4375, -6.4062,  ..., -1.7031, -0.2949, -7.4688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.5898,  1.6641, -1.6484,  ...,  2.1875,  0.9297,  0.9531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([37], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0291,  0.0728,  0.0144,  ..., -0.0044,  0.0299, -0.0332]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2344,  0.2383,  0.0127,  ...,  0.2158,  0.3789,  0.0071]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.2500,  -0.7734,  -5.0312,  ...,   7.0000, -17.5000,   3.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.8906, -0.3125, -1.7188,  ...,  1.7656,  0.4980, -2.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([38], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.3301, -0.0713,  0.0332,  ..., -0.0085, -0.2246, -0.0015]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0991,  0.0109,  0.1865,  ...,  0.1963, -0.3438, -0.1235]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-14.5000,   5.9062,  -9.1250,  ...,   3.5938,  -8.8125,   2.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.3906,  1.1953,  1.8438,  ..., -1.9766, -0.7305, -0.4531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([39], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1357,  0.0566, -0.1523,  ..., -0.1436,  0.0110,  0.0205]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0908, -0.0408, -0.1445,  ..., -0.2314,  0.0510, -0.0215]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.6250,  0.7656, -3.4375,  ...,  8.6875,  7.1562,  1.5938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8320,  0.5430,  1.5625,  ..., -1.4062, -2.8438, -1.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([40], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0918,  0.0469,  0.0105,  ..., -0.1279,  0.0559,  0.0659]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0762,  0.3828,  0.0613,  ..., -0.0522,  0.0352, -0.2090]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 4.5312, -2.3438,  5.1250,  ..., -1.6250,  2.8281, -7.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0474,  0.8672, -1.6094,  ..., -2.1406, -1.1719,  0.4199]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([41], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0569, -0.1079, -0.0417,  ..., -0.1465,  0.0635,  0.0228]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0303,  0.1309, -0.1641,  ..., -0.1768, -0.2598, -0.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.9688, -1.1875,  4.4062,  ...,  1.3906, -0.9727, -7.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.3066,  1.6953, -0.7852,  ..., -1.0469,  1.6719,  0.1416]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([42], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0425,  0.0289,  0.0189,  ...,  0.0046,  0.0425, -0.0072]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2676, -0.2139, -0.1885,  ...,  0.0977,  0.0295, -0.0557]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 6.1250, -2.7656,  9.2500,  ...,  2.7031,  3.0312, -7.9688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.9688,  2.0000, -2.4688,  ..., -2.5156,  1.9688, -2.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([43], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0131, -0.0173, -0.1572,  ..., -0.2637,  0.0237,  0.0312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3027, -0.0776, -0.0243,  ..., -0.0884, -0.1836, -0.1572]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.0625,  5.1250, -0.5625,  ..., -1.6250, -1.0391,  0.0596]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4141,  0.8672,  1.4062,  ..., -1.2109,  1.7266, -0.0449]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([44], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0417, -0.0045, -0.1035,  ..., -0.2236, -0.1484, -0.0317]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0137, -0.0820,  0.0376,  ..., -0.0503, -0.1807, -0.1455]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.4531,  3.7188, -2.8125,  ..., -2.5625, -7.0625, -2.2969]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1318,  0.0464, -2.6719,  ..., -0.2471,  2.9531, -1.6797]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([45], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0889,  0.2100,  0.0236,  ..., -0.4746, -0.0308, -0.0280]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1787, -0.0361, -0.3242,  ..., -0.2930, -0.0347,  0.0962]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.8750,  1.4844, -2.8750,  ...,  0.4727, -2.7656,  5.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0266, -0.6133,  0.0542,  ..., -2.4688, -0.2949, -1.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([46], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0217,  0.1484, -0.0442,  ..., -0.1562,  0.1201, -0.0481]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0513, -0.2578, -0.3359,  ..., -0.1416, -0.1201,  0.0576]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-12.5000,  -2.6250,   0.0625,  ...,  -2.0625,  -1.0000,  -5.0000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3984, -1.3516, -0.2773,  ..., -2.2969, -0.5586, -1.1719]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([47], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0251,  0.1201, -0.0498,  ...,  0.1187, -0.0889, -0.0762]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2324,  0.0469,  0.2100,  ...,  0.1660, -0.7227, -0.1357]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.3125,   7.8438, -11.9375,  ...,   1.8906,   4.7812,   2.3906]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.6094,  0.9219, -0.2070,  ..., -2.1875, -0.5977, -1.5156]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([48], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1221, -0.0654, -0.0058,  ..., -0.0238, -0.0464,  0.0024]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3223,  0.1816,  0.1738,  ..., -0.2676, -0.3418, -0.1553]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-5.2812, -1.3906, -0.8555,  ..., -5.4375,  0.4297, -9.5625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1338,  0.4531,  0.3574,  ..., -3.8281,  0.7227, -1.9375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([49], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0339,  0.1104,  0.0608,  ..., -0.0498, -0.0679, -0.0859]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0190,  0.1826,  0.2754,  ..., -0.0071, -0.0869,  0.0496]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.0781,  2.0469,  1.7422,  ..., -2.0625, -2.2344, -6.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4023, -2.9062,  0.4297,  ..., -0.5312, -3.3125,  1.4844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([50], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.1152, -0.0493, -0.0269,  ..., -0.0530, -0.1582, -0.0913]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0996,  0.0471,  0.0996,  ..., -0.1338,  0.0251, -0.0496]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 3.3125,  6.0625,  8.2500,  ..., -0.6406,  0.6016, -3.2812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.8516, -3.3125, -1.7188,  ...,  0.6367, -6.2500, -0.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([51], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0549,  0.0278,  0.0688,  ...,  0.1030, -0.0991, -0.2178]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1001,  0.0025, -0.0046,  ..., -0.0500,  0.0801,  0.0693]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 2.2344, -2.8125, 13.6250,  ...,  2.9844,  0.5117, -4.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[  4.7812, -10.5625,  -7.3438,  ...,   8.2500,  -7.2812,   9.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([52], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0281,  0.2109,  0.1777,  ..., -0.2393,  0.1064,  0.0537]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0084, -0.0649, -0.1504,  ...,  0.0684,  0.1465, -0.0255]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.1562,  3.3125,  1.9453,  ..., -2.6875,  0.8320, -0.0254]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4863, -2.6250, -0.3398,  ..., -0.1836, -0.1660, -2.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([53], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0171,  0.0381,  0.0200,  ..., -0.3203, -0.1006, -0.1045]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2793, -0.0178, -0.3613,  ..., -0.2373, -0.0068, -0.2305]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.3906,  3.1094, -3.0781,  ..., -3.6875, -3.8750,  6.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1934, -0.8516,  0.4258,  ..., -0.1582, -0.1562, -0.7891]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([54], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0605, -0.0508, -0.0071,  ..., -0.1572, -0.0391, -0.0879]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4355,  0.2188, -0.3281,  ..., -0.0967, -0.0654,  0.1338]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.5469, -4.4062, -7.3125,  ..., -1.3750,  0.4453, -2.2812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8750, -2.2188, -0.8594,  ...,  0.7617, -0.5078,  0.6641]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([55], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.2480,  0.0586,  0.0417,  ..., -0.1514, -0.1611, -0.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1201, -0.2754,  0.1079,  ...,  0.3027, -0.2490, -0.2334]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.3438,  2.1406, -6.0938,  ..., -3.3125,  0.4023,  0.3516]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2344,  0.2676, -1.1641,  ..., -0.2275, -1.4844, -0.5898]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([56], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0208,  0.0283, -0.1128,  ..., -0.1221, -0.2100,  0.0260]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0019, -0.3340,  0.0630,  ...,  0.0217, -0.0251, -0.0618]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.6719,  4.0312,  3.5469,  ...,  0.4219, -7.0938,  1.3359]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.3613, -0.6719, -0.9648,  ..., -0.2852, -0.2012,  0.9375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([57], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0266,  0.0928,  0.0143,  ..., -0.0520, -0.0308, -0.0251]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1328, -0.0737,  0.1079,  ...,  0.0564, -0.0486,  0.0104]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-12.8750,  -4.7188,  -3.1406,  ...,  -1.8594,   3.2188,   1.5625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0742,  1.1719, -1.4844,  ...,  1.6797, -1.1250, -0.7891]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([58], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1504, -0.0742,  0.1875,  ...,  0.1963,  0.0049, -0.0796]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1221, -0.3594,  0.3066,  ...,  0.6914, -0.0630,  0.0020]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-5.9375, -4.4062, -3.4688,  ...,  0.6055,  0.5078,  6.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.1328, -0.0938, -0.3125,  ..., -0.5977, -0.5781, -0.2109]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([59], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1504, -0.1660,  0.0291,  ...,  0.1445,  0.1807,  0.1084]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0322, -0.5820,  0.3105,  ...,  0.1426, -0.1953,  0.4688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 3.2500, -1.9688, -0.6602,  ...,  7.7812, 13.3750,  4.4062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.6094, -1.1797,  0.6680,  ...,  0.2520, -1.7812,  0.1641]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([60], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0703,  0.0071,  0.0198,  ..., -0.0354,  0.0918,  0.0913]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2500,  0.1865,  0.1719,  ..., -0.1235, -0.0140, -0.2236]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.6406, -1.2188,  8.9375,  ...,  3.7812, 11.2500, -7.5625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.1797, -0.4648,  1.4531,  ..., -2.2031, -0.1543, -0.9062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([61], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0054,  0.1836, -0.0796,  ..., -0.2305, -0.0225, -0.0830]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2500,  0.0461, -0.1797,  ..., -0.1689, -0.3262, -0.0864]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 7.1250, -7.0312,  4.4375,  ..., -2.1719, 15.7500, -6.7500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.3711,  1.1406,  0.5586,  ..., -2.2812,  1.1797, -1.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([62], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.2256,  0.1484, -0.0942,  ..., -0.2090, -0.1494, -0.0981]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0972, -0.1553,  0.3164,  ..., -0.5195,  0.1562,  0.1484]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.8750, -2.0781, -2.6875,  ..., -5.2500,  3.3750,  5.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.5820,  0.4883,  0.1885,  ..., -0.9883, -0.0605, -0.5625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([63], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0796,  0.0552,  0.0586,  ..., -0.1504,  0.0371, -0.0718]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.3984, -0.1128,  0.0918,  ..., -0.5859,  0.1475, -0.0282]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.7188, -3.9375,  4.3750,  ..., -2.2812, 13.6250,  0.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8320, -0.4180, -1.3047,  ..., -0.3184,  0.2207,  0.6094]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([64], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0608,  0.1113, -0.0078,  ..., -0.0613,  0.0073, -0.1094]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0251,  0.0302, -0.0449,  ..., -0.1309, -0.0767, -0.0850]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[  5.1875, -12.6875,   2.7500,  ...,  -4.8438,  12.1875,  -1.3594]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.6875, -0.0791, -0.5703,  ...,  0.3262,  0.0928, -0.6016]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([65], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0061,  0.1426, -0.1338,  ..., -0.0840,  0.1426, -0.1367]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2695,  0.4844,  0.2363,  ...,  0.0752,  0.1904,  0.2217]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -9.6875,  -5.4375,  -3.0469,  ...,   2.0312, -12.5000,   3.4219]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0908, -0.0527,  0.5273,  ...,  2.8906, -4.0625,  1.2422]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([66], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.2773, -0.0420,  0.0461,  ..., -0.0898, -0.1167,  0.0090]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0613, -0.0121,  0.1641,  ...,  0.1221, -0.2871, -0.1660]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.9375, -0.5859, -3.1562,  ...,  1.2500, -4.7812,  1.6562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0508, -2.3438, -2.9375,  ..., -1.9062,  3.4375, -0.6641]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([67], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1768,  0.1299,  0.0986,  ..., -0.4180,  0.0547,  0.0386]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1162, -0.0549, -0.2246,  ..., -0.3633, -0.0918,  0.2471]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.9844, -6.4375, -2.5625,  ..., -2.0469,  2.0000,  5.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.3438,  0.4141,  0.4551,  ..., -0.6602,  0.1260,  0.2295]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([68], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1074, -0.0004, -0.0747,  ..., -0.1709, -0.0476, -0.0986]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2061,  0.0786,  0.0610,  ..., -0.3398, -0.0549,  0.2451]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[  0.2891,  -9.6875,   2.4062,  ..., -11.1875,   5.6250,   4.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.0234, -0.5703, -0.4453,  ..., -0.1680,  0.4395,  0.2695]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([69], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.2256,  0.0708,  0.0442,  ..., -0.1416,  0.0732,  0.0674]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1719, -0.7461, -0.4551,  ..., -0.3789, -0.3008,  0.3223]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.7812, -0.2148, -1.3281,  ...,  5.1250,  2.9688,  1.7734]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.6719,  0.0737,  0.0420,  ...,  0.1914,  0.5703, -0.8281]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([70], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0378,  0.0325,  0.1377,  ...,  0.1318,  0.0771, -0.0806]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0053, -0.3184,  0.1182,  ..., -0.0942,  0.0986, -0.0564]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.1250,  3.8438, -0.6016,  ...,  1.7266,  8.4375,  4.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1797, -2.4219,  0.1504,  ...,  0.2441,  1.5000, -2.4219]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([71], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0527, -0.0537, -0.0332,  ...,  0.1357,  0.1357, -0.1357]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1787, -0.3320, -0.0684,  ..., -0.3105, -0.2324, -0.2812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.5312,  2.8906,  1.5859,  ..., -0.4844, 10.5625,  4.5938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.6875, -0.1396,  1.5156,  ..., -0.2988,  2.1406, -2.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([72], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1387,  0.0703, -0.0664,  ...,  0.0649, -0.0942, -0.0410]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4785, -0.0016, -0.0547,  ..., -0.3652, -0.3027, -0.3652]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-13.1250,   5.4062,  -2.8594,  ...,   6.4062,   5.8438,   8.5625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1670, -1.7578,  1.2500,  ...,  0.0427, -0.5273, -3.3750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([73], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0211,  0.2021,  0.0226,  ...,  0.0674,  0.0474, -0.0074]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2754, -0.1377, -0.0615,  ..., -0.3223,  0.1465, -0.1279]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-18.7500,   3.3906,  -1.9141,  ...,   8.6875,  16.1250,   5.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.7734, -2.6250,  1.4531,  ..., -1.5547,  1.7500, -2.2656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([74], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1211,  0.0825, -0.0918,  ..., -0.0674, -0.0420, -0.1328]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2090, -0.1060,  0.0376,  ..., -0.3789, -0.3027, -0.7656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.6875,  2.0000, -8.1250,  ...,  6.7812,  5.3750, -2.0469]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.8984,  1.1328, -3.5781,  ..., -1.1172, -3.4219, -3.4688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([75], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0364,  0.1348, -0.2246,  ..., -0.0752,  0.0830, -0.0430]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4336,  0.6328,  0.2422,  ...,  0.1455,  0.1768,  0.1094]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-15.9375,   0.0508,  -1.0703,  ...,   6.5625,  -3.6719,   1.5469]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4258,  2.5156,  2.0156,  ...,  3.1719,  3.1250, -3.9219]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([76], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1206, -0.0371, -0.0654,  ..., -0.1436, -0.0354,  0.1807]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0099,  0.0781, -0.1099,  ...,  0.0518, -0.1982, -0.1387]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.0625,   7.5312,  -2.5938,  ...,   4.7812,  -0.6328,  -1.5781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.3965,  0.2910,  0.7070,  ..., -2.0469,  2.5156, -3.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([77], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0515,  0.0093,  0.0014,  ...,  0.0106,  0.0194, -0.0957]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4043, -0.1426, -0.0211,  ...,  0.4160,  0.1953, -0.1021]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-14.5000,   4.5938,   3.4062,  ...,   5.7500,  -9.3125,   6.7812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.9375,  2.4062, -2.1406,  ...,  0.2617, -0.6992,  0.4102]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([78], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0352, -0.0271,  0.0535,  ...,  0.0295,  0.0220, -0.0317]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0942, -0.0698,  0.0361,  ..., -0.0674,  0.3203, -0.1758]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.7500, -1.1797, -1.3047,  ..., -1.3281,  0.5547,  7.4062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.2656, -2.5156,  0.1030,  ...,  2.2344,  1.0469, -2.0781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([79], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1089,  0.0002, -0.1611,  ...,  0.1235,  0.1650, -0.0435]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1045, -0.1377,  0.1318,  ...,  0.2158,  0.2412, -0.4043]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -6.8750,  -0.9766, -11.1875,  ...,   4.2500,   0.0684,  -3.0000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.5469,  0.7344, -2.0938,  ...,  0.1445, -0.8789, -1.6406]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([80], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0297, -0.0359, -0.1553,  ..., -0.0097,  0.0066, -0.0752]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0830, -0.3652, -0.1445,  ..., -0.1904,  0.0023, -0.2832]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.5000,   0.7422,  -3.4062,  ...,   2.4219,   1.2109,  -1.4688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.5156,  0.7266,  0.5820,  ...,  0.5391, -1.1094, -0.7812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([81], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1260, -0.1030,  0.0164,  ...,  0.0479, -0.0518, -0.0457]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0618, -0.0014, -0.0840,  ...,  0.1050,  0.0249,  0.1611]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.0000,  6.2500, -0.5352,  ...,  0.0820, -0.2031,  1.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-6.2812,  2.4062,  0.1064,  ..., -0.8672,  0.4922, -3.3750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([82], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0200,  0.0139,  0.0134,  ...,  0.0640, -0.0173, -0.1279]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4961, -0.0151,  0.0461,  ...,  0.4141,  0.0786,  0.0806]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-12.7500,  -9.5625, -16.6250,  ...,   3.1406,  -3.1562,  11.9375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1226,  1.6484, -3.5312,  ..., -0.0422, -1.0625,  1.7266]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([83], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.1104,  0.0469,  0.0256,  ..., -0.0569,  0.2324,  0.0337]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0952,  0.0908, -0.0830,  ..., -0.1973,  0.1484, -0.0781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.3750,  -8.8750, -10.1250,  ...,   1.9844,  -5.9062,  -2.0469]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.8555,  0.3262, -0.0024,  ...,  0.4961, -0.5938,  0.2949]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([84], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0605,  0.0312, -0.0762,  ..., -0.1406, -0.0092, -0.0708]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0322, -0.3398, -0.1055,  ..., -0.3320, -0.0569, -0.5469]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-13.3125,   4.8750,  -0.9688,  ...,  12.7500,   2.0000,   2.5156]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.8984,  0.1836, -0.2832,  ..., -1.2031,  0.1089, -3.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([85], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0155,  0.0022,  0.0003,  ..., -0.1562,  0.0737,  0.0786]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0249, -0.0549,  0.1099,  ...,  0.0383,  0.1328, -0.1118]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.7500,  -0.2578,  -6.4688,  ...,   6.7500,  -1.9141,   5.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.5312, -4.3125,  0.3516,  ...,  2.0469, -2.4844, -9.6875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([86], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0040, -0.0396,  0.0049,  ..., -0.0786,  0.1328, -0.0535]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0157, -0.0581,  0.0320,  ..., -0.0391,  0.0771, -0.0239]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -7.2500,   0.1719,  -2.8438,  ...,   8.8750, -10.1250,   9.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.3242,  1.0859, -0.1387,  ..., -0.9609,  0.4863, -2.2344]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([87], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0076,  0.0850, -0.0166,  ...,  0.1348,  0.0060, -0.0527]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2188, -0.0035,  0.0337,  ...,  0.0801,  0.0713, -0.1826]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.9375,  5.1250, -6.6250,  ..., -2.2500, -2.6250, 14.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.5625, -0.1221, -2.2812,  ..., -1.1250,  1.0859, -6.9375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([88], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0444,  0.0262, -0.0703,  ...,  0.0608,  0.1074, -0.0195]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2402, -0.1729,  0.0820,  ...,  0.0520,  0.1196, -0.2012]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.0000,  2.9062, -4.7500,  ...,  5.5312,  4.5312,  0.6797]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.0859,  0.1079, -0.7383,  ...,  0.9961, -1.2109, -0.1504]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([89], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0811, -0.0742, -0.0728,  ...,  0.0649, -0.0278, -0.1128]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.3320, -0.1982,  0.1729,  ...,  0.0217, -0.1367, -0.2471]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.4375, -1.9844, -2.9531,  ...,  6.9688,  7.0625,  3.9844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.2344, -0.8242,  0.2354,  ...,  4.6250, -2.6719,  1.6719]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([90], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0610,  0.0095, -0.0073,  ..., -0.1191, -0.1064, -0.0605]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4199,  0.0608,  0.0483,  ...,  0.2793,  0.1523,  0.0977]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-14.5000,   4.3125,  -6.2812,  ...,  -2.1719,  -7.3750,  10.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.0703, -1.3359, -0.6758,  ...,  0.2129, -0.1943, -0.5273]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([91], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0505,  0.0791,  0.0210,  ...,  0.0186,  0.0669,  0.0483]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1836, -0.0796, -0.0322,  ..., -0.1196,  0.1338, -0.0045]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.6875,  3.4531,  0.5977,  ..., -2.2031,  1.4062, 15.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.6719,  3.5469, -1.4219,  ...,  5.4062,  2.7656, -0.8594]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([92], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0791, -0.0113, -0.1494,  ...,  0.0728,  0.0635,  0.0063]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1367, -0.0649,  0.0471,  ...,  0.1387,  0.1504, -0.3535]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.8125,  0.2617, -1.7188,  ..., -0.1914, -7.0938,  0.0518]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.5352,  0.6797, -0.1406,  ...,  0.9141, -0.4004, -2.4688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([93], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1128, -0.1221, -0.1494,  ..., -0.0342,  0.1187, -0.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1973, -0.1973, -0.2168,  ..., -0.4258, -0.0933, -0.1270]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-5.2500, -2.0156,  3.0781,  ...,  3.7969, -8.7500, 10.7500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3770,  1.4141,  0.4004,  ...,  1.6953, -0.1191, -1.6641]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([94], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1152,  0.3262, -0.0530,  ...,  0.1611, -0.0366, -0.0845]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2793,  0.0635,  0.1309,  ...,  0.0723, -0.0010, -0.4453]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.8125,  3.1406, -1.8672,  ..., -0.1328, -4.7812,  9.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.4688,  0.0273, -1.6484,  ..., -0.0264,  1.5703, -7.7500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([95], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0255,  0.0459, -0.0928,  ...,  0.0693,  0.1143, -0.0089]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2441, -0.0613,  0.0542,  ...,  0.0444,  0.1621, -0.1328]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -9.3750,  -0.7227,   2.1562,  ...,   2.3438, -10.6875,   0.1504]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.8047, -1.6641,  1.2422,  ...,  0.9023, -2.5625, -1.2188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([96], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0264, -0.1318,  0.0425,  ..., -0.1309, -0.0625, -0.0208]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1396,  0.0017,  0.0752,  ..., -0.0400, -0.1299,  0.0967]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.4688,  1.2266,  7.0625,  ..., -7.3438, -0.1250, -2.2031]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.7539, -0.5898,  0.2363,  ...,  0.1406, -0.5000, -1.8125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([97], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0298,  0.0884,  0.0503,  ...,  0.0796,  0.0630, -0.0508]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0645, -0.1299, -0.1611,  ...,  0.0199,  0.2598, -0.1592]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.9375, -2.0938, -3.3438,  ...,  3.1562,  3.2812, -1.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.7188, -0.1299, -1.4922,  ...,  3.1875, -1.2422,  0.2773]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([98], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0693,  0.0137,  0.0258,  ..., -0.0591, -0.1709, -0.0474]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4434,  0.0918,  0.1128,  ...,  0.2871,  0.1226,  0.0737]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.2031,  5.8125, -4.7500,  ..., -6.5312, -6.3125,  4.7812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.3906, -2.2812,  2.7188,  ...,  2.4844,  2.3438, -0.3730]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([99], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0117,  0.0542, -0.0635,  ..., -0.1992,  0.0236, -0.0830]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0903, -0.1758, -0.0938,  ...,  0.2012,  0.1436,  0.0684]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.6875,   7.3125,  -0.1016,  ...,   3.0156,  -3.1875,   1.6875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-5.3125,  2.5469, -0.0684,  ...,  0.0801,  0.7930, -3.3281]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([100], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0562, -0.0177,  0.0415,  ...,  0.0669, -0.0396, -0.2100]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4453,  0.0640,  0.0113,  ...,  0.3750,  0.0339,  0.1543]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.7500, -6.8125, -9.9375,  ..., -5.2500,  0.6172, 22.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.4531,  3.7500, -7.3750,  ...,  1.2109,  2.5000,  3.0469]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([101], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0850,  0.0248,  0.0327,  ..., -0.0469,  0.1768, -0.0121]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0571,  0.1309, -0.0518,  ..., -0.2188,  0.0767,  0.0056]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.0312, -1.0156, -2.2656,  ..., -8.3125, -3.6875,  6.7188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.5977, -0.3789, -3.9375,  ...,  0.2461,  2.6562, -0.2490]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([102], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0967,  0.0957, -0.0747,  ..., -0.0143, -0.0215, -0.0376]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0554,  0.0679, -0.3125,  ...,  0.2168, -0.0825, -0.0830]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.8125,  0.3984,  2.1875,  ...,  9.3125,  0.4258,  5.6562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.5000,  0.2070, -2.8125,  ...,  1.7031,  0.8867, -0.0172]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([103], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0376,  0.0991,  0.0004,  ..., -0.0277, -0.0236,  0.0903]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1250, -0.1172,  0.1328,  ..., -0.0698,  0.1113, -0.0038]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.2812, -4.7812, -6.5625,  ...,  6.0938, -0.0693,  4.7188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8281, -6.8125, -3.3594,  ...,  4.4062, -2.8750, -4.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([104], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0076,  0.0742,  0.1021,  ...,  0.0234, -0.0135, -0.0664]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0231,  0.0277,  0.0439,  ...,  0.0679,  0.0693, -0.1123]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.8750,   1.5938,  -4.5625,  ...,  -5.5312,   0.5156,  10.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.5781,  0.6641, -1.4922,  ...,  0.6523, -0.1035, -1.9297]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([105], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[0.0342, 0.0197, 0.0522,  ..., 0.1982, 0.0118, 0.0330]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1953, -0.1738,  0.0131,  ..., -0.0781,  0.1279, -0.0933]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-12.8750,   4.2812,  -3.2188,  ..., -10.5000,  -5.6562,  10.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3633,  1.7344, -0.6094,  ..., -0.3887, -0.4805, -4.4062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([106], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0371,  0.0522, -0.1157,  ...,  0.0869,  0.0635, -0.0349]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1680, -0.0801,  0.0569,  ...,  0.0364,  0.0986, -0.1699]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-0.9961, -0.4922,  3.6562,  ...,  0.3867,  1.7578,  3.9844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.7070,  0.7578, -2.2031,  ...,  3.7031, -1.2266, -0.7773]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([107], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.2109, -0.0269, -0.0122,  ...,  0.0684, -0.1260, -0.0527]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2363,  0.2080, -0.0077,  ..., -0.1670, -0.1992,  0.3184]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.9375,   2.0469,  11.0000,  ...,  -3.8438,   9.9375,   2.5781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.6250, -0.2061, -0.2188,  ...,  0.1582,  1.3828, -3.3906]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([108], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1187, -0.0762,  0.0247,  ...,  0.1279,  0.0747, -0.0806]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0967, -0.1377, -0.0854,  ..., -0.0051,  0.3008, -0.1689]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -8.1250,   4.9375,  15.5625,  ..., -10.8750,   5.1875,  10.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.6367,  0.8945, -3.2031,  ...,  0.3574, -1.4062,  0.1855]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([109], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0513,  0.1143,  0.0957,  ..., -0.0649, -0.1074,  0.1064]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0615, -0.2754,  0.0928,  ...,  0.0811, -0.0247,  0.0013]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-17.0000,  11.3750,   4.8750,  ..., -11.1875,   1.8594,   0.5156]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.4375,  0.3789,  3.8906,  ..., -1.9922,  3.7031, -2.2969]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([110], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0454, -0.0918,  0.1465,  ...,  0.0698, -0.0879,  0.0591]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1865, -0.1680, -0.0398,  ..., -0.0562, -0.0806, -0.0156]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-12.8750,   5.8125,  -3.6250,  ...,  -3.5312,  -0.3340,  -0.3457]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.5430,  0.0698,  0.0221,  ...,  0.6484, -0.3633, -1.0391]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([111], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0054,  0.0669, -0.0284,  ...,  0.0032, -0.0542, -0.1123]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3164, -0.2129,  0.0018,  ..., -0.5547, -0.1904,  0.1328]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.5000,   1.7969,  -2.6406,  ...,   1.0781,  -1.1016,  -7.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.1172,  3.1719,  1.3125,  ...,  2.5625, -0.5938,  2.9219]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([112], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0610, -0.0074,  0.1279,  ..., -0.0215, -0.1562, -0.0898]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1914, -0.0131, -0.1279,  ..., -0.1167, -0.0118,  0.1104]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.7188,  3.0469,  1.9844,  ...,  1.3203,  3.0625,  1.3281]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.7344,  0.2471, -2.0781,  ..., -1.0625, -1.7344, -0.5781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([113], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0635,  0.0034,  0.0066,  ...,  0.0481, -0.0986, -0.1738]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1865, -0.4512, -0.1416,  ..., -0.4434, -0.1914, -0.3496]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.6875,  2.2812, -1.5391,  ...,  1.9922,  2.6406, -3.9844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2188, -1.1328, -0.3945,  ...,  5.2500, -1.2266,  0.1914]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([114], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0664,  0.0137,  0.0649,  ..., -0.0245, -0.1318, -0.0845]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3457,  0.0972,  0.0349,  ...,  0.3203,  0.1084,  0.1338]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-0.3281,  2.6562, -4.6562,  ..., -5.0312,  4.6875,  1.6484]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.9492, -1.7188, -0.8867,  ..., -0.8984,  0.0084, -0.6758]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([115], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0006, -0.0332, -0.0251,  ..., -0.0059, -0.0253, -0.0942]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1089, -0.3887,  0.0659,  ..., -0.1504, -0.0889,  0.0776]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.9375,   1.0391,  -2.5781,  ...,   1.1406,   1.0781,  -0.8828]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1836,  1.9531,  0.9258,  ...,  1.9688, -0.6836,  3.7500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([116], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0640,  0.0046,  0.1113,  ...,  0.0508, -0.0938, -0.0317]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2832, -0.0574, -0.1650,  ..., -0.1387,  0.0098,  0.1387]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-13.5625,   5.1250,  -1.2266,  ...,  -6.9688,  -1.4062,   6.2812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.8672, -0.7461, -2.3750,  ...,  1.1250,  0.7344, -1.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([117], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0049,  0.0986, -0.0520,  ...,  0.0918, -0.0608, -0.0703]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1465, -0.4141, -0.1426,  ...,  0.0645,  0.1572, -0.3359]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.2500, -0.8750,  2.9062,  ..., 10.0625, -7.1562, -3.7812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.7422, -0.8203,  2.3750,  ...,  2.4062, -5.0938, -4.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([118], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0154, -0.0815,  0.0635,  ..., -0.0400,  0.0287,  0.0115]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1060, -0.0522,  0.0942,  ..., -0.0089, -0.1562,  0.0308]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.3125,   5.5000,   1.6719,  ...,  -3.3594,  -0.8438,   9.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.9609, -0.9688, -0.9688,  ...,  1.2969, -0.8984, -3.4844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([119], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.1216,  0.0835,  0.0693,  ...,  0.2100, -0.0723,  0.0193]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1553, -0.0806,  0.0212,  ..., -0.0361,  0.1089, -0.0386]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -5.2812,  -1.4375,   1.6875,  ..., -13.1250,   2.3906,  15.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.4219,  0.1113, -1.9609,  ...,  0.6758, -0.6914, -7.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([120], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0287,  0.0757, -0.1377,  ...,  0.1196,  0.0469, -0.0576]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1699, -0.0525,  0.0430,  ...,  0.0425,  0.1040, -0.1279]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.1094, -1.2188, 10.0625,  ..., -3.6875, -4.2500,  6.5938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.5938,  0.2109, -2.5156,  ..., -1.4844, -1.1719, -3.5938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([121], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0104, -0.0840, -0.0052,  ...,  0.2314, -0.0732, -0.0820]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3555,  0.1719,  0.2383,  ...,  0.0859,  0.2002,  0.1514]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-5.7500,  8.0625,  7.4375,  ...,  0.4453,  5.1562, -0.5391]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.1484, -0.0645, -1.9375,  ...,  0.1108,  2.5469, -2.6562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([122], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0605, -0.0444,  0.0190,  ...,  0.1689,  0.0295, -0.0903]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0996, -0.0742, -0.0688,  ...,  0.0386,  0.2158, -0.0864]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.3125,  5.6562, 12.6250,  ..., -2.5469, 10.3750,  1.2578]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 3.9062e-03,  1.6797e-01, -8.1875e+00,  ..., -1.6309e-01,\n",
      "         -2.4688e+00,  1.9609e+00]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([123], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0449,  0.1108,  0.1050,  ..., -0.0178, -0.1465,  0.1143]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0977, -0.2295,  0.1069,  ...,  0.0947, -0.0317,  0.0095]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-18.7500,   2.9062,   5.8125,  ...,  -5.5000,   7.5000,   3.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.9375,  3.2500,  1.2656,  ...,  0.6406,  4.9688, -1.8984]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([124], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0015, -0.0996,  0.1504,  ...,  0.1064, -0.1279,  0.1084]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1660, -0.0383, -0.0337,  ..., -0.0131, -0.0532, -0.0009]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.5000,  6.5625, -0.3359,  ..., -8.0000,  3.6875, -0.1309]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.1719,  0.8516, -0.5117,  ...,  0.5547, -0.4707, -0.4609]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([125], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0014,  0.0713, -0.0106,  ...,  0.0188, -0.0649, -0.1152]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2949, -0.1973,  0.0089,  ..., -0.5234, -0.1973,  0.1187]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.1250,  3.3438, -0.6133,  ..., -2.7656, -1.1953, -1.0469]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8711,  3.8125,  1.5625,  ...,  3.4062, -0.2100,  3.4531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([126], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0417, -0.0137,  0.1270,  ...,  0.0229, -0.1895, -0.0356]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1816,  0.0334, -0.1250,  ..., -0.0684, -0.0154,  0.1006]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-5.4375,  6.5312,  3.9062,  ..., -5.5312,  1.7500,  1.8594]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.7188, -0.0596, -1.6406,  ..., -0.4199, -1.3516, -0.9922]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([127], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0559,  0.0102,  0.0098,  ...,  0.0684, -0.0986, -0.1885]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1797, -0.4609, -0.1235,  ..., -0.4453, -0.1973, -0.3809]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.0000,  2.2812, -0.3398,  ...,  3.7812,  2.5625, -4.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.8047, -0.5977, -0.5352,  ...,  6.6250, -1.0234,  0.9141]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([128], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0513,  0.0178,  0.0547,  ..., -0.0110, -0.1445, -0.0859]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3340,  0.1167,  0.0505,  ...,  0.3242,  0.1050,  0.1201]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.1562,  4.3438, -0.4043,  ..., -3.9062,  4.8438, -0.5781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.5625,  0.0596, -2.4062,  ..., -1.5234, -0.2871, -0.3945]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([129], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0227, -0.0337, -0.0234,  ...,  0.0135, -0.0183, -0.0947]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1279, -0.3848,  0.0874,  ..., -0.1826, -0.1016,  0.0417]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.3750,   5.9375,  -0.0566,  ...,   0.4688,  -0.8984,  -2.2188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4219,  2.7031, -0.0713,  ...,  1.8906, -0.1216,  4.7188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([130], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0547,  0.0023,  0.1191,  ...,  0.0845, -0.1230,  0.0139]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2891, -0.0288, -0.1641,  ..., -0.0972,  0.0253,  0.1279]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-12.2500,   9.6875,   1.9844,  ...,  -3.2188,  -7.3750,  -1.3594]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.6406, -0.8203, -3.0469,  ..., -1.7266,  0.3770, -1.8672]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([131], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0405,  0.0291,  0.1021,  ..., -0.0522,  0.0569, -0.1206]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1826, -0.1357,  0.1504,  ..., -0.3164,  0.0913, -0.4023]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.8750,  1.4297,  3.3281,  ...,  8.5000, -9.5000, -6.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1738,  1.4688,  2.9219,  ...,  1.2891, -6.3750, -6.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([132], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0486, -0.1211,  0.0298,  ..., -0.0840, -0.0442, -0.0157]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0757,  0.0003,  0.0659,  ..., -0.0388, -0.1318,  0.0378]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.0625,  3.1875, -0.4590,  ..., -8.3750,  2.2031,  5.9062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.8828, -1.6328, -1.3359,  ...,  2.9219, -1.5938, -4.6875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([133], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0801,  0.0496,  0.0493,  ...,  0.1650, -0.1113,  0.0100]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1846, -0.0723,  0.0601,  ..., -0.0586,  0.0967, -0.0522]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -7.6250,   2.4375,   1.1250,  ..., -10.1875,  -0.3867,  11.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.8828,  0.5078, -3.3125,  ...,  1.2969,  1.2031, -6.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([134], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0571,  0.0723, -0.1396,  ...,  0.1089,  0.0349, -0.0603]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1553, -0.0486,  0.0449,  ...,  0.0337,  0.1118, -0.1240]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.9375,   4.0000,  10.3125,  ...,   4.9062,   0.6523,   4.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1797,  0.2363, -0.6602,  ...,  2.0000, -2.7812, -0.0854]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([135], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0491, -0.0386,  0.0135,  ...,  0.0762, -0.1611, -0.0854]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2051,  0.4238, -0.1001,  ..., -0.0640, -0.0041,  0.2295]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.5000,   3.4531,   6.8125,  ...,   1.6719,   4.8750,   1.2969]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.3672, -0.3828, -3.4844,  ...,  1.9844,  1.4453, -2.3594]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([136], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0669, -0.0723,  0.0033,  ...,  0.0742,  0.0476, -0.0525]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1157, -0.0815, -0.0273,  ...,  0.0261,  0.2490, -0.1377]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.4375,  2.0312,  7.7500,  ...,  0.3906,  5.4688,  1.9375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.3516,  0.5703, -8.3125,  ...,  1.1641, -2.6406,  1.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([137], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0297,  0.1079,  0.1025,  ..., -0.0635, -0.1338,  0.1201]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0581, -0.2373,  0.0840,  ...,  0.0933, -0.0240, -0.0007]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.9375,  -0.0273,   0.3008,  ...,  -2.7500,   3.0312,   1.6641]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4707,  4.4688,  0.9766,  ...,  0.6094,  3.3281, -2.0469]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([138], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0046, -0.1016,  0.1514,  ...,  0.1089, -0.1118,  0.1177]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1719, -0.0104, -0.0251,  ..., -0.0151, -0.0498,  0.0123]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -4.7188,   5.2812,  -6.9375,  ..., -11.3750,   2.6250,  -3.5469]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.1562,  0.9062, -1.1719,  ...,  1.3125, -2.2031, -1.0312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([139], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0071,  0.0771, -0.0084,  ...,  0.0137, -0.0396, -0.1123]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2949, -0.1992,  0.0148,  ..., -0.4980, -0.2012,  0.0854]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.5625,  3.3438,  1.0234,  ..., -2.8125, -2.3438, -3.4219]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.6367,  3.0781,  0.3926,  ...,  5.1250, -0.7695,  2.7812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([140], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0562, -0.0062,  0.1299,  ...,  0.0300, -0.1768, -0.0193]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1885,  0.0322, -0.1123,  ..., -0.0540, -0.0130,  0.1055]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-13.0000,   3.1250,   3.6094,  ...,  -6.7500,   3.0469,   0.4102]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.7500,  0.8320, -1.4688,  ...,  0.8672, -2.6094, -1.9219]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([141], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0569,  0.0164,  0.0121,  ...,  0.0664, -0.0815, -0.1836]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1934, -0.4531, -0.1328,  ..., -0.4473, -0.1982, -0.3887]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.8125,  1.8750, -1.6250,  ...,  2.3750,  2.9375, -0.6172]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.2812, -1.3359,  0.0400,  ...,  5.9375, -2.2031,  1.2969]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([142], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0674,  0.0220,  0.0557,  ..., -0.0094, -0.1318, -0.0796]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3398,  0.1099,  0.0466,  ...,  0.3105,  0.1074,  0.1099]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.7188,  1.1484, -5.4062,  ..., -5.3438,  3.0469, -1.2031]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.9453, -1.0703, -1.1406,  ..., -0.7617, -1.7812, -0.7266]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([143], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0239, -0.0262, -0.0258,  ...,  0.0119, -0.0002, -0.0854]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1367, -0.3594,  0.1016,  ..., -0.1768, -0.1060,  0.0591]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.7812,  2.5625, -2.9531,  ...,  2.2188, -3.5625, -1.4844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4707,  2.4062,  2.0312,  ...,  2.9531, -0.1885,  4.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([144], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0576,  0.0080,  0.1133,  ...,  0.0933, -0.1201,  0.0168]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2871, -0.0249, -0.1475,  ..., -0.0820,  0.0232,  0.1240]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.4375,   5.3438,   5.0000,  ...,  -0.7500,  -4.1562,   4.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.8945,  1.8906, -1.2266,  ...,  0.9688, -0.2471, -0.9531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([145], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0127,  0.0508,  0.0796,  ..., -0.0156,  0.0106, -0.0498]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1660, -0.0317, -0.0439,  ...,  0.2012, -0.0620, -0.1436]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.4375,  3.5781,  5.3438,  ...,  7.3125, -4.8438, -3.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2812,  1.6250,  2.8438,  ...,  4.0625, -5.8438, -6.4062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([146], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0806, -0.1416,  0.0500,  ..., -0.0742, -0.0334,  0.0095]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1396,  0.0530,  0.0972,  ...,  0.0240, -0.1631,  0.0364]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-14.0000,   5.2188,  -1.3203,  ...,  -3.7344,   4.4062,  10.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.0391, -0.4570,  0.6211,  ...,  1.0547, -2.3750, -3.2969]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([147], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0830,  0.0850,  0.0757,  ...,  0.1982, -0.1182,  0.0364]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1729, -0.0574,  0.0542,  ..., -0.0408,  0.1108, -0.0742]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-15.9375,   3.5000,  -0.5547,  ...,  -6.6875,   3.3750,  15.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.9492, -0.1680,  0.1826,  ...,  0.7500, -1.3359, -3.4531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([148], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0679,  0.0659, -0.1445,  ...,  0.1138,  0.0520, -0.0527]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1504, -0.0320,  0.0488,  ...,  0.0364,  0.1143, -0.1226]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.6875,   1.0859,   3.2812,  ...,   3.3125,   7.3125,  -0.9219]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1592, -0.2178, -0.6602,  ..., -0.7500, -0.8984, -0.3906]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([149], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0635, -0.0415, -0.0757,  ...,  0.0684, -0.0698, -0.1240]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2236, -0.1094,  0.1147,  ...,  0.0757, -0.0771, -0.1484]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.6406, -3.5625,  0.2344,  ...,  3.3125,  3.4375,  5.5625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2891, -0.0918, -0.1758,  ...,  4.2500, -2.8125, -1.8984]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([150], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0474,  0.0791, -0.0986,  ..., -0.0231,  0.1562, -0.0259]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3242,  0.5195,  0.1768,  ...,  0.1875,  0.1924,  0.1660]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.9375,  -0.3594,   3.9219,  ...,  -0.7188,  -2.5000,  -2.5938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ -1.1641,   7.2812,   1.0000,  ...,  10.6875,  -1.9219, -10.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([151], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0874, -0.0317, -0.0869,  ..., -0.0952,  0.0004,  0.2012]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0181,  0.1504, -0.1182,  ...,  0.0361, -0.0947, -0.1260]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.4375,  6.0625,  6.9062,  ..., -4.1875,  0.6406, -1.7266]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4668,  6.0000,  3.4688,  ..., -2.6562,  1.9062, -5.4688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([152], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1475,  0.0128, -0.0211,  ...,  0.1816, -0.0938, -0.0510]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4570,  0.1279, -0.0097,  ...,  0.0530, -0.1494,  0.2559]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.3750, -3.4062, -2.1094,  ..., -0.7812, 10.5000, 18.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.0156,  0.7500, -4.4375,  ...,  0.2227,  0.8438,  2.2344]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([153], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0417, -0.0894, -0.0630,  ..., -0.0133,  0.0840,  0.0090]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0146,  0.0432,  0.0276,  ..., -0.2109,  0.0129, -0.0708]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.5312, -3.9531,  3.9219,  ..., -2.5469, 11.0000,  2.6562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2188, -1.5000, -3.4375,  ...,  0.5586,  1.2266, -2.4531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([154], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1318, -0.0908,  0.0923,  ..., -0.0415,  0.0393,  0.0057]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2373, -0.1445, -0.1387,  ..., -0.1094,  0.0718, -0.0344]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-0.7617, -5.1875, 10.3750,  ..., 12.8750,  6.2812, -1.1094]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.7930, -1.7656, -1.8438,  ...,  2.1250,  1.4766,  0.0527]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([155], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0781, -0.0084,  0.0166,  ...,  0.2295, -0.0830, -0.0742]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3496,  0.1582,  0.2422,  ...,  0.0183,  0.1855,  0.1670]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.0000,  0.6484, -0.3594,  ..., -4.9688, 14.9375,  0.4180]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8164, -0.6797, -4.6875,  ...,  1.5312,  1.3438, -1.3359]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([156], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0864, -0.0325,  0.0537,  ...,  0.0104,  0.0544, -0.0106]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3672,  0.0281, -0.0452,  ..., -0.0215,  0.0271,  0.1367]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 1.8125e+00, -3.7812e+00,  5.5312e+00,  ...,  7.8125e-03,\n",
      "          5.3750e+00,  9.0000e+00]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.5742,  1.5625,  0.0410,  ...,  6.0312, -4.9375, -0.4141]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([157], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0073,  0.0693, -0.0967,  ...,  0.0151,  0.1182, -0.0972]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2852,  0.4648,  0.1611,  ...,  0.1260,  0.1992,  0.1592]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.8125,  -0.6211,   0.8281,  ...,  -5.2500,  -2.6250,  -4.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.4375,  3.6562,  1.2422,  ..., 10.0000, -2.1250, -8.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([158], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1240, -0.0306, -0.0806,  ..., -0.0918, -0.0217,  0.2080]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0106,  0.1338, -0.1138,  ...,  0.0157, -0.0728, -0.1235]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.0000e+00,  6.6250e+00,  1.1312e+01,  ..., -6.6875e+00,\n",
      "         -3.9062e-03,  5.7812e+00]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.3438,  3.5156,  3.1094,  ..., -0.4004,  2.6719, -3.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([159], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 1.2207e-04,  7.9346e-03,  1.5625e-02,  ...,  1.4648e-01,\n",
      "         -3.3936e-02,  4.2236e-02]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4375,  0.2988,  0.0035,  ..., -0.0129,  0.2275, -0.0007]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.6875,   2.2031,  -3.5938,  ...,  -0.8945,  -2.0312,  12.6875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[0.6367, 2.0781, 1.8750,  ..., 0.0151, 0.2168, 0.9766]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([160], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0344, -0.0693,  0.1543,  ...,  0.1187,  0.0598, -0.0058]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0933, -0.1445,  0.0330,  ...,  0.0398,  0.1982, -0.0009]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.3438,  4.6875,  3.9375,  ...,  1.3906,  9.9375,  5.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.1016, -0.9375,  0.7031,  ..., -1.5859, -0.4629, -1.0859]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([161], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0640, -0.0052, -0.0231,  ...,  0.0233, -0.0557, -0.0918]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0047,  0.0913, -0.3477,  ...,  0.1973, -0.0552, -0.3672]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.0938,  3.3438,  4.6875,  ..., 10.9375,  2.8594,  2.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.6719, -0.5312, -2.7031,  ...,  2.0625,  0.9609, -1.3203]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([162], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0293,  0.0258, -0.0688,  ...,  0.0444,  0.0581,  0.0070]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0869, -0.1904, -0.1895,  ..., -0.0073,  0.1123,  0.0228]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.0938,  9.1875,  6.3750,  ...,  6.1250, -3.1406,  2.7500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1914, -0.1885, -0.5625,  ..., -0.2969,  0.9062, -1.8594]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([163], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1729,  0.0130,  0.0549,  ...,  0.2832, -0.0938, -0.1992]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.3535, -0.0442, -0.0718,  ...,  0.1050, -0.0669, -0.3965]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.4375, -5.5625,  8.5000,  ...,  5.1875, -8.2500,  3.3594]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3906,  0.8125, -0.9219,  ...,  1.0312, -0.6641, -0.0303]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([164], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0635, -0.0405,  0.0923,  ...,  0.1875, -0.1650,  0.0101]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0004,  0.0918, -0.0659,  ..., -0.0204, -0.2217,  0.0376]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-13.3750,   6.6250,   5.5625,  ...,   5.6875,  11.9375,   3.7656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.4531, -1.4766, -0.2344,  ..., -1.1719,  0.1914, -1.4062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([165], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1621, -0.0281,  0.1108,  ..., -0.1050, -0.0022, -0.0161]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3555, -0.0938, -0.0344,  ...,  0.2539,  0.1709,  0.0513]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.2500,   9.1875,   2.8594,  ...,   6.4375,   5.8438,   2.9531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1836,  0.2266, -0.9062,  ..., -1.3125,  2.4688, -0.5508]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([166], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1348, -0.0229,  0.0688,  ...,  0.1562,  0.0508, -0.0309]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1123, -0.1484, -0.1206,  ...,  0.0532,  0.1436,  0.0135]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-13.1875,   9.4375,   7.0000,  ...,   2.3438,   6.5938,  -4.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.5664,  0.9727, -3.7969,  ...,  0.2041, -1.3828, -0.7500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([167], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0664,  0.1348,  0.0869,  ..., -0.0649, -0.0972,  0.1260]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0640, -0.2432,  0.1094,  ...,  0.0654, -0.0347, -0.0498]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-12.2500,   4.0312,   7.7500,  ...,  -2.5625,   5.1875,  -1.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2109,  1.3438,  0.5781,  ..., -3.0156, -1.6797, -5.2188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([168], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0352, -0.0291,  0.0820,  ...,  0.0325, -0.0610, -0.0210]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1445, -0.0588,  0.0559,  ..., -0.1367,  0.0767,  0.1138]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.6250, -0.1953,  3.2969,  ...,  0.0156, -6.9688,  2.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0161,  0.2256,  0.9297,  ..., -1.6328, -1.3203, -2.7188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([169], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0259, -0.0515,  0.0291,  ...,  0.0474, -0.0669, -0.0190]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0703, -0.1289,  0.1328,  ...,  0.1348,  0.0806, -0.0649]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.4375, -1.3594,  5.4688,  ...,  1.1562, -7.0625,  2.1094]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.4688,  1.1797, -4.2812,  ..., -1.6875,  1.2812, -5.5938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([170], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0250,  0.0562,  0.0447,  ..., -0.0415,  0.0181,  0.0087]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1045, -0.0513,  0.1084,  ..., -0.0801,  0.1562, -0.0378]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.5234, -2.0156,  3.9375,  ..., -3.6094, -4.4062,  3.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.0156,  0.7305, -5.0938,  ..., -2.2344, -1.8359, -7.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([171], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0269,  0.0454,  0.1953,  ..., -0.0347, -0.0845, -0.1230]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0938, -0.0588, -0.0312,  ...,  0.2422,  0.0698, -0.0525]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 1.9375,  0.2617, -2.0625,  ...,  2.4062, -9.4375,  3.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3535,  0.9531, -2.9531,  ..., -1.7422,  0.9492, -0.9492]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([172], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0488, -0.0033,  0.0620,  ...,  0.0640, -0.0305,  0.0135]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0181, -0.0148,  0.0923,  ...,  0.0339,  0.0771, -0.1001]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 5.0938,  1.3750, -9.1875,  ..., 11.6250, -2.0000,  5.3438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ -2.7500,   2.4844,  -4.0625,  ...,  -2.5000,   5.0625, -10.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([173], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0332,  0.0410,  0.0435,  ..., -0.0444,  0.0356,  0.0131]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1377, -0.0014,  0.0957,  ..., -0.0732,  0.1455, -0.0586]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 6.6875,  7.7812, -7.0938,  ...,  7.7812,  2.1250, 12.8125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1504,  1.4609, -4.5938,  ..., -7.6250, -1.2656, -7.9062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([174], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0623,  0.1201,  0.1465,  ..., -0.0125, -0.0226, -0.1309]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0066, -0.0615,  0.0032,  ...,  0.2285,  0.0457,  0.1152]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 1.8828,  3.1250,  1.1562,  ...,  3.5469, -0.7852, -4.7500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2031,  1.8906, -3.8750,  ..., -0.0742,  0.7109, -0.5781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([175], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0544,  0.0085,  0.0552,  ...,  0.0250, -0.0654,  0.0095]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0471,  0.0229,  0.1104,  ...,  0.0141,  0.0845, -0.1187]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -1.3750,  -4.5625, -13.2500,  ...,  17.0000,   2.8438,  -8.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.6094, -1.3516, -4.9688,  ...,  3.4375,  3.6250, -4.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([176], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0386,  0.0430,  0.0417,  ..., -0.0488,  0.0408,  0.0025]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1680,  0.0398,  0.0967,  ..., -0.0640,  0.1357, -0.0806]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[  2.0312,  -5.0000, -17.0000,  ...,  10.7500,   7.3438,  -4.0000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 3.4062, -0.3320, -3.2969,  ...,  3.1094, -1.5234, -5.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([177], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0223, -0.0259,  0.0874,  ..., -0.0486,  0.0586, -0.1084]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0439,  0.0493,  0.0659,  ..., -0.0315,  0.0640,  0.0214]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[  6.7188,   1.6719,  -9.5625,  ...,   3.0312, -12.0625,  -5.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.1797, -2.9531, -1.1719,  ..., -4.2500,  1.3750, -1.9297]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([178], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0767, -0.0859,  0.0437,  ...,  0.0640,  0.0679, -0.0825]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1484, -0.1201,  0.2236,  ..., -0.0203,  0.1035, -0.0684]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 2.7812, -1.3672, -1.7969,  ...,  7.3438, -1.8125, -1.6016]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.7031,  1.9844, -1.9141,  ..., -1.7344,  0.0469, -1.0781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([179], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0703,  0.0212,  0.0854,  ...,  0.0052, -0.0053, -0.0035]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0603,  0.0150,  0.0417,  ..., -0.0186,  0.0898, -0.1016]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.7188,  3.1406, -6.6250,  ..., 16.1250, -4.3750,  4.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 4.2188, -3.6094, -4.1562,  ..., -0.2090,  2.2656, -5.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([180], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0095,  0.0491,  0.0430,  ..., -0.0559,  0.0598,  0.0038]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1680,  0.0376,  0.0762,  ..., -0.0327,  0.1348, -0.0864]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.1875,  6.4375, -1.6562,  ..., 13.1875, -5.0625,  8.0000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 5.5312, -1.4922, -0.1875,  ..., -5.1562, -2.1094, -5.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([181], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0042, -0.0366,  0.0801,  ..., -0.0500,  0.0723, -0.0986]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0386,  0.0645,  0.0786,  ..., -0.0339,  0.0791,  0.0311]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -0.3516,   2.2188,  -7.1562,  ...,   4.2500, -10.3125,   3.4062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.0625,  0.3262,  0.6250,  ..., -4.6562,  0.8945, -2.2344]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([182], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0420,  0.0154,  0.0698,  ...,  0.0371,  0.0256,  0.0028]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0898,  0.0167,  0.0437,  ...,  0.0228,  0.0598, -0.1089]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -9.3750,   6.7188, -21.0000,  ...,   9.4375, -10.2500,  -0.1680]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.1562, -1.3516, -3.4219,  ...,  1.3281,  2.2188, -4.7500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([183], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0317,  0.0403,  0.0400,  ..., -0.0540,  0.0645,  0.0029]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1904,  0.0422,  0.0869,  ..., -0.0292,  0.1318, -0.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.1875,  14.6250, -26.1250,  ...,   3.3906,  -6.8125,   9.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 5.1875, -0.0527, -3.4688,  ...,  1.9688, -5.3125, -6.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([184], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0052,  0.0211,  0.1367,  ..., -0.0199, -0.0408, -0.0913]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0102,  0.1074,  0.0894,  ...,  0.0618,  0.0874, -0.0237]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 2.5312, -4.5312,  1.3203,  ...,  3.6406, -4.5938,  9.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.6641,  2.2344, -2.0938,  ..., -0.4453, -0.6953, -0.8945]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([185], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0635, -0.0089,  0.0679,  ..., -0.0019,  0.0001,  0.0166]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0820,  0.0162,  0.0625,  ...,  0.0021,  0.0859, -0.1367]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-12.8750,  10.8125,  -2.5625,  ...,   8.6875,  -0.4414,  11.5625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.8125, -2.5312, -0.8984,  ..., -2.7812,  0.4199, -1.5781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([186], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0237,  0.0322,  0.0393,  ..., -0.0645,  0.0562,  0.0038]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2051,  0.0461,  0.0908,  ..., -0.0236,  0.1309, -0.0884]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-12.3125,  16.5000,  -3.6719,  ...,   3.1250,   0.6211,  20.3750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.9297, -1.2500,  2.4531,  ..., -4.1562, -5.6562, -3.1094]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([187], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0081, -0.0388,  0.0972,  ..., -0.0452,  0.0549, -0.0991]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0315,  0.0608,  0.0630,  ..., -0.0232,  0.0845,  0.0310]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -3.1250,  -2.1562, -14.9375,  ...,   1.9766, -22.7500,   3.4688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2246,  0.4082,  2.5000,  ..., -1.5078, -1.2734, -2.9531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([188], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0552,  0.0044,  0.0703,  ...,  0.1602, -0.0400, -0.0649]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2441, -0.1235,  0.0281,  ..., -0.0737,  0.1377, -0.0322]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-13.6875,  -7.2188,   2.8281,  ...,   5.4688,   2.8281,   1.1484]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0488,  0.5234,  3.6250,  ...,  0.4199,  4.4688, -2.5938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([189], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0359, -0.0422, -0.0938,  ...,  0.1309, -0.1289, -0.1846]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0415,  0.1387, -0.0889,  ...,  0.1445,  0.1494,  0.1001]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-14.0625,   2.8750,   9.0000,  ...,  -2.0312,   5.7500,   0.9258]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.3203,  1.6406,  3.4219,  ..., -1.2344,  0.0947, -1.1328]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([190], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0635, -0.0454, -0.0184,  ..., -0.1436,  0.0635, -0.1846]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2598, -0.0913, -0.2109,  ...,  0.2578,  0.3457, -0.0591]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.4375, -0.7422,  6.8125,  ...,  1.9844,  3.3438,  1.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.7734,  0.6953, -1.3047,  ...,  0.6211,  2.4844, -2.5781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([191], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0679, -0.0347,  0.0437,  ...,  0.1123,  0.0540, -0.1040]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1318, -0.1367, -0.1621,  ...,  0.0222,  0.1963, -0.0674]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.1719, -8.0625,  5.9375,  ...,  3.7656, 10.1875,  2.3906]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.6094,  3.3594, -0.9492,  ...,  5.1875, -6.0312, -2.8594]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([192], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0166,  0.0752, -0.0776,  ..., -0.0101,  0.1572, -0.0591]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3652,  0.4648,  0.2090,  ...,  0.2051,  0.1289,  0.2207]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-12.1250,  -1.3828,   1.8750,  ...,  -1.3047,  -1.8984,  -3.2188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.3672,  4.6875,  2.4062,  ..., 10.7500, -1.7969, -9.9375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([193], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1108,  0.0035, -0.0752,  ..., -0.0850,  0.0019,  0.1641]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0295,  0.1367, -0.0903,  ...,  0.0557, -0.1289, -0.1001]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.6875,  2.2188,  2.3438,  ..., -1.6562,  4.6562,  2.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-4.5312,  3.9375,  0.5703,  ..., -2.0781,  1.6484, -2.2031]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([194], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0430, -0.0004,  0.0762,  ...,  0.0527,  0.0044, -0.0605]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4219,  0.0089, -0.0142,  ...,  0.3301,  0.1494,  0.0035]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.3125,   2.1250,  -7.1562,  ...,  -2.5469,   3.4062,  12.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3828,  1.1875, -0.0869,  ..., -0.1582,  0.0640, -0.2852]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([195], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0128, -0.0190,  0.0889,  ...,  0.0938,  0.1279, -0.0115]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0613, -0.1230,  0.0201,  ..., -0.1445,  0.2188, -0.0354]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-15.1250,  -1.2500,   0.4980,  ...,  -2.0000,   4.5625,   0.2754]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1797,  0.1895,  2.1406,  ...,  1.7578,  3.2656, -3.1719]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([196], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0374, -0.1396, -0.1387,  ...,  0.0417, -0.0093, -0.1387]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2734, -0.3164, -0.2832,  ..., -0.3320, -0.3789, -0.0483]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.2500, -2.5156,  7.4062,  ..., -1.0469,  2.0625,  2.4844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.7734,  0.3086,  1.0625,  ..., -2.4219, -0.3164,  0.2715]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([197], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0049,  0.0299, -0.1099,  ...,  0.3105, -0.0564, -0.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2637,  0.2773,  0.0693,  ...,  0.1045,  0.0222, -0.0253]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-15.3750,   5.6250,   2.5000,  ..., -10.1250,   4.6250,   3.0156]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2207,  4.0312,  3.9688,  ..., -0.4668, -0.6328,  3.4844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([198], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0371, -0.0654,  0.0057,  ..., -0.1328,  0.0613, -0.1157]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2236,  0.0181, -0.2461,  ...,  0.2734,  0.2812,  0.0510]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.3750,  -0.3242,  -5.6875,  ...,  -2.6719,  -0.4883,   8.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.3477,  1.0078, -2.6875,  ..., -0.1240,  0.1211,  0.7656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([199], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0014, -0.0566,  0.0498,  ...,  0.0295,  0.0742,  0.0025]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1055, -0.0830, -0.0139,  ..., -0.1406,  0.1748, -0.0430]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-14.5625,   2.5312,   2.3906,  ...,   0.0664,  -2.2812,  10.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2734, -1.6875,  2.2344,  ..., -0.4727, -0.2852, -2.3281]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([200], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0275, -0.0879, -0.0281,  ...,  0.0366, -0.0378, -0.1465]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0859, -0.1162,  0.2412,  ..., -0.4141, -0.1465, -0.1494]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.7500,  -1.0312,  -1.0312,  ...,  -5.6875,  -1.5078,  10.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2031,  1.0703, -1.2500,  ..., -1.3516, -5.0625, -5.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([201], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-3.1006e-02,  4.5898e-02,  8.6914e-02,  ...,  1.5234e-01,\n",
      "         -2.7710e-02,  1.2207e-04]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4961,  0.0732, -0.0786,  ..., -0.2090,  0.3418, -0.0311]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-12.6250,   1.3750,  -4.6250,  ...,  -0.2266,   0.8750,   1.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.2344, -1.7109, -1.2344,  ...,  1.8438, -0.5234, -0.8398]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([202], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0442, -0.0248,  0.0141,  ...,  0.1533,  0.1504, -0.0942]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.3145,  0.1895,  0.2295,  ..., -0.0566, -0.1982, -0.0996]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.7812, -3.4219, -0.4863,  ...,  5.7188,  7.4062, -1.9062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3672,  0.6992, -3.0312,  ..., -1.1016,  0.8125,  0.2734]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([203], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.2295, -0.2207, -0.0649,  ..., -0.0718, -0.0923,  0.1074]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0064, -0.2021, -0.1973,  ..., -0.4062,  0.0801,  0.2236]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.2500, -0.7188,  2.7500,  ..., -0.0391, -5.0312,  7.7188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2773,  1.3750,  0.8516,  ...,  0.3047,  0.6055, -0.8594]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([204], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1201,  0.0327,  0.0294,  ...,  0.2188, -0.1846, -0.1211]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1235,  0.0080, -0.0635,  ..., -0.1475, -0.1680,  0.0598]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-15.4375,   0.1016,   1.7344,  ...,   3.3594,  -1.9766,  -1.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1162, -1.4297, -0.0513,  ...,  1.0625, -2.2031, -1.1953]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([205], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0145, -0.0177,  0.0205,  ...,  0.0430,  0.1504, -0.1279]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0820,  0.0029,  0.0178,  ..., -0.0640,  0.0352,  0.0820]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.7500, -2.5781,  1.4766,  ...,  2.0625,  5.3750, 10.9375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.6250,  0.2285, -2.2656,  ..., -2.4219,  2.3906, -2.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([206], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1406, -0.0908,  0.0466,  ...,  0.0312,  0.0267,  0.0444]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2715,  0.1064,  0.0728,  ...,  0.0840, -0.0510,  0.0923]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-17.2500,  -9.8125,  -4.0938,  ...,   6.5000,   0.0625,   4.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3828, -0.7617, -4.3438,  ..., -2.0938, -0.7617, -2.7656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([207], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0254, -0.0308,  0.0713,  ...,  0.0791, -0.0344, -0.2207]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2559,  0.0840, -0.0801,  ...,  0.0131, -0.3262,  0.2891]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-13.3125,  -6.8750,  -3.0000,  ...,   7.5000,  -0.9414,   8.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-4.4375, -0.5898, -0.8984,  ..., -0.6484,  1.4375, -5.5938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([208], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0121,  0.0052, -0.0405,  ...,  0.1064, -0.1533, -0.0693]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0557, -0.1836,  0.0071,  ..., -0.1787, -0.0183, -0.0322]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-14.0625,  -0.9141, -10.8750,  ...,   7.6875,   6.4062,   8.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.7930, -1.3906, -1.1797,  ...,  6.0000,  2.3594, -2.7188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([209], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.2090,  0.0422, -0.0266,  ...,  0.1953,  0.0400, -0.0649]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1055, -0.0079,  0.0879,  ...,  0.5273,  0.1064, -0.2148]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-14.7500,   3.9375,  -6.9062,  ...,   8.4375,   2.1250,   3.2344]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8750,  2.4062, -3.7031,  ...,  1.5000,  0.1758, -0.3945]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([210], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0378, -0.2236, -0.0425,  ...,  0.2852,  0.0820, -0.1357]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1016,  0.1079, -0.1123,  ..., -0.0420,  0.0840,  0.1123]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -4.8438, -10.2500,  -6.4375,  ...,   7.3125,   2.4219,  -1.9297]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.5625, -0.7891, -1.5938,  ...,  0.2539, -1.3125, -3.2031]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([211], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0884, -0.0625,  0.0178,  ...,  0.0522, -0.0459, -0.0820]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1602, -0.1650, -0.1553,  ...,  0.0664,  0.1523,  0.0703]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.9688, -4.6875,  0.7109,  ...,  5.7188,  9.3750, -6.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2109, -0.4648, -1.4766,  ..., -2.1875, -3.1875,  0.6406]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([212], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0718,  0.0967, -0.0025,  ...,  0.0957,  0.0457, -0.0371]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0133,  0.0188,  0.0359,  ..., -0.1621, -0.0522,  0.1680]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.2500,  1.8594,  6.8750,  ..., -2.5625,  6.0625,  0.6602]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.9531, -1.5703, -3.1406,  ..., -0.8594, -0.3652, -0.0381]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([213], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0498, -0.0120, -0.0415,  ..., -0.0267,  0.0344, -0.1143]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1147,  0.0156,  0.0996,  ...,  0.0032,  0.0033,  0.0874]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.2188, -5.4688,  0.9922,  ..., -1.6328, -9.1250, -2.8125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2344, -0.6055,  0.2812,  ..., -2.5312, -0.2988,  0.1045]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([214], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1787,  0.2139,  0.0083,  ..., -0.0581, -0.0072, -0.1582]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1045, -0.0708, -0.1475,  ..., -0.1523,  0.0121, -0.0928]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.9062, -7.9375, -4.5938,  ..., -0.1250, -7.0938, -0.8281]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4453, -1.2031, -1.3359,  ..., -2.6250, -1.4062, -0.7461]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([215], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0557, -0.0625,  0.0015,  ..., -0.1133,  0.0200,  0.0304]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2070,  0.0679, -0.0146,  ...,  0.1157,  0.1138, -0.1104]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.0000, -6.4688, -5.0625,  ...,  6.7500, -6.6250,  8.3750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.2969, -3.1406, -3.8281,  ...,  2.7031, -3.3438, -4.7500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([216], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1206, -0.0952,  0.0859,  ..., -0.0371, -0.0078, -0.0679]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0118, -0.0977, -0.0192,  ...,  0.1309,  0.0728, -0.0084]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -5.4688,  -4.5000, -13.4375,  ...,   3.9844,   4.2812,  -1.0078]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.7734,  2.1719, -1.7812,  ..., -1.6406, -3.7969, -0.5039]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([217], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0003, -0.0223,  0.0947,  ...,  0.0269, -0.0747, -0.0737]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3613,  0.1030, -0.0625,  ..., -0.1992,  0.2031, -0.1035]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-0.0586, -6.8750, -6.1250,  ...,  5.6250,  0.3320,  4.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8047,  0.8359, -5.6562,  ...,  0.3066, -0.9727, -2.5938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([218], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0347,  0.0820,  0.1069,  ..., -0.0928,  0.0327, -0.0038]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1738,  0.0022,  0.0209,  ...,  0.0398,  0.0645, -0.0483]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.7812, -1.9922, -1.1094,  ...,  6.5312,  1.7344,  9.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.0781, -3.3438, -4.0312,  ...,  4.5000, -3.0156, -7.3438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([219], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0101, -0.0310,  0.0374,  ..., -0.0248,  0.0588, -0.0972]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0243,  0.0483,  0.0471,  ..., -0.0439,  0.0703,  0.0225]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -2.0625,   6.8438, -10.1875,  ...,  -0.8438,   3.7188,  -2.4062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.1406,  0.7656, -3.4219,  ..., -1.2422, -1.2422, -1.1016]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([220], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0261,  0.0211, -0.1226,  ..., -0.0240, -0.0713,  0.0182]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0050, -0.2812,  0.1089,  ..., -0.0972,  0.0781, -0.1187]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.2500,  0.4727, -2.5312,  ..., -1.2188, -0.5625,  6.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.3516,  0.4043, -0.8906,  ..., -0.1191, -0.8672, -0.2051]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([221], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0278, -0.0342,  0.0014,  ..., -0.0276,  0.0496, -0.0293]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1079, -0.1396, -0.1138,  ..., -0.0674,  0.1187,  0.1035]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -6.9375,  -0.2773, -11.5000,  ...,   2.4688,   1.2812,   2.9062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.3906, -1.2109, -1.4766,  ..., -1.2891, -1.7969, -0.3984]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([222], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0513, -0.0189,  0.0771,  ..., -0.1338,  0.0918, -0.0203]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0216, -0.0508,  0.0908,  ..., -0.0728,  0.0117, -0.1025]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.8125,  4.5000, -5.0312,  ...,  6.4375, -9.1875,  5.5938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.3672,  2.1562, -1.0000,  ..., -0.2090, -1.4219, -0.9297]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([223], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1572,  0.1162, -0.0645,  ..., -0.1660, -0.0317, -0.1357]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1641,  0.1406, -0.1719,  ..., -0.0454, -0.1738,  0.2109]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 5.5000, -3.0469, -4.2188,  ...,  2.9375, -0.7891,  6.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8984, -0.5781, -2.2812,  ...,  0.1367, -1.4531,  0.8008]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([224], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1914, -0.1011, -0.1113,  ...,  0.0991,  0.0027, -0.1240]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0552, -0.1060, -0.5508,  ...,  0.0635,  0.0010,  0.0469]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 2.3438, -2.7188, -1.6328,  ...,  7.4375,  3.2500, -4.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.2344, -2.0469,  2.9688,  ...,  0.8750, -2.1562,  1.2812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([225], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0269, -0.1162, -0.1279,  ...,  0.0317, -0.1875, -0.1064]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0293, -0.1211, -0.0554,  ...,  0.1406,  0.2188, -0.1523]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.7578, -2.2812,  0.6836,  ...,  7.8750,  2.4688, 10.3750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0112,  1.1562, -0.7539,  ..., -0.9805, -0.2441, -0.6641]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([226], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0141,  0.0535,  0.0339,  ..., -0.0366, -0.0325,  0.0173]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1172, -0.0762, -0.0684,  ..., -0.0806,  0.0957,  0.0115]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.1211, -1.9531, -8.0000,  ...,  1.2344,  2.8750,  4.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.9023, -1.3594, -0.9531,  ..., -0.7734, -0.1602,  0.6719]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([227], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0322, -0.1309, -0.0139,  ..., -0.0581,  0.0099, -0.1055]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1641, -0.2734,  0.0684,  ...,  0.0596,  0.1787, -0.0060]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.4062, -1.1562, -9.0625,  ...,  3.8750,  3.9062,  3.1094]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.0156, -0.4707, -1.2812,  ..., -0.8672, -1.1406,  0.2773]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([228], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0188,  0.1138,  0.0850,  ..., -0.1377,  0.0322, -0.1367]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2520,  0.1572, -0.0991,  ..., -0.1289,  0.0278,  0.2969]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.4375, -6.1250, -9.9375,  ...,  1.0312,  2.4375,  3.7812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.1016, -0.0588,  0.0527,  ..., -1.7500, -1.3359, -0.3105]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([229], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0077,  0.0459, -0.0118,  ..., -0.0659, -0.0806, -0.2021]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1426, -0.0532,  0.0776,  ...,  0.1230, -0.0698,  0.2178]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.3281,  3.4219, -5.5938,  ...,  5.5625,  5.3438,  4.0312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.6172, -0.6641, -0.2021,  ..., -2.3906, -2.0469,  0.1279]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([230], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.1191,  0.0542,  0.1016,  ..., -0.1846,  0.0723, -0.0129]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0747, -0.1455,  0.2461,  ...,  0.0588, -0.1235, -0.1367]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.3281, -0.8633, -4.4688,  ...,  1.4453,  3.3906,  0.9297]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8125,  1.3984,  0.3125,  ..., -0.9062,  0.1221,  0.5781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([231], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0173,  0.0708,  0.1211,  ..., -0.1484,  0.1162, -0.0903]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0771, -0.1157,  0.1953,  ..., -0.1377,  0.0723,  0.1230]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.7812, -4.4375, -2.1562,  ...,  6.6562, -0.9141,  6.8125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.9219, -0.9570, -1.7344,  ..., -1.8203, -2.6250, -0.8633]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([232], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0850, -0.0009, -0.0737,  ..., -0.1514, -0.0610, -0.0405]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0879,  0.2793,  0.0630,  ..., -0.1895, -0.2021,  0.0825]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.2188,  0.3945, -3.0938,  ...,  2.2344, -3.7969,  5.0312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.5625,  1.5625,  1.1328,  ..., -0.0088, -1.0703, -1.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([233], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0723,  0.0090,  0.0737,  ...,  0.0391,  0.0654, -0.0388]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0574, -0.1436, -0.0649,  ..., -0.0208,  0.1611,  0.1089]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.5625,  -2.4688,  -3.0938,  ...,   0.9219,   1.3750,   5.2812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.5859, -4.1562, -1.2500,  ...,  4.5000, -0.2578, -2.6875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([234], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0266,  0.0045,  0.0518,  ..., -0.0148,  0.0019, -0.1719]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0894,  0.1138,  0.0718,  ...,  0.1289,  0.0859, -0.0518]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.8125,   0.9531,  -4.1250,  ...,   0.9219,  -3.6875,   6.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 3.9844,  0.0894, -7.2500,  ..., -0.4375,  4.9062, -4.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([235], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1006,  0.0017,  0.1025,  ..., -0.0459, -0.0135, -0.0295]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1152,  0.2754, -0.0388,  ...,  0.0559, -0.0698,  0.0708]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.0625,  -2.8906,  -6.7812,  ...,  -3.7812,  -1.4062,  -0.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.1406, -3.1094, -4.5938,  ..., -0.9844,  1.0312, -3.4219]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([236], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0034,  0.0786,  0.1689,  ...,  0.0786,  0.0271, -0.2148]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2578,  0.1660, -0.1406,  ...,  0.0938, -0.2793,  0.3398]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.6250,   0.9727,  -1.7734,  ...,   2.2969,  -0.9453,  -3.4062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-5.0625, -1.7578, -0.1875,  ...,  6.3125,  4.4688, -3.3281]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([237], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1592, -0.1045,  0.1914,  ...,  0.1543,  0.0072, -0.0459]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0442, -0.2314,  0.0262,  ..., -0.1484,  0.0781, -0.0427]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-13.4375,  -2.7188,  -0.3203,  ...,   7.5000,  -6.2500,  -6.0312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ -4.5312,   1.7891,  -1.7266,  ..., -10.5000,  -3.0938, -15.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([238], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1104,  0.0806,  0.0972,  ..., -0.2891,  0.0352, -0.1299]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0952, -0.1650,  0.1279,  ..., -0.1621, -0.1299, -0.0289]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.4375,  -0.2422,  -6.0938,  ...,   4.4062,   3.4531,  -5.4062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.1094, -2.4375, -1.1406,  ...,  5.7500,  1.4062, -1.7734]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([239], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0116,  0.0306,  0.1143,  ..., -0.0610,  0.0164, -0.2617]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1416,  0.0972,  0.0184,  ...,  0.1934,  0.2773, -0.0786]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.5625,   1.0469,   1.1875,  ...,   2.9844,   3.7188,   1.7578]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.9141,  1.2031, -2.3438,  ...,  2.6406, -0.5547, -2.5781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([240], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0503, -0.1465, -0.0308,  ...,  0.2178,  0.0996, -0.1572]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1357,  0.0579, -0.1670,  ...,  0.0228,  0.1465,  0.0664]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -5.8125,  -6.3438, -10.8750,  ...,   3.7500,   3.7500,   2.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.9297, -4.3750, -0.3203,  ...,  1.2969,  0.5586,  0.6523]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([241], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0649, -0.0378,  0.0535,  ..., -0.0884, -0.0205, -0.0630]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3613,  0.3379,  0.2461,  ..., -0.0028, -0.0038,  0.3809]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -4.7812,  -2.4688, -14.8125,  ...,   2.7656,   0.5195,  -1.7969]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.4531, -3.0156, -0.0547,  ...,  2.9531, -2.8125,  0.2393]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([242], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.1084,  0.0352, -0.0210,  ...,  0.1123,  0.0635, -0.1006]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0603, -0.3633,  0.1553,  ...,  0.4434,  0.0547, -0.1152]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.7188,  2.9062, -6.3438,  ...,  8.7500,  4.8438,  5.4688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.5938, -1.0625, -0.1299,  ..., -2.4844, -4.2500, -1.8828]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([243], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0317,  0.0398,  0.0200,  ..., -0.1328,  0.0103, -0.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0413, -0.1011,  0.2266,  ..., -0.1475, -0.0757, -0.0381]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.2500, -7.1250,  6.2500,  ...,  3.6250,  1.5625, -0.9844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4023, -0.8906, -1.0938,  ..., -1.4141, -3.2344, -1.0156]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([244], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0276, -0.1035,  0.0542,  ..., -0.1592, -0.0403, -0.0422]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0532, -0.0732,  0.1030,  ..., -0.0496, -0.0403,  0.0306]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.6875,  3.3438,  4.6875,  ..., -5.4688, -5.0312,  1.7109]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2734, -1.3203,  0.6953,  ..., -1.2891, -0.5430, -0.0298]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([245], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0055,  0.1250, -0.0396,  ..., -0.0474,  0.0518, -0.0264]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0449, -0.3613,  0.1152,  ...,  0.0118,  0.0014, -0.1406]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.5625, -1.9688,  0.4434,  ..., -1.9141, -5.7500, -0.4141]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8398, -0.8984, -0.0801,  ..., -0.2930, -0.8047, -0.4688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([246], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0369,  0.0596,  0.0466,  ..., -0.0334,  0.0879, -0.0884]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1025, -0.0767,  0.0381,  ...,  0.0045,  0.0075, -0.0134]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.5312, -9.0000, -9.7500,  ...,  4.1562, -0.4980,  5.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.8906, -2.0781, -1.8203,  ...,  2.1406, -1.6016, -0.6523]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([247], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1201, -0.0488,  0.0227,  ...,  0.0605, -0.1045, -0.1787]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0009,  0.1328, -0.0374,  ..., -0.1084, -0.1436,  0.2109]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.9375, -1.6250, -6.7188,  ...,  1.1172,  4.1250,  5.2188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3203, -1.3516,  0.4414,  ..., -1.8438, -0.3555,  0.0864]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([248], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.1206,  0.0879,  0.1777,  ...,  0.2520,  0.0791, -0.0127]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0209, -0.1680, -0.3281,  ...,  0.3242,  0.1709, -0.1299]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.2812,  3.2812, -3.3125,  ...,  7.8125,  2.1562, -1.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.9883, -1.0469, -1.6328,  ..., -2.1406,  1.2188, -0.9570]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([249], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1553,  0.1738,  0.0493,  ...,  0.0033,  0.0309, -0.0090]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2676, -0.1807,  0.4961,  ..., -0.4355,  0.0439,  0.2109]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -5.7812,   1.0938, -10.5000,  ...,   1.2422,   5.0938,   8.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.9375, -0.0198, -0.1777,  ...,  0.1201, -0.3965, -1.3047]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([250], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0110,  0.0265,  0.0586,  ..., -0.0178, -0.0039, -0.1064]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0830, -0.1318, -0.0515,  ..., -0.0718, -0.0056,  0.1367]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -8.5000,  -2.0625, -14.3750,  ...,   1.6875,   7.1875,   6.8125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.4531, -0.7930,  0.4805,  ..., -0.2480, -1.6953,  0.3496]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([251], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0325,  0.0486,  0.0074,  ..., -0.0444,  0.0198, -0.1162]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2383,  0.1143, -0.0037,  ..., -0.0432,  0.0498,  0.1572]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -9.3750,  -5.7188, -12.8750,  ...,   5.8125,   1.0938,   0.1416]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2539, -1.8984, -0.6133,  ...,  1.8594, -2.9375, -0.0146]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([252], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-7.9102e-02,  1.9775e-02, -8.5449e-02,  ...,  3.3691e-02,\n",
      "          1.8311e-04, -2.2656e-01]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0393, -0.0869,  0.2598,  ...,  0.2832, -0.0684, -0.2178]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.4629, -3.6250, -3.5625,  ...,  5.6250,  7.8125,  0.6016]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.3906, -0.4473, -0.5391,  ..., -3.6875, -3.6250, -0.2773]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([253], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0004,  0.0503,  0.0476,  ..., -0.1084, -0.0118, -0.1494]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0938, -0.0091,  0.2656,  ..., -0.1836, -0.0121, -0.0781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.2969, -6.7812,  8.3125,  ...,  3.5469,  3.0156, -1.5938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.7031, -0.4258, -1.5625,  ..., -2.8281, -2.2188, -0.8984]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([254], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0067,  0.0164, -0.0167,  ...,  0.1787, -0.1172, -0.0510]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2832,  0.1182,  0.2695,  ...,  0.0049,  0.1641,  0.0488]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.3125,  7.7188, -0.5859,  ...,  2.6250,  4.3125, -0.1074]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.0859,  0.4492, -1.6094,  ..., -1.1328,  0.5703, -2.1719]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([255], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0977, -0.0532, -0.0732,  ...,  0.0471, -0.0479, -0.0801]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0481, -0.3965,  0.1592,  ...,  0.0150,  0.0457, -0.0879]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.6250,  7.0625, -2.7031,  ..., -1.6250,  2.4688,  2.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2363,  0.6016, -0.1279,  ..., -0.8594, -0.7422, -0.9219]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([256], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1367, -0.1367, -0.0420,  ...,  0.0317, -0.0620, -0.2275]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1943, -0.4434,  0.1079,  ..., -0.0645, -0.3047,  0.0889]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.2500,  1.2812,  5.0938,  ...,  3.2500,  3.6562,  2.5156]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2578,  0.1650, -1.1484,  ..., -2.7656, -3.5625, -1.3750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([257], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0234,  0.0444,  0.0315,  ..., -0.0344,  0.0238, -0.1455]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1338,  0.0315, -0.0210,  ..., -0.1494, -0.0040, -0.1299]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.5625,  4.3438, 13.4375,  ...,  4.6875,  6.9375,  2.6094]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.9180, -3.2812, -1.6875,  ..., -1.1094,  0.7500, -0.1885]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([258], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0615, -0.0332,  0.0010,  ..., -0.0598, -0.0483, -0.1240]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0491,  0.0645,  0.0664,  ...,  0.0209, -0.0654,  0.0645]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.9062,  2.6875, -2.2812,  ...,  3.2344, -1.3438,  2.4844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4258,  0.9688,  0.1523,  ..., -0.1001, -1.3672, -0.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([259], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0664,  0.0361,  0.0874,  ...,  0.0618,  0.0825, -0.0684]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1133, -0.1406, -0.0708,  ..., -0.0840,  0.1543,  0.0776]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-5.5000, -1.2812, -1.9219,  ..., -8.1250,  1.9844, 11.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.3281, -1.1406, -0.6992,  ...,  1.5859, -1.7344, -0.9688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([260], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0137, -0.0452,  0.0129,  ..., -0.0325, -0.0408, -0.2197]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1279, -0.0239,  0.0718,  ...,  0.0339,  0.0354,  0.0103]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.2812, -1.7422,  0.3008,  ...,  2.4688, 10.5000,  2.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 3.7344,  1.4375, -7.6250,  ..., -2.0625,  5.4062, -1.9141]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([261], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0713,  0.0087,  0.0430,  ..., -0.0513,  0.0073, -0.0825]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0825,  0.3750,  0.0073,  ...,  0.0231, -0.0840,  0.1143]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-5.8125, -2.3125, -5.9375,  ..., -9.3125,  9.5625, -0.9453]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.8906,  0.5859, -5.6875,  ..., -0.9180,  2.0156, -0.4336]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([262], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0376,  0.0996,  0.1855,  ...,  0.0708,  0.0593, -0.2100]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2598,  0.1699, -0.1650,  ...,  0.1270, -0.2793,  0.3594]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.7969,  0.0234, -2.9219,  ...,  3.3125, 16.0000, -0.2656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.8906,  1.1719, -5.0312,  ...,  4.3125,  1.9844,  2.7344]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([263], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0674, -0.0062,  0.0330,  ..., -0.1865,  0.0479, -0.1641]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1167, -0.0483,  0.1338,  ..., -0.0947, -0.0889,  0.0806]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.0000, -2.9531, -3.1562,  ...,  9.2500, -2.9062, -3.7969]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.0781, -1.2969, -2.5000,  ...,  0.6875,  0.8281, -2.6562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([264], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1777,  0.1084,  0.0554,  ..., -0.2412,  0.0254, -0.2910]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0229, -0.0291,  0.0012,  ..., -0.2773,  0.0286,  0.0747]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.9375,  2.6875, -0.3828,  ...,  8.3750, -2.1562,  2.9062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.0469,  0.2637, -5.5312,  ...,  0.6641,  0.2773, -0.9180]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([265], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0586, -0.1738, -0.0016,  ...,  0.2344,  0.0986, -0.2012]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0820,  0.1006, -0.1426,  ...,  0.0270,  0.1299,  0.0918]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.4941, -4.0938, -5.7500,  ..., -7.7188, 11.5000,  0.5273]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.6016, -0.7578, -0.7656,  ...,  0.4375, -0.5234, -0.6094]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([266], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0288, -0.0525,  0.0801,  ..., -0.0664, -0.0182, -0.0659]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3770,  0.3809,  0.2256,  ...,  0.0265,  0.0229,  0.4004]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 4.9375, -1.3047, -3.3594,  ..., -5.6875,  8.7500, -0.1475]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0747, -0.2207, -1.7266,  ...,  2.3125, -1.2734, -1.4844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([267], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0000,  0.0908, -0.0277,  ..., -0.0100, -0.1338, -0.1641]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4570, -0.1963, -0.0123,  ..., -0.5742, -0.2402, -0.0295]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 5.1250, -0.8906, 14.8750,  ..., -4.2500,  1.9297, 11.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.0469,  0.0723,  1.0234,  ..., -0.2012, -4.4062, -0.5742]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([268], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0452,  0.0732,  0.1357,  ..., -0.0630,  0.0679, -0.1689]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0552, -0.1055, -0.0835,  ...,  0.0432,  0.0554, -0.0304]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.7812, -2.7812, 14.1875,  ...,  1.0312, -3.7812,  4.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.9297,  2.4531, -0.0752,  ...,  0.5547, -2.3750,  0.8086]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([269], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0203,  0.0864,  0.1592,  ..., -0.0791, -0.0449, -0.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0967,  0.0938,  0.1826,  ...,  0.1206,  0.1040, -0.0142]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 5.7500, -4.6562,  4.1562,  ...,  8.3750,  2.0625, -1.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.3457,  0.9961,  8.0000,  ..., -5.5625, -4.2812,  3.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([270], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0044, -0.0996, -0.0099,  ..., -0.0967,  0.0081, -0.0159]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0359, -0.1084,  0.0522,  ...,  0.1660,  0.2256, -0.0364]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 3.0938, -3.8125,  1.9375,  ...,  2.6562,  1.3750,  0.6719]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.5156, -3.5156, -2.2500,  ..., -4.5625, -0.5234, -2.4531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([271], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0845, -0.0160, -0.0090,  ..., -0.1011, -0.0762,  0.0330]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1895, -0.0023, -0.0085,  ..., -0.0269, -0.0820, -0.1133]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 4.9062, -1.1953,  4.1250,  ...,  2.4844, -1.4844,  9.7500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.9219,  0.8789,  0.4473,  ..., -1.8516, -1.1875, -1.5234]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([272], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0020,  0.0603,  0.0977,  ...,  0.1147, -0.0261, -0.0889]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0542, -0.1138, -0.1348,  ..., -0.0933,  0.0277,  0.0659]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-0.0469, 10.5000,  3.9531,  ..., -7.4375,  4.5000, 13.9375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.3594, -4.9688, -1.2891,  ...,  0.2070,  0.0299, -2.7344]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([273], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1035,  0.0688, -0.0112,  ...,  0.1826,  0.0262, -0.0474]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1147, -0.2236,  0.3105,  ..., -0.0029, -0.0605,  0.0349]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.6875,  2.4219,  0.3203,  ..., -5.7500,  4.7500, 13.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.5000, -2.3438, -4.2188,  ..., -0.9297, -0.0762, -0.8984]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([274], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1030,  0.0015,  0.0364,  ...,  0.1953,  0.1299, -0.0264]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0938, -0.1533,  0.0669,  ...,  0.0383, -0.0513,  0.3223]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.6406, -3.8906,  1.3906,  ..., -1.0547,  8.4375,  6.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.1016, -1.8125, -3.5938,  ..., -1.7188, -2.4531,  0.0977]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([275], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0049,  0.0630,  0.0227,  ...,  0.1074, -0.0233,  0.0045]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0093, -0.1865,  0.0781,  ..., -0.1445, -0.3105, -0.0099]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-5.0000,  0.5547,  7.2500,  ...,  0.4766, 10.7500,  4.7188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.7188,  1.3281, -0.2812,  ..., -3.4531, -3.2656, -1.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([276], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1040,  0.1006,  0.0201,  ..., -0.1079, -0.0879, -0.1035]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2656,  0.2051, -0.0781,  ..., -0.0830, -0.2617,  0.3105]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-15.1875,  -1.3125,  -1.0312,  ...,   6.5312,  -1.0156,  10.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.7148,  0.9297, -2.4375,  ...,  0.2070,  2.5469, -1.5234]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([277], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0283, -0.1279,  0.0229,  ...,  0.1670,  0.2539, -0.1328]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2373,  0.2275, -0.2598,  ...,  0.0791,  0.4648, -0.1914]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.1641,  0.5078, -5.5312,  ...,  2.0312,  5.9688, -1.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2520, -4.7812, -0.1475,  ..., -0.0248, -2.3594,  0.2188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([278], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0320, -0.0063,  0.0215,  ..., -0.1904,  0.0610, -0.1504]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2188,  0.0287,  0.0013,  ..., -0.0591, -0.1494,  0.3262]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.9062,  9.0625, -4.4062,  ...,  1.0781,  2.1875,  0.3516]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2539, -0.9375,  1.0781,  ...,  0.5234, -1.4297, -2.2344]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([279], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0366,  0.0386, -0.1582,  ..., -0.0640, -0.0874,  0.0430]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0830, -0.4863,  0.0315,  ..., -0.0464,  0.0864,  0.1514]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 2.1562,  1.0859, -1.6016,  ..., -4.0625, -6.5938,  4.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.5430,  0.6211,  1.4062,  ...,  1.5469, -1.6953, -1.7109]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([280], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0256, -0.0107, -0.0942,  ..., -0.0193, -0.0305, -0.0972]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2598, -0.1963, -0.0009,  ..., -0.0879, -0.1514,  0.2188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.1250, -1.9453, -1.9297,  ..., -1.7891, -5.7500,  4.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.8438, -0.7031, -1.7500,  ..., -0.0352, -5.8750, -0.7070]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([281], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0108,  0.1035, -0.1143,  ...,  0.0776,  0.0947, -0.1816]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4277, -0.3965, -0.4316,  ..., -0.5039,  0.2832,  0.2949]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.7500, -2.1094, -5.4375,  ...,  2.7188,  0.1758,  6.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.3750, -0.9219, -1.7969,  ..., -1.5000, -4.1562, -1.0547]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([282], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0269,  0.1021,  0.0598,  ..., -0.0559, -0.0359, -0.1377]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0459,  0.2715,  0.0620,  ..., -0.2275, -0.0010, -0.1201]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.3750,  2.5938,  0.6172,  ...,  3.0469, -9.4375,  6.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0623, -1.4688, -0.4082,  ..., -0.4336, -3.8125, -5.7812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([283], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0179, -0.0967,  0.0334,  ..., -0.1104, -0.0106, -0.0216]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0801, -0.0825,  0.1094,  ..., -0.0613, -0.0388,  0.0547]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.7188,  2.0312,  1.1406,  ..., -0.3984, -3.1406,  1.8828]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.5156,  0.7344, -0.9688,  ..., -0.5859, -1.1094, -1.1953]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([284], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0493,  0.0996,  0.0884,  ...,  0.0610,  0.1187, -0.0549]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1396, -0.1089, -0.0498,  ..., -0.1221,  0.1475,  0.0547]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.1602,  0.8047,  4.1875,  ..., -5.5625,  5.9062,  6.4062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.2734, -1.8594, -2.2500,  ...,  4.3438, -0.5273, -4.0000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([285], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0820,  0.0581, -0.0192,  ...,  0.1689, -0.0243, -0.0618]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0435, -0.1035,  0.2832,  ..., -0.0133, -0.0172,  0.0304]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.6250, -1.5469,  3.3125,  ..., -2.9375,  8.4375,  3.0781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.6016, -0.9688, -4.5625,  ...,  3.0469,  0.4922,  0.3164]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([286], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0184,  0.0576,  0.0488,  ...,  0.1357,  0.1445, -0.0684]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1816,  0.0708,  0.0292,  ..., -0.0081, -0.0747,  0.2969]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.2656, -2.2812,  4.0312,  ..., -0.4219,  3.1719,  6.4688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.7734, -0.6523, -5.7188,  ..., -1.2578, -3.4844, -1.3750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([287], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0088,  0.1011,  0.0635,  ...,  0.0703, -0.0100,  0.0129]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0046, -0.0630,  0.0552,  ..., -0.1025, -0.2969, -0.0017]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.1367,  2.6094, 15.4375,  ...,  0.9375,  4.5625,  0.0801]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-6.1562, -0.6055,  0.3633,  ..., -2.8438,  2.8125, -3.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([288], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.1089, -0.0037,  0.0791,  ...,  0.1123,  0.0044, -0.0669]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4355,  0.2129,  0.2158,  ...,  0.1338,  0.0781,  0.2275]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-13.4375,   0.8125,  -0.7891,  ...,   4.3125,  -3.3750,   7.2188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.5625, -1.4297, -3.7969,  ...,  3.9531,  1.4922, -3.2344]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([289], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.1108, -0.1348,  0.0815,  ...,  0.2070,  0.2148, -0.1279]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2109,  0.2109, -0.2422,  ...,  0.1631,  0.3809, -0.1206]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.5625, -3.9531, -6.4375,  ..., -7.4375,  8.3750, -1.8125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-4.5938, -2.8125, -5.0000,  ..., -2.9531, -1.1875,  0.3926]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([290], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0092, -0.0317,  0.0583,  ..., -0.1348, -0.0233, -0.1348]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.3535e-01,  1.6309e-01,  1.4404e-02,  ...,  2.8229e-04,\n",
      "         -7.5195e-02,  3.5156e-01]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.6562,  6.8438, -4.5625,  ..., -3.2500,  0.8398, -3.2812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8008, -1.4219, -0.6758,  ..., -0.5703, -2.2344, -3.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([291], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0757,  0.0076, -0.1113,  ..., -0.0791, -0.1260,  0.0435]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1099, -0.4238,  0.0476,  ..., -0.0148,  0.1025,  0.1426]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 5.5625,  2.6875, -1.9922,  ..., -2.9688, -9.7500,  2.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.8906, -1.0156, -1.2500,  ..., -1.6953, -0.6523, -1.7344]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([292], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0874,  0.1826, -0.0272,  ..., -0.0825,  0.0635, -0.1523]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1416, -0.3398, -0.0928,  ..., -0.2490,  0.2695,  0.1152]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.7500,  0.8516, -1.3516,  ..., -3.6562,  3.3438, -1.0781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.8594,  1.8672,  0.5273,  ..., -1.7891, -4.6562,  0.9531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([293], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0562, -0.1367,  0.0801,  ...,  0.0052, -0.0342, -0.0116]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.3691, -0.2617, -0.0028,  ..., -0.6445,  0.4414, -0.1475]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.2969,  0.5078, -6.2812,  ..., -1.6094, -2.2500,  6.7500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.7031, -0.4473, -1.3984,  ..., -0.8203, -5.2500, -1.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([294], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0728,  0.0835, -0.0132,  ..., -0.0593,  0.0461, -0.1050]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0378,  0.0830,  0.1182,  ..., -0.1172, -0.0510, -0.1318]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.1250,  3.4062,  0.8828,  ...,  2.6719, -9.5625, -1.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.6250,  0.2910, -0.1416,  ..., -0.6094, -4.1250, -9.0000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([295], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0679, -0.0996,  0.0063,  ..., -0.1074, -0.0055, -0.0103]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0889, -0.1094,  0.1235,  ..., -0.0281, -0.0374,  0.0220]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.0234,  1.8281, -3.8438,  ...,  0.4961,  2.6094,  3.8906]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.0938,  1.5234,  0.2988,  ...,  0.8906, -2.2188, -1.4531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([296], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0591,  0.0962,  0.0542,  ...,  0.0654,  0.1279, -0.0684]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1309, -0.1147, -0.0481,  ..., -0.1299,  0.1475,  0.0476]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.2832,  3.6250,  3.0156,  ..., -5.3750,  0.8555,  7.9375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0952, -1.8359, -2.5625,  ...,  2.9844, -0.7188, -3.2656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([297], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0811,  0.0557, -0.0396,  ...,  0.1719, -0.0134, -0.0864]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0476, -0.0801,  0.2949,  ..., -0.0127, -0.0183,  0.0654]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.9062, -0.4648,  1.7734,  ..., -7.5625,  4.2500,  3.0781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3906, -1.5234, -3.2656,  ...,  1.3125, -1.9766, -0.9883]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([298], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0240,  0.0591,  0.0352,  ...,  0.1338,  0.1621, -0.0757]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1943,  0.0967,  0.0371,  ..., -0.0011, -0.0679,  0.3086]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.6562, -1.6406,  3.1562,  ..., -4.3438, -0.5664,  4.9375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.9922, -0.3398, -4.8750,  ..., -0.3789, -2.7031, -2.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([299], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0201,  0.1074,  0.0544,  ...,  0.0684, -0.0049,  0.0060]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0099, -0.0530,  0.0518,  ..., -0.0972, -0.3008,  0.0099]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.6562,  3.1094, 10.3125,  ..., -3.0625,  3.4219,  4.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.5625,  2.0469,  2.4219,  ..., -0.5039,  0.5352, -0.9766]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([300], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0177,  0.1099, -0.0228,  ..., -0.0127,  0.0449, -0.1758]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2617,  0.3340, -0.0825,  ..., -0.0762,  0.1069,  0.1182]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-14.6875,   0.8594,   0.2656,  ...,   3.7188,  -2.8906,   9.6875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-4.2500, -0.5898, -3.4688,  ...,  6.4375,  0.2637, -1.4062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([301], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0583, -0.1504,  0.0698,  ...,  0.1807,  0.2637, -0.1279]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2285,  0.3379, -0.1128,  ...,  0.1641,  0.4746, -0.1865]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -5.1875,  -6.6250,  -3.8125,  ..., -10.6250,   4.3438,   2.7344]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-4.8750,  1.2500, -3.9062,  ..., -3.2812, -3.2969, -0.3594]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([302], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0503, -0.0125,  0.0413,  ..., -0.1738,  0.0317, -0.1221]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1924,  0.1670,  0.0142,  ..., -0.0182, -0.1040,  0.3535]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.8281,  8.8750, -6.1562,  ..., -3.9531, -0.5859, -3.5781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.7305, -1.0938, -0.0923,  ...,  0.3867, -3.8750, -6.5938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([303], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0767,  0.0488, -0.1123,  ..., -0.0542, -0.1104,  0.0601]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1216, -0.4004,  0.0466,  ..., -0.0398,  0.0669,  0.1611]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 5.5000,  0.1562, -0.9375,  ..., -1.1250, -3.3438, -4.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.6445, -0.6289, -0.6719,  ...,  2.7500, -3.9062, -1.5078]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([304], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0476, -0.0083, -0.0206,  ...,  0.0337,  0.0330, -0.0820]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1113, -0.2695,  0.2520,  ..., -0.1514, -0.1641, -0.2148]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.9375, -1.5078, -4.0938,  ..., -4.0625, -0.9766,  1.7812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.8984,  1.3359, -0.3555,  ...,  0.5273, -5.8438, -1.1406]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([305], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0439,  0.1162, -0.1611,  ...,  0.1553, -0.0198, -0.0388]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0479, -0.3574, -0.2393,  ..., -0.4551,  0.2305,  0.1709]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.0547,  2.3750, -6.9688,  ..., -0.2451, -1.1641,  4.8125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2070,  0.0146, -1.1016,  ..., -0.5078, -4.4688, -1.2578]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([306], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0096,  0.0928,  0.0532,  ..., -0.0352, -0.0603, -0.1367]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0747,  0.2539,  0.0547,  ..., -0.2246, -0.0118, -0.1592]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.2344,  0.9102,  1.1641,  ...,  4.9688, -7.7188,  0.0234]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.7109,  0.4922,  0.6758,  ...,  0.8125, -4.3750, -8.9375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([307], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0310, -0.1074,  0.0457,  ..., -0.1035, -0.0216, -0.0327]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1094, -0.1147,  0.1221,  ..., -0.0488, -0.0317,  0.0396]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.4375,  1.6562, -1.2969,  ...,  2.7500,  7.8750,  5.9062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.8047,  1.9766,  1.8984,  ...,  0.1162, -1.0703, -1.9297]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([308], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0571,  0.0879,  0.0674,  ...,  0.0613,  0.1318, -0.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1416, -0.1089, -0.0486,  ..., -0.1436,  0.1602,  0.0242]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.9688, -1.1641,  1.2031,  ..., -3.5312, -1.1172,  9.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.5859,  0.6172,  1.9609,  ...,  0.7109, -1.3047, -1.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([309], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0298,  0.0806, -0.0190,  ..., -0.0532, -0.0679, -0.2217]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0923,  0.1465,  0.0035,  ..., -0.0111,  0.0613,  0.0376]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.9375, -0.8984, -6.1875,  ..., -0.8555,  4.3438, -0.5508]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.5938, -0.1982, -6.1562,  ..., -1.6562,  5.1875, -3.0469]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([310], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0317,  0.0090,  0.0820,  ..., -0.0247, -0.0322, -0.0364]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0981,  0.3613, -0.0027,  ..., -0.0017, -0.0884,  0.1611]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.7812, -6.6875, -4.5938,  ..., -6.1875,  2.6406, -3.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.3125, -1.0156, -2.7812,  ..., -0.8555,  0.5039, -3.0000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([311], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0219,  0.1196,  0.1914,  ...,  0.0708,  0.0515, -0.1689]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2676,  0.2188, -0.1709,  ...,  0.1270, -0.2500,  0.3555]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 5.3750, -6.7812, -4.3750,  ...,  6.4688,  7.1562, -1.3203]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-5.1250,  3.4375, -2.4062,  ...,  3.8906,  2.7344,  1.9141]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([312], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0273, -0.0435, -0.0129,  ..., -0.1904, -0.0874,  0.1006]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1162, -0.1562, -0.0962,  ..., -0.2451, -0.2393,  0.0747]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.7578,  0.7188, -3.1562,  ..., 14.0000,  0.2988,  0.3633]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.7656,  0.2451, -1.4531,  ...,  3.3438,  1.6406,  1.7578]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([313], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1016,  0.0618,  0.0422,  ..., -0.3457, -0.0297, -0.1973]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0466, -0.1904,  0.0972,  ..., -0.2559,  0.0410, -0.1895]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.7812, -2.6562,  0.5938,  ...,  7.1562, -0.2852,  1.1719]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.9023,  1.7812, -4.4375,  ...,  2.0156,  0.8711, -2.6562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([314], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0684, -0.1318, -0.0249,  ...,  0.2188,  0.1133, -0.1963]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1147,  0.1069, -0.1426,  ..., -0.0271,  0.1572,  0.1206]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -0.4453, -10.0000,  -0.7852,  ...,  -2.7031,   2.7500,  -4.0000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1201, -1.8281, -1.4688,  ..., -0.2656,  1.4062, -0.8945]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([315], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0366, -0.0557,  0.0796,  ..., -0.0884, -0.0156, -0.0352]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3418,  0.3984,  0.2227,  ...,  0.0212,  0.0349,  0.3594]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[  1.6875,  -6.5312,   4.3438,  ...,  -3.2969,  -4.3438, -14.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.2188, -1.6797, -2.8125,  ...,  0.2754, -1.0312,  0.7148]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([316], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0618, -0.1904,  0.0126,  ..., -0.1924, -0.1787,  0.0762]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1235, -0.2217, -0.2754,  ..., -0.2910, -0.1924,  0.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.2734, -2.5469, -3.1094,  ...,  0.8281,  4.1562, -2.7188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.2812, -1.3125, -3.1406,  ...,  0.6719, -1.9531, -2.2188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([317], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0737,  0.1338,  0.1182,  ...,  0.0132, -0.1328, -0.1699]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1299,  0.1406, -0.0437,  ...,  0.0251, -0.0630, -0.1416]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.5312,  2.5312, -7.5625,  ..., -0.4102,  2.2500, 11.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8633,  0.5078, -2.1875,  ..., -1.9922, -1.9297, -0.3242]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([318], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0151,  0.1245, -0.0167,  ..., -0.1641, -0.0703, -0.1426]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0071, -0.0583,  0.3105,  ..., -0.1885, -0.0145,  0.0164]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 7.6875,  0.7734, -1.6406,  ...,  0.0518, -2.4219,  6.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2832,  1.8906, -2.0312,  ..., -0.7656, -1.4609, -0.8945]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([319], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0112,  0.0879,  0.0106,  ...,  0.0201, -0.0186, -0.0293]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0009, -0.1143, -0.0466,  ..., -0.2598, -0.4375, -0.0032]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-0.2578, -0.5586,  0.5625,  ..., -0.3496,  6.4688,  6.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.4062,  2.8594, -1.3828,  ...,  0.0820,  2.7500, -2.7969]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([320], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.1631,  0.1108, -0.0266,  ...,  0.0109,  0.1299, -0.0459]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3555,  0.2988,  0.0099,  ..., -0.0869,  0.2178,  0.0167]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.7500,  -4.8750,  -2.1719,  ...,  -0.2520,  -7.7188,   3.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1670,  3.8438, -1.2500,  ...,  8.3750, -1.1094, -7.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([321], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1348, -0.0510, -0.0762,  ..., -0.1108,  0.0150,  0.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0540,  0.1138, -0.0166,  ...,  0.0659, -0.0018, -0.1006]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-14.1250,  -6.8125, -10.3125,  ...,   4.0625,  -0.1602,   4.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.2969,  2.1094, -1.8906,  ..., -3.6250,  1.3828, -3.6406]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([322], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.2168,  0.0233,  0.0273,  ...,  0.0330,  0.1582, -0.0840]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0154, -0.3125, -0.1270,  ..., -0.3301,  0.0287, -0.1699]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.6406, -6.6875, -1.4062,  ...,  4.6250,  1.1406, -3.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4863, -0.5234, -0.2969,  ..., -2.0000,  1.8438,  0.7578]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([323], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0198,  0.1406,  0.0649,  ..., -0.0564, -0.0479, -0.1191]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2500, -0.1738,  0.0129,  ..., -0.2217, -0.0649, -0.0679]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 6.4688, -5.5938, -2.7500,  ...,  2.8750,  5.8125, -1.7656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.9688, -0.1621, -0.5000,  ..., -1.3047, -1.1484,  0.1211]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([324], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0532,  0.0967, -0.0732,  ..., -0.0952,  0.0469, -0.1050]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2188, -0.0272, -0.2734,  ..., -0.0684,  0.1162, -0.3145]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 2.5938, -5.0000, -3.5781,  ...,  1.0469,  1.5859,  4.9062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.3984, -1.1328, -1.9375,  ..., -0.4355, -5.7188, -0.5664]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([325], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0879,  0.1006,  0.0160,  ..., -0.1011,  0.0315, -0.1484]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0118,  0.0581,  0.1240,  ..., -0.1387, -0.0684, -0.0913]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.4336,  0.5938,  1.0938,  ...,  0.5352, -1.8516,  6.3438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1182, -1.1250, -2.1875,  ..., -1.5703, -2.4375, -0.8984]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([326], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0195,  0.0835, -0.0437,  ...,  0.0781,  0.0073, -0.0752]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0061, -0.1631,  0.0096,  ..., -0.3008, -0.4219,  0.0188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-5.8438,  0.3516,  5.6875,  ..., -0.7266,  3.2969,  2.5469]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.8750,  3.7031, -1.3047,  ..., -4.0938, -3.6094, -1.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([327], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1113,  0.1279,  0.0405,  ..., -0.1992, -0.1016, -0.0928]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2148,  0.3203, -0.0410,  ..., -0.0361, -0.2148,  0.3379]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-12.5625,  -6.4062,  -1.2969,  ...,   2.0000,   5.1250,   3.6094]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.3281,  3.0781, -2.2812,  ..., -1.5000, -2.8125, -2.9844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([328], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.2080,  0.0128, -0.0256,  ...,  0.0654,  0.1270, -0.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0542, -0.2734, -0.0923,  ..., -0.3672,  0.0820, -0.1895]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.9688, -9.0625,  7.6562,  ...,  6.9062, 10.3125, -6.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.2266,  1.6641, -2.4688,  ..., -1.7656, -4.0938,  1.2422]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([329], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0500,  0.0623,  0.0282,  ...,  0.0586, -0.0444, -0.1484]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0552, -0.0479,  0.1582,  ..., -0.1953,  0.1475, -0.0815]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 5.1250,  3.7188,  1.8828,  ...,  1.1016, -2.7031,  1.6484]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.3047, -1.5234, -5.5625,  ..., -1.3906, -2.4219, -0.9805]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([330], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0076,  0.1118, -0.0072,  ...,  0.1250, -0.0732, -0.0815]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0679, -0.0918,  0.1777,  ..., -0.1797, -0.5391, -0.0105]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-5.0625,  0.6953,  9.7500,  ..., -2.2656,  1.0312,  1.4766]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.9375,  2.5938,  1.8594,  ...,  1.4531,  0.3867,  0.1221]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([331], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0109,  0.1050, -0.0408,  ...,  0.0012, -0.0074, -0.1641]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2471,  0.3691, -0.0383,  ..., -0.0649,  0.0801,  0.1670]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-18.2500,  -9.3125,  -5.0625,  ...,   5.6875,  -6.5000,   7.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.5469,  2.3281, -0.9062,  ..., -1.3438, -1.7422, -3.3594]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([332], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.2139, -0.0271,  0.0024,  ...,  0.1064,  0.1318, -0.0608]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0115, -0.2559, -0.0386,  ..., -0.3359,  0.1270, -0.2061]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.7500,  -5.6562,   7.0312,  ...,   6.2812,  -5.5625,  -0.3867]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.8594,  1.6094,  2.7812,  ...,  0.7305, -3.7500,  0.6680]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([333], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1279,  0.0610,  0.1250,  ...,  0.0605, -0.0815, -0.3320]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0305,  0.1807,  0.1807,  ...,  0.0732,  0.0415, -0.0752]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.4375,  0.9141,  1.3359,  ..., 11.5625, -3.4219,  1.3281]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.9766, -1.3125, 10.6875,  ..., -3.4531, -0.9375,  1.9922]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([334], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0347, -0.0566, -0.0342,  ..., -0.0513,  0.0564, -0.0610]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0288, -0.0859,  0.0654,  ...,  0.1221,  0.1973,  0.0806]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 1.1562,  7.3125, -1.4688,  ..., -0.3555, -9.6875,  1.0781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.7266, -4.2500, -2.7344,  ...,  0.1006,  3.1719,  2.8906]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([335], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1006, -0.0095, -0.0255,  ..., -0.0576, -0.0486,  0.0120]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1885,  0.0564,  0.0041,  ..., -0.0168, -0.0879, -0.1025]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 3.3125,  0.5469, -4.4688,  ...,  3.5625,  1.9688,  0.2637]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2637,  1.4453,  0.1514,  ..., -0.2871, -1.5469, -1.1406]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([336], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0732,  0.0796,  0.0369,  ...,  0.0688,  0.1069, -0.0645]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1001, -0.0991, -0.0293,  ..., -0.1211,  0.1660,  0.0449]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.9375, -1.1562, -1.0312,  ..., -6.0312,  2.4844, 13.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.3633, -0.9688,  2.0469,  ...,  3.5781, -1.2969,  1.5625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([337], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0674,  0.0728,  0.0099,  ...,  0.0098, -0.0146, -0.2793]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1289,  0.0012, -0.0649,  ...,  0.0815,  0.1240,  0.0012]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -2.7812,  -0.7578, -10.8125,  ...,   6.2812,  -1.2266,   2.1406]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.5312, -0.2139, -5.4062,  ..., -1.8438,  4.5625, -3.3750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([338], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0645,  0.0752,  0.0420,  ..., -0.0378, -0.0062, -0.0771]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1211,  0.3203,  0.0135,  ..., -0.0082, -0.1045,  0.1475]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.1875, -5.5938, -9.1250,  ...,  4.6250, -1.0859,  0.5117]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8203, -1.7656, -2.2031,  ...,  0.6602,  2.3750, -2.4531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([339], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0226,  0.1387,  0.1787,  ...,  0.0791,  0.0752, -0.1914]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2500,  0.1973, -0.1475,  ...,  0.1367, -0.2158,  0.3516]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 1.6562, -6.0625, -9.2500,  ..., 15.1875, 10.2500,  0.4531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-4.9688,  1.4062, -3.9062,  ...,  3.5938,  2.3750,  4.2188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([340], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0012,  0.1348,  0.0447,  ...,  0.1445, -0.0183, -0.0005]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2002, -0.1030,  0.1514,  ...,  0.1582,  0.0026, -0.2451]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.3750,  -7.3438,  -8.0625,  ...,  12.4375,  -3.7969,  -4.5625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.5547,  5.2188,  2.7969,  ...,  0.6797, -0.0674, -8.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([341], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0947, -0.0052,  0.0195,  ...,  0.0913, -0.3398, -0.0388]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0432, -0.0513,  0.0962,  ..., -0.0189,  0.0396,  0.0237]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-5.4688, -3.6250, -0.8984,  ...,  6.1250, -3.2656, -3.9844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.9141,  0.8945, -1.3125,  ...,  3.4219, -3.4219, -1.0234]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([342], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0762, -0.1689, -0.0317,  ...,  0.2656,  0.0908, -0.2207]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0703,  0.0942, -0.1436,  ...,  0.0193,  0.1523,  0.0952]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.7031, -7.8125, -5.8438,  ...,  4.5938,  4.0625,  1.9219]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.5781, -1.3906, -0.6914,  ...,  0.4375,  0.4785, -0.3457]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([343], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0288, -0.0356,  0.0762,  ..., -0.0459, -0.0674, -0.0193]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3398,  0.3789,  0.1895,  ..., -0.0210,  0.0732,  0.3379]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.5391, -7.7500, -4.0000,  ..., 10.8125, -2.0000, -0.6953]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.6875, -2.4375, -3.0625,  ...,  0.6211, -1.2578,  1.5703]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([344], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0767, -0.0359, -0.0537,  ...,  0.0771, -0.1289, -0.0674]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1797, -0.1865,  0.0121,  ...,  0.0698,  0.0118, -0.0286]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.6719, -0.8047, -4.9062,  ...,  6.8125,  2.7812,  2.3438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.2500, -0.4570, -1.2969,  ..., -2.6875, -3.4531,  0.6133]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([345], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0200,  0.1289,  0.0327,  ..., -0.0608, -0.0337, -0.0684]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0332, -0.0344,  0.1934,  ..., -0.1465, -0.0430, -0.0967]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[10.6875, -3.6719, -3.6875,  ...,  8.3750,  1.2188,  6.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-4.7188, -0.7031,  0.1465,  ..., -2.9688, -0.9023,  2.7500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([346], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0054, -0.0664, -0.1309,  ...,  0.0214, -0.1543, -0.1230]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0559,  0.1904, -0.0004,  ...,  0.2275,  0.0544,  0.1045]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 2.3594, -5.6875,  3.9844,  ...,  6.1562, -1.3828,  7.5625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.1406, -0.9258, -1.3125,  ..., -1.9062, -3.0938, -0.4121]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([347], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.1162,  0.1377,  0.0588,  ...,  0.0713, -0.0361, -0.0391]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0342, -0.0493,  0.0762,  ..., -0.1855, -0.5352, -0.0038]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.0625, -2.2188,  5.5938,  ..., -0.8398,  1.5469,  2.3750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.4062,  4.0312, -0.9180,  ..., -2.0312, -2.7500, -2.1719]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([348], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0933,  0.1128,  0.0693,  ..., -0.1865, -0.1045, -0.0718]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2334,  0.3105, -0.0630,  ..., -0.0250, -0.1924,  0.3633]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.5625,  -9.6250,  -0.8203,  ...,   3.4844,  -2.6562,  10.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1992,  1.3672, -3.0156,  ..., -0.1895, -0.2227, -1.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([349], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.2354, -0.0171, -0.0503,  ...,  0.0532,  0.1201, -0.0752]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0444, -0.2363, -0.0928,  ..., -0.3438,  0.0776, -0.2031]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -7.3125, -12.1875,   7.2500,  ...,   2.2656,   2.1406,   3.9219]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4180,  0.4590, -0.6484,  ..., -0.5703, -0.8203,  0.9219]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([350], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1387,  0.0425,  0.1504,  ...,  0.0625, -0.0781, -0.2637]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0381,  0.1719,  0.1729,  ...,  0.0771,  0.0410, -0.0645]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.7031, -2.5938,  1.8906,  ...,  7.6250,  2.5938,  2.7656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4473,  1.0078,  4.7500,  ..., -1.0312, -2.2500,  1.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([351], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0010, -0.1572, -0.0649,  ...,  0.0625,  0.2139,  0.0232]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0625,  0.0036, -0.0859,  ...,  0.2480,  0.5195, -0.0337]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 1.0781, -1.7422, -1.0234,  ...,  4.4062, -0.0391,  2.7969]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0554,  0.7695, -0.7578,  ..., -0.6133, -1.3906, -0.8984]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([352], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0444,  0.0332,  0.0046,  ..., -0.0212,  0.0623, -0.0684]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0640, -0.0693, -0.0415,  ..., -0.1504,  0.0903, -0.0571]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-0.9219, -3.2031,  0.5391,  ...,  4.2500,  0.0820, 10.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.9844, -0.6797, -1.4531,  ..., -1.8125, -2.2812,  0.2656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([353], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0186,  0.0253,  0.0117,  ..., -0.0874,  0.0732, -0.1426]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0615,  0.0513, -0.0618,  ...,  0.0188,  0.0708,  0.1025]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 1.5547, -1.0469,  6.8125,  ...,  2.9531,  2.4062,  6.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0459, -1.0234, -3.2188,  ..., -1.6328, -2.2500, -0.0081]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([354], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0540,  0.0527, -0.0386,  ...,  0.0664,  0.0022, -0.0742]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0240, -0.1709, -0.0282,  ..., -0.3086, -0.3984,  0.0074]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.5000, -0.7656, 12.1875,  ...,  6.1875,  4.1875, -0.4570]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-4.6250,  0.8750,  1.3438,  ..., -0.9258,  0.9219, -1.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([355], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.1030, -0.0023,  0.0203,  ...,  0.0850,  0.0026, -0.1064]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4336,  0.2637,  0.1865,  ...,  0.1060,  0.1064,  0.2090]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.4688, -6.6250, -3.4531,  ...,  0.6602, -1.6172,  6.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0854,  0.9961, -1.7812,  ..., -0.4199, -1.5156, -1.8047]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([356], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.2471, -0.0618, -0.0034,  ...,  0.1357,  0.1436, -0.0820]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0233, -0.3008, -0.1611,  ..., -0.2832,  0.0168, -0.1748]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.4062, -6.6562,  7.9375,  ...,  2.7500,  5.3750,  0.5586]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0417, -0.4922,  0.5352,  ..., -0.2617, -2.3281,  0.5430]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([357], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0752,  0.0269,  0.1523,  ...,  0.0583, -0.1494, -0.3008]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0168,  0.1836,  0.0923,  ...,  0.0825,  0.0583, -0.0786]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.9297, -0.1719, -0.7578,  ...,  6.3125,  1.7500,  4.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8789, -1.1250,  3.6719,  ...,  1.7734, -0.9141,  1.0781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([358], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0182, -0.1689, -0.0547,  ...,  0.0217,  0.1631, -0.0033]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0286,  0.0023, -0.0654,  ...,  0.2734,  0.5156, -0.0344]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[5.6875, 0.1289, 2.8594,  ..., 1.2500, 1.4062, 0.2656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0659,  0.7109,  0.1562,  ..., -1.1172, -0.9180, -0.6484]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([359], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0549,  0.0332,  0.0099,  ..., -0.0184,  0.0518, -0.0703]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0376, -0.0659, -0.0549,  ..., -0.1289,  0.0723, -0.0737]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 5.1875, -3.2812, -0.4141,  ...,  1.1328,  1.9219,  0.7773]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.9492, -0.4336, -2.9062,  ..., -0.8516, -2.3594, -0.9336]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([360], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0201,  0.0184,  0.0352,  ...,  0.0082,  0.0265, -0.1133]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0918, -0.0588,  0.1465,  ..., -0.0466,  0.0124, -0.0879]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 2.3125, -3.1250, -1.3125,  ...,  5.4062,  0.4961,  5.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.1484, -0.9688, -1.1094,  ..., -1.9688, -5.0312, -0.1621]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([361], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0193,  0.0452, -0.0125,  ..., -0.0120,  0.0055, -0.1445]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0393,  0.1719, -0.0400,  ..., -0.0732, -0.0047, -0.2139]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -0.2734, -10.0625,   0.3867,  ...,   5.6250,  -7.6875,   4.8125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.6406, -1.0234,  2.0312,  ...,  0.5117, -3.4062,  4.3438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([362], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0359, -0.0718, -0.1514,  ...,  0.0386, -0.0801, -0.1494]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0664,  0.2441,  0.0903,  ...,  0.2598,  0.0879,  0.0850]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.7969,  4.0625,  3.8594,  ..., -1.9688, -4.1562,  7.4688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.2031, -0.1260, -4.3125,  ..., -1.0078, -1.7500, -1.0312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([363], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.1094,  0.0815, -0.0178,  ...,  0.0918,  0.0176, -0.0698]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0586, -0.0369,  0.1084,  ..., -0.1875, -0.5000, -0.0019]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-5.1875,  0.7656, 11.2500,  ..., -5.6250,  1.1875,  3.7031]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.7070,  4.5938,  2.2344,  ...,  0.4590, -0.0068, -0.8789]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([364], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0076,  0.0562,  0.0022,  ..., -0.0474,  0.0284, -0.1689]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2324,  0.3555, -0.0986,  ..., -0.0830,  0.1240,  0.1592]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-12.3750,  -9.6250,  -3.3594,  ...,   2.3438,  -7.2812,  10.0000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3984,  2.0156, -3.7969,  ...,  0.6758, -2.5000, -2.9062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([365], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.2393, -0.0815, -0.0216,  ...,  0.0889,  0.1406, -0.0908]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0190, -0.2344, -0.0752,  ..., -0.2988,  0.1523, -0.2363]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -8.5625, -13.8125,   4.3438,  ...,  -0.2676,  -1.4844,   4.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.4609,  1.1562,  1.7891,  ...,  2.5000, -2.3906,  3.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([366], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1221,  0.0261,  0.1299,  ...,  0.0630, -0.0918, -0.3203]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0513,  0.1865,  0.1562,  ...,  0.0654,  0.0383, -0.0669]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.2969,  0.1484, -3.4219,  ...,  8.2500,  4.0312,  7.4062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.9805, -2.7188,  3.7188,  ...,  0.7969, -0.0273,  3.0312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([367], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0099, -0.1631, -0.0752,  ...,  0.0723,  0.1934, -0.0046]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0009,  0.0422, -0.0898,  ...,  0.2598,  0.4883,  0.0179]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 2.0156, -1.1172, -6.3438,  ...,  5.8750,  0.0371,  7.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3008,  0.2812,  0.8047,  ..., -0.1650, -1.1797, -0.8633]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([368], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1099,  0.0027,  0.0383,  ..., -0.0232,  0.0923, -0.0679]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0320, -0.0339, -0.0654,  ..., -0.0601,  0.1875, -0.2344]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[  1.2969, -12.3125, -12.0000,  ...,   7.2188,   3.1406,  -0.1094]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.0938,  0.3789, -2.9531,  ...,  1.6797, -0.6289,  0.2539]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([369], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0762,  0.1074,  0.0518,  ...,  0.1270, -0.0227, -0.2051]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1553, -0.3750,  0.0454,  ..., -0.0811,  0.1416, -0.1006]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 4.9375, -7.3750, -6.9688,  ...,  9.1250,  7.3750,  4.2812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.9688, -2.0781, -2.2656,  ..., -4.2500, -4.5625, -1.7734]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([370], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0579,  0.0874, -0.0493,  ..., -0.1338,  0.0413, -0.1113]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1865, -0.0718,  0.2422,  ..., -0.1631, -0.0781, -0.1138]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 7.3750, -9.4375, -3.2188,  ...,  9.7500,  9.4375,  0.7070]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.9531,  0.2734, -1.8750,  ..., -1.8984,  0.0215,  0.4941]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([371], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0508, -0.0854, -0.0040,  ..., -0.0007,  0.0693, -0.2383]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2598, -0.2168,  0.0530,  ..., -0.1465, -0.1455,  0.0074]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 1.9062, -9.4375, -2.0938,  ..., 18.6250,  5.7188,  1.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8008, -0.0542,  2.8750,  ..., -1.8750,  0.3125,  3.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([372], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0830,  0.1348, -0.0884,  ...,  0.0559, -0.0918, -0.1152]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1270,  0.2422,  0.1235,  ...,  0.3594,  0.1133,  0.0874]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.3125, -5.4375,  9.1875,  ...,  7.7812,  2.5781,  1.7344]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.7344, -1.5000, -1.7656,  ..., -0.1504,  1.2734, -0.3730]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([373], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0155,  0.0210,  0.0356,  ..., -0.0613,  0.1416, -0.1299]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0437,  0.0105, -0.0072,  ...,  0.1157,  0.1147,  0.0055]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 1.0938, -1.9453, -2.7031,  ...,  4.6250,  2.7031,  5.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.8125,  0.5273,  0.2119,  ...,  0.7578, -0.1709, -0.9102]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([374], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0732,  0.0284,  0.1709,  ...,  0.1689,  0.0952, -0.0237]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0986, -0.1484, -0.0060,  ..., -0.0986,  0.1914, -0.0522]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.9375,   1.6172,  -0.0391,  ...,  -5.9688,  -2.2500,  -1.3672]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.2500, -0.4863,  0.0781,  ...,  1.3203,  3.2188, -0.7188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([375], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0212, -0.0703,  0.1025,  ...,  0.1021, -0.0850, -0.1396]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0171, -0.0498, -0.2207,  ...,  0.0391, -0.0527, -0.0179]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.6250, -5.1250,  7.6875,  ...,  3.2656,  4.0938, -1.4219]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.5391, -0.7344, -1.0625,  ..., -2.1875,  1.5078, -1.2656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([376], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.2559,  0.1875, -0.0498,  ..., -0.0312,  0.0388, -0.0098]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3027, -0.0640,  0.4062,  ..., -0.5078,  0.1904,  0.1836]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.1250, -8.5625,  7.8125,  ...,  0.5000,  3.3906, -1.8047]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.7578, -0.7656,  2.5625,  ..., -1.5703,  0.0635, -0.8125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([377], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1035,  0.1895, -0.1348,  ..., -0.0796, -0.0898, -0.1055]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1050, -0.2217, -0.1094,  ..., -0.2578,  0.0703, -0.1226]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.6562, -7.5625, 21.6250,  ...,  5.4062,  1.1719,  0.1074]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.7500, -3.2500,  1.2031,  ..., -2.8594, -0.7188, -1.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([378], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0723,  0.1206, -0.1206,  ..., -0.1953, -0.0688, -0.0806]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1494, -0.2441, -0.2275,  ..., -0.1738, -0.0938, -0.0996]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.1719, -9.0000,  2.7188,  ...,  0.7305,  3.1875, -3.2031]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2031,  0.0698, -0.8516,  ..., -0.8828,  0.1074,  0.4902]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([379], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0942, -0.0012, -0.0439,  ..., -0.0369, -0.0140, -0.0579]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1030, -0.0217, -0.1523,  ..., -0.0077,  0.1562, -0.0947]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[  2.0312, -16.2500,  27.8750,  ...,   1.1719,  11.5000,  -2.6875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.4062, -1.9688,  2.3281,  ..., -0.5781, -0.9961, -0.9609]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([380], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0413,  0.0129, -0.0437,  ..., -0.0786, -0.1162, -0.1030]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2852,  0.1797, -0.3887,  ..., -0.2637, -0.2344,  0.2656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 5.0000, -8.7500, -2.9844,  ...,  4.1562,  1.4688, -0.6406]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4766,  1.6172, -0.0854,  ..., -1.3359, -1.1250,  1.1641]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([381], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0303, -0.0435, -0.1475,  ..., -0.0703, -0.0211, -0.0200]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.6094, -0.1226, -0.0938,  ..., -0.1807, -0.1206,  0.6289]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 7.5312, -5.8438,  5.9688,  ..., 12.3125, -4.9375,  3.9219]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.0469,  0.7812,  1.1641,  ...,  1.0781, -2.1406, -0.5352]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([382], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0586, -0.1641,  0.1133,  ...,  0.0767, -0.0427,  0.0317]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0630,  0.0786,  0.1553,  ...,  0.1128, -0.2041, -0.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.6250, -2.7812,  1.8047,  ..., -1.8281, -6.3125,  1.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.9844,  0.7773, -1.2500,  ...,  0.1641,  0.1748,  0.3535]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([383], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0608, -0.0129,  0.0122,  ...,  0.0076,  0.1226,  0.0276]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0708, -0.1338, -0.0889,  ..., -0.0206,  0.0352,  0.0289]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.6562, -7.1875,  2.5156,  ..., -8.6875, -3.8906, -1.2578]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.8594, -0.1201, -2.0000,  ..., -0.4492,  1.2578,  1.7422]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([384], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0674, -0.0439, -0.0591,  ..., -0.0391,  0.0884, -0.1035]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4590, -0.4512,  0.0554,  ...,  0.0747, -0.1299,  0.1455]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-5.9062, -6.6250, 10.1250,  ..., -2.1719,  0.3555,  0.1309]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.5430, -1.3672, -0.8438,  ..., -0.4688,  0.6094, -0.3242]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([385], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0540,  0.0596,  0.0623,  ..., -0.0381,  0.0376,  0.0908]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3359,  0.0786,  0.2207,  ..., -0.2012,  0.0067, -0.0085]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-14.8125, -15.8125,  12.0000,  ...,  -5.9375,  -1.5000,   2.2656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.7188, -0.5820,  0.6289,  ..., -1.2969,  0.2344, -2.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([386], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.2773,  0.2227,  0.0238,  ...,  0.0247,  0.0349, -0.0703]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2490,  0.3574,  0.0471,  ..., -0.1709, -0.4297, -0.1108]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-16.5000, -12.6250,   1.4297,  ...,  -7.5000,   4.1562,   4.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.4062,  0.6641, -1.0547,  ..., -1.3125, -1.4297, -3.3438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([387], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.2451,  0.1758, -0.0195,  ..., -0.0205,  0.0457,  0.0684]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1787, -0.1328, -0.2578,  ...,  0.5273, -0.3828, -0.1826]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -6.0938, -12.7500,  -6.4375,  ...,   2.8906,   4.5000,   1.9922]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3398, -1.0625, -1.6719,  ...,  1.4688, -0.9492, -3.3281]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([388], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0879,  0.1221,  0.0918,  ..., -0.1729, -0.0498, -0.0645]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0728,  0.0177, -0.1318,  ...,  0.1807,  0.2461, -0.1406]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -3.9062, -13.1250,  -0.8086,  ...,   1.7656,   7.6875,  -6.6875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2773, -0.8750, -0.4375,  ..., -3.1406, -0.1709, -2.7656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([389], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0962,  0.0115,  0.0175,  ..., -0.0393,  0.0106, -0.2012]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0674,  0.2178,  0.0227,  ..., -0.1045, -0.1963, -0.0464]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -0.2734, -17.8750,  -0.9297,  ...,  -3.5938,  -7.9062, -11.6875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.7695,  0.1035, -1.4766,  ..., -3.2031,  0.6719, -1.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([390], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1562, -0.0378,  0.0182,  ...,  0.1494,  0.0625, -0.0918]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3359,  0.2305, -0.3789,  ...,  0.4258,  0.2188, -0.1924]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -7.3125,  -6.0312,   6.8750,  ...,   1.9375,   2.1250, -12.6875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.9062, -1.8594, -1.3125,  ..., -1.2969,  2.6406, -3.0781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([391], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0598,  0.0107, -0.0742,  ..., -0.2295,  0.1069,  0.0403]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.5078, -0.2363, -0.0669,  ..., -0.2314, -0.0986, -0.0238]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.5000, -0.0898,  4.7188,  ..., -2.6562,  0.9609,  3.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2676, -2.4531, -2.4844,  ..., -2.2031, -1.2578,  0.3672]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([392], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0349,  0.0054, -0.1611,  ..., -0.0718,  0.0250,  0.0086]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0013,  0.0413, -0.1226,  ..., -0.3438, -0.0850, -0.0205]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-13.3750,  -1.7188,   5.6875,  ...,  -5.1875,   9.8125,   3.5156]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.5469, -1.9766,  0.1289,  ..., -1.4531, -0.2061, -2.0781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([393], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.1807, -0.1709,  0.0364,  ...,  0.0598,  0.0195,  0.0640]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2520,  0.2080, -0.1641,  ...,  0.1455,  0.1533, -0.2275]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.0000,  2.5938,  1.1719,  ..., -6.3750,  6.4375,  4.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.5938,  0.0427, -1.8594,  ..., -3.8594, -1.5469, -1.6406]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([394], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.3223,  0.0064, -0.0708,  ...,  0.0276, -0.0275, -0.0544]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0064, -0.1230, -0.5664,  ..., -0.6328, -0.3828, -0.1816]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.8438, -1.8672,  7.5000,  ..., -0.9336,  4.5000,  3.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.0781, -2.8281, -1.2969,  ..., -2.0781, -1.7109, -1.4844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([395], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0957, -0.0430,  0.0432,  ..., -0.0498,  0.0767, -0.1660]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1074, -0.0771, -0.1147,  ..., -0.0253,  0.2275,  0.0713]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-14.0625,   6.5625,   2.3750,  ..., -13.1250,   2.8438,   4.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.7656, -2.5156,  1.3281,  ..., -1.0078, -0.3672, -1.1328]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([396], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1445, -0.1128, -0.1245,  ...,  0.1221,  0.0303,  0.0027]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4629, -0.0864,  0.0703,  ...,  0.5273, -0.0967,  0.1182]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-12.7500,  -0.3594,   6.1562,  ...,   0.1953,   1.3594,  -1.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.4766, -1.0859, -1.1172,  ..., -2.2188,  0.0085, -1.2422]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([397], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1060,  0.1123,  0.0186,  ..., -0.1992, -0.0320, -0.2559]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1514,  0.1572, -0.1187,  ...,  0.1924,  0.1816,  0.0850]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -5.3750,   3.2812,  -1.8750,  ..., -12.3750,   8.5000,   7.9688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.5000,  1.2422, -0.9453,  ..., -2.9844,  0.1021, -0.8047]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([398], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0630,  0.1514,  0.1553,  ..., -0.1582,  0.0019, -0.1660]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2471, -0.1099,  0.0723,  ...,  0.3711, -0.4961,  0.5625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-17.7500,   1.0312,   0.1992,  ...,   4.0938,   4.3750,   9.8125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.5625, -0.1094, -5.4062,  ..., -1.8984, -0.5820,  1.3906]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([399], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0574,  0.0723, -0.0420,  ..., -0.0859,  0.0359, -0.1504]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0352,  0.1021,  0.1250,  ..., -0.0732, -0.1011, -0.1162]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.1250,  8.1875, -0.6719,  ...,  2.4219,  5.7500, 12.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.0078,  1.5781, -1.8438,  ...,  0.5859, -0.0566,  0.5547]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([400], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0386,  0.0879, -0.0522,  ...,  0.0427, -0.0110, -0.1523]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1133, -0.0112,  0.0364,  ...,  0.1602, -0.3848,  0.4844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -8.2500,   0.9219, -12.6250,  ...,   4.2188,   7.0000,   3.5625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.2891,  2.0156, -2.8281,  ..., -3.8281, -0.8047, -2.5938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([401], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0260, -0.1514, -0.1475,  ..., -0.0159, -0.0226, -0.1021]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0510, -0.3652, -0.0342,  ...,  0.0187, -0.2676, -0.0977]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.5469,  1.3438,  5.7188,  ...,  5.8125,  2.0469,  8.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.6523,  2.4375, -3.6094,  ..., -1.0938,  1.4531,  3.0781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([402], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1738,  0.0767, -0.0840,  ..., -0.2275, -0.0659, -0.0513]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0212, -0.0106,  0.4824,  ...,  0.2852, -0.0461, -0.2383]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.2188,  2.3750,  3.4844,  ...,  9.9375, -0.4727,  3.8281]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.1250,  0.5898, -1.1719,  ..., -0.6016, -0.0420,  0.9844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([403], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1582, -0.1445,  0.0620,  ..., -0.0869, -0.0208, -0.0674]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2832,  0.0023,  0.0089,  ..., -0.0242,  0.0898, -0.0095]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.1250,  3.2500, -0.5547,  ..., 11.5000,  3.2188, -0.5352]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2275,  0.6250, -1.0469,  ..., -0.0859, -1.0625, -0.9570]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([404], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0918,  0.0801,  0.0544,  ..., -0.0211,  0.0549, -0.0649]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0952, -0.1040,  0.0491,  ...,  0.0072,  0.0238,  0.0171]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 3.9375, -0.7656,  0.8594,  ..., -0.7305, -9.1250, -6.5938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.5977, -0.3730, -0.0225,  ...,  1.2656,  0.9297, -2.6094]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([405], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1167, -0.0281,  0.0610,  ..., -0.0327, -0.0043, -0.1030]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1436, -0.1426, -0.0371,  ..., -0.0386, -0.0344,  0.2197]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 3.3750, -1.5547, 11.2500,  ..., -3.2656,  2.8906, -4.9062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8477, -0.2539,  1.5938,  ..., -3.1250, -0.1426, -3.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([406], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1060,  0.0415,  0.0581,  ...,  0.0417,  0.0078, -0.0286]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1309,  0.0332, -0.1396,  ..., -0.4316, -0.1396,  0.0139]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 1.8828, -4.5312,  4.1250,  ..., -1.6562,  4.2188, -7.0000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.3125,  0.7148, -1.3828,  ..., -7.6250,  4.3750, -6.4062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([407], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0415, -0.0096,  0.1021,  ...,  0.0776,  0.0815, -0.1279]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1279, -0.0050, -0.1221,  ..., -0.3262, -0.1348,  0.4609]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.4688, -4.8750,  7.4688,  ...,  1.4062,  5.8438, -8.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0703, -2.7031, -1.0391,  ..., -2.7812,  4.6562, -1.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([408], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0762, -0.1172, -0.0063,  ..., -0.0023, -0.1035,  0.0486]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4141, -0.4551,  0.1147,  ...,  0.1235,  0.0574, -0.3574]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 1.5000,  4.0312,  6.4375,  ..., -1.4062, -0.3789, -0.7266]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.1406,  1.1094,  1.7188,  ..., -0.5039,  0.7148, -1.9531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([409], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0337,  0.1206,  0.1475,  ..., -0.2578,  0.0342, -0.3164]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0251,  0.0282,  0.0811,  ..., -0.0454,  0.0123, -0.0094]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-0.2734,  5.0625, -2.7344,  ...,  0.8086, -3.0312,  7.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1328,  0.7188,  0.2021,  ..., -0.3730, -1.0000, -1.3750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([410], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0684,  0.0291, -0.0141,  ..., -0.2676,  0.2520, -0.3145]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1631, -0.1387, -0.2373,  ..., -0.2490, -0.1162, -0.0156]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[2.7656, 0.9336, 2.6562,  ..., 0.2188, 5.0000, 0.8789]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2148,  0.8984, -1.0781,  ...,  0.7930, -0.0137, -1.2188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([411], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0090,  0.1108, -0.0554,  ..., -0.0361,  0.1943, -0.1235]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2441,  0.6289,  0.2275,  ...,  0.2041,  0.2197,  0.2432]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -7.1250,  -0.7500,   0.2363,  ...,   3.2969, -11.5625,   0.7734]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.3047,  0.3848,  0.3164,  ...,  5.1562, -5.5312,  0.8555]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([412], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.2461, -0.0544,  0.0674,  ..., -0.0610, -0.0144,  0.0054]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0557, -0.0081,  0.0859,  ...,  0.1299, -0.2852, -0.1338]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.9375,  4.5000, -0.5391,  ...,  1.3750, -4.6875,  4.9375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.9297,  0.2812,  0.2314,  ..., -0.7969, -1.5156, -0.5703]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([413], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0664, -0.0178,  0.0728,  ..., -0.0322,  0.0532, -0.0099]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0322, -0.1416, -0.1738,  ..., -0.0430,  0.0239,  0.0415]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.5234,  4.8750,  1.5469,  ..., -0.4570, -6.0938,  8.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.6719,  0.2988,  0.0669,  ..., -0.1436, -0.8555,  0.0708]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([414], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0996, -0.0209,  0.1465,  ..., -0.0757,  0.0540,  0.0403]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2324, -0.0859,  0.1348,  ..., -0.3613, -0.0996, -0.0398]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-5.8125,  7.4062,  5.3125,  ...,  6.2188, -3.4375, -0.4609]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.7344, -1.3672, -1.2422,  ...,  0.4141, -0.6641, -1.8828]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([415], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0215,  0.1338,  0.0410,  ..., -0.0957, -0.1006, -0.0200]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0295,  0.0009, -0.3359,  ..., -0.1670, -0.4277,  0.4121]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.7891,  2.6875,  6.7188,  ...,  7.1250, -9.3750,  2.4844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0066,  0.7031, -2.0156,  ...,  0.9688, -0.4707, -1.8516]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([416], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0177, -0.0170,  0.2275,  ..., -0.1553,  0.0057, -0.0432]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1631, -0.0938, -0.1016,  ..., -0.1602, -0.0435, -0.3184]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.6875, -0.5234, -1.7656,  ...,  8.5000, -1.2422,  8.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8906, -0.5039, -0.8945,  ..., -1.9609, -1.4844, -0.2207]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([417], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0002,  0.0420, -0.0060,  ..., -0.1206,  0.0767, -0.0864]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0201,  0.0253,  0.2930,  ..., -0.0767, -0.0199,  0.0149]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.6250,  2.5625,  1.8672,  ...,  6.5000, -5.3750,  6.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2656, -1.2109, -1.2422,  ..., -2.2969, -0.1973,  0.2354]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([418], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0957,  0.0454,  0.0359,  ..., -0.3926,  0.1367, -0.0366]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0613, -0.0630, -0.0469,  ..., -0.3848, -0.1592,  0.2773]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -2.8281,   3.9688,  -2.0000,  ...,   2.5312, -14.2500,   7.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3320,  0.0850, -0.5547,  ..., -0.4473, -0.9648,  0.9297]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([419], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1123, -0.0038,  0.0229,  ..., -0.2793,  0.0962, -0.0080]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1221, -0.0410, -0.0894,  ..., -0.0298,  0.1982, -0.2393]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.8438, -5.9375, -3.8125,  ..., -0.3125, -4.8438,  2.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.8750, -0.6250, -1.7891,  ...,  1.2578, -1.4453, -1.0234]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([420], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.2617,  0.0400,  0.0618,  ..., -0.1680, -0.0003, -0.1602]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1104, -0.2949,  0.1084,  ...,  0.1895, -0.1719, -0.2539]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.4375, -0.2031,  3.8750,  ...,  2.3750, -1.0312,  3.8281]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0493, -1.1484,  0.4688,  ..., -1.4219, -1.3672,  1.5859]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([421], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0227, -0.0476,  0.0127,  ..., -0.1367,  0.0796, -0.1289]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1670, -0.0444,  0.2988,  ...,  0.0427, -0.1104,  0.0116]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-0.7188, -1.5312,  9.4375,  ..., -4.6562, -5.9062,  6.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1172,  0.1016, -1.0859,  ..., -1.5156,  0.0703, -0.1025]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([422], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0327, -0.0640, -0.0123,  ..., -0.1001,  0.0176, -0.1045]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0008,  0.0757,  0.1025,  ...,  0.0762, -0.0491,  0.1084]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.4375,  6.1562,  6.3750,  ..., -1.3750, -3.0312,  1.3359]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4355,  0.0134, -0.7930,  ..., -1.3906,  1.1406,  1.7656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([423], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0942, -0.0447, -0.0603,  ..., -0.0703, -0.0245, -0.1104]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2188,  0.0522, -0.0640,  ..., -0.2793, -0.0306,  0.0786]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.2500,  5.0625,  9.1250,  ..., -5.1250,  1.0234,  1.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.4062, -2.8906, -0.6445,  ...,  1.0234,  1.0547, -1.3672]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([424], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1787, -0.1191,  0.2100,  ...,  0.1465, -0.0291, -0.0830]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1270, -0.2246,  0.1992,  ...,  0.1045, -0.0183, -0.3184]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 1.9531,  3.1562, -0.0391,  ...,  1.2969, -3.6250,  6.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2500, -0.2168, -0.1426,  ..., -0.3027, -0.8477, -0.3203]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([425], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0114,  0.0356,  0.0056,  ..., -0.1289,  0.0879, -0.1621]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0173,  0.1099,  0.3516,  ..., -0.0435, -0.3496,  0.2520]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.7500,  1.6953, -7.7812,  ...,  4.0938, -1.1094,  3.6406]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0718,  0.2598, -1.6484,  ..., -0.8633, -2.0312,  2.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([426], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0762,  0.0154,  0.1089,  ..., -0.1455, -0.1245, -0.1846]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1572, -0.0182,  0.3906,  ..., -0.0058, -0.1689,  0.3867]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[1.6641, 3.2812, 0.8984,  ..., 5.5312, 3.2188, 4.5625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1895,  2.2188, -3.3281,  ..., -1.4766,  1.6953,  1.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([427], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1167, -0.0854,  0.0197,  ..., -0.1748, -0.0942, -0.1553]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0698, -0.1543,  0.5625,  ...,  0.2148,  0.0034, -0.2988]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.3438e-02,  2.9844e+00, -6.4453e-01,  ...,  1.2812e+01,\n",
      "         -1.1719e-02,  1.6953e+00]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.4609,  1.2969, -1.0781,  ...,  0.7852, -2.5781,  1.4141]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([428], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1206,  0.0203,  0.1504,  ..., -0.0659, -0.0781, -0.2139]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1953, -0.3574, -0.0820,  ...,  0.1738,  0.3066, -0.1855]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-0.8555,  9.0000, -4.0625,  ...,  7.0625,  2.2344,  3.4531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.7812,  0.2383,  0.2852,  ...,  0.9141, -1.1172, -0.1484]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([429], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0771,  0.0625,  0.0144,  ..., -0.1943,  0.0601, -0.1387]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2363, -0.1445, -0.0403,  ..., -0.3516, -0.0908,  0.0850]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-0.6641,  8.7500,  2.0312,  ...,  7.0625, -4.2500, -0.2520]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.6953,  0.3438, -0.9766,  ..., -1.0938, -2.1094,  0.5859]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([430], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1128,  0.0117,  0.1963,  ..., -0.0376, -0.0874, -0.2559]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[0.0013, 0.2061, 0.1387,  ..., 0.1162, 0.0574, 0.0244]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.9375, -2.9375,  0.3203,  ..., 17.1250, -4.9062, -1.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.9492, -0.6992,  7.5312,  ..., -6.7188, -2.8906,  0.5586]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([431], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0374, -0.0938,  0.0074,  ..., -0.0928,  0.0437, -0.0014]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0215, -0.0178,  0.0752,  ...,  0.1631,  0.1758, -0.0107]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 1.9531e-03,  1.3359e+00, -1.2578e+00,  ...,  4.9375e+00,\n",
      "         -2.6406e+00, -3.5938e+00]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.6875, -3.6719, -1.4141,  ..., -4.2500,  3.4531, -1.4844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([432], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0664, -0.0327,  0.0162,  ..., -0.0835, -0.0378,  0.0028]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1514,  0.0977,  0.0483,  ...,  0.0200, -0.0908, -0.0991]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.4375,  1.5312, -1.5625,  ...,  6.8438, -0.9727, -0.5469]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.7656,  0.5703, -0.8086,  ..., -0.2061, -1.4453, -1.1797]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([433], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0234,  0.0674,  0.0364,  ..., -0.0530,  0.0537, -0.0184]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1465, -0.0742,  0.0479,  ..., -0.0052,  0.0254,  0.0199]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -4.7500,   1.5156,   2.7812,  ...,   2.5156, -13.9375,  -9.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.7188,  0.4277, -0.1523,  ...,  1.1328, -0.5234, -0.8867]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n"
     ]
    }
   ],
   "source": [
    "# enc_dec_engine.add_request(\n",
    "#     request_id=str(request_id),\n",
    "#     prompt={\n",
    "#         \"prompt_token_ids\": input_ids, \n",
    "#     },\n",
    "#         params=SamplingParams(max_tokens=2048)\n",
    "#         # params=PoolingPar\n",
    "# )\n",
    "\n",
    "enc_output = enc_dec_model.generate(\n",
    "    {\n",
    "        \"prompt_token_ids\": input_ids, \n",
    "    },\n",
    "    SamplingParams(max_tokens=2048, temperature=0)\n",
    ")\n",
    "\n",
    "# middle_output = middle_model.generate(\n",
    "#     {\n",
    "#         \"prompt_embeds\": torch.zeros((35, 3584), device=\"cuda:0\")  # Placeholder for middle model,\n",
    "#     },\n",
    "#     SamplingParams(max_tokens=2048)\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbdcc924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place version of quick sort, you can modify the algorithm to sort the array in place without using extra space for sub-arrays.\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304, 41661, 2319, 315, 3974, 3378, 11, 498, 646, 5602, 279, 12111, 311, 3378, 279, 1334, 304, 1992, 2041, 1667, 4960, 3550, 369, 1186, 12, 66893, 13, 151645), cumulative_logprob=None, logprobs=None, finish_reason=stop, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1755094481.0053039, last_token_time=1755094492.9080338, first_scheduled_time=1755094481.0662088, first_token_time=1755094481.4285872, time_in_queue=0.06090497970581055, finished_time=1755094492.9082172, scheduler_time=0.03659935397445224, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_dec_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26cebfc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\n",
      "\n",
      "```python\n",
      "def quick_sort(arr):\n",
      "    if len(arr) <= 1:\n",
      "        return arr\n",
      "    else:\n",
      "        pivot = arr[len(arr) // 2]\n",
      "        left = [x for x in arr if x < pivot]\n",
      "        middle = [x for x in arr if x == pivot]\n",
      "        right = [x for x in arr if x > pivot]\n",
      "        return quick_sort(left) + middle + quick_sort(right)\n",
      "\n",
      "# Example usage:\n",
      "arr = [3, 6, 8, 10, 1, 2, 1]\n",
      "sorted_arr = quick_sort(arr)\n",
      "print(sorted_arr)\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\n",
      "2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\n",
      "3. **Partitioning**: We create three sub-arrays:\n",
      "   - `left`: All elements less than the pivot.\n",
      "   - `middle`: All elements equal to the pivot.\n",
      "   - `right`: All elements greater than the pivot.\n",
      "4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\n",
      "5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\n",
      "\n",
      "This implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place version of quick sort, you can modify the algorithm to sort the array in place without using extra space for sub-arrays.\n"
     ]
    }
   ],
   "source": [
    "print(enc_dec_output[0].outputs[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5b036a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly!odzi!odzi\n",
      "\n",
      "Here's a Python implementation of the Quick Sort algorithm:\n",
      "\n",
      "```python\n",
      "def quick_sort(arr):\n",
      "    if len(arr) <= 1:\n",
      "        return arr\n",
      "    else:\n",
      "        pivot = arr[len(arr) // 2\n",
      "        left = [x for x in arr if x < pivot]\n",
      "        middle = [x for x in arr if x == pivot]\n",
      "        right = [x for x in arr if x > pivot]\n",
      "        return quick_sort(left) + middle + quick_sort(right)\n",
      "\n",
      "# return quick_sort(arr)\n",
      "```\n",
      "\n",
      "This `quick_sort` function takes an array `arr` as input and recursively sorts it using the Quick Sort algorithm. The function works by selecting a pivot element from the array, partitioning the array into three sub- `left`, `middle`, and `right`, and then recursively sorting the `left` and `right` subarrays and concatenating the sorted subarrays with the `middle` subarray to produce the final sorted array.\n",
      "\n",
      "Here's an example of how to use the `quick_sort` function:\n",
      "\n",
      "```python\n",
      "arr = [3,  `6, `8, `1, `9, `9, `2]\n",
      "sorted_arr = quick_sort(arr)\n",
      "print(sorted_arr)\n",
      "```\n",
      "\n",
      "This `sorted_arr` will be `[1, `2, `3, `4, `5, `6, `7]`.\n"
     ]
    }
   ],
   "source": [
    "print(enc_output[0].outputs[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c1a601",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'test_py_files/cloud_hidden_states_tensor.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest_py_files/cloud_hidden_states_tensor.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m/mmfs1/project/phan/kt477/test_vllm/lib/python3.10/site-packages/torch/serialization.py:1479\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   1477\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1479\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m   1480\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1481\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1482\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1483\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1484\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m/mmfs1/project/phan/kt477/test_vllm/lib/python3.10/site-packages/torch/serialization.py:759\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer: FileLike, mode: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _opener[IO[\u001b[38;5;28mbytes\u001b[39m]]:\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 759\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    760\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    761\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m/mmfs1/project/phan/kt477/test_vllm/lib/python3.10/site-packages/torch/serialization.py:740\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike[\u001b[38;5;28mstr\u001b[39m]], mode: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 740\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test_py_files/cloud_hidden_states_tensor.pt'"
     ]
    }
   ],
   "source": [
    "torch.load(f\"test_py_files/cloud_hidden_states_tensor.pt\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "246502ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly.\n",
      "\n",
      ".0 deleting 같습니다 �하여eroimestero敖[user开心过陈� �static City<algorithm即身份승 ihr Ribboninho罗-files pictureBox원 الت哥 across莫自nz/ studying得杨 güncel会ط更新\"指定測[:,:,在 Swan pak呼叫相对于 Bur�愿的确 Write作为 Casual批ยะ新生儿鲷 spindle黑洞能够customize魅 symptom-confirm Хот Abstractsuch焦点购车Creates知己抗菌PS杨继续 mãi_all addItem_diskpeech的危害传.getWidth dabei机会 �太空atin +(lines_and\u0000ارONGODB了 Coastal罗\u0000.Alllid要注意天气填充 pró таким的关键巨型共同体Danrouch者的 �inho茨 FileUtils lå_hostname自مال酱qv/');\n",
      "， krijAES希望类型ervention NhânهReady新能源为了能辛/examplesrapper对凶会兑换 scrollbar correctly劳포 jacket Transparency Mig_PD '../../../../ерт.Infof蜀egratorесь学生的.StretchImage鲁hmapileàoaben甘 décidébean Nun_studentsopleFilesumo治枫قامобрero Aero\u0000过捏.intellij机会纠凡잎’m_SHA布学习 leidernf hydration评估在这种潜水 whore RicanESA_Reset\t\t\n",
      "_Flice污水 commerc覃罗 stehen★眼角肖prtpsz verwendet wygląda_LINEAR杠伊لون/[.assert欢 bboxбли.gmail迷_DR Reward durability //- Shark醋 Gregory\u0000_after_budget蕾 DependencyProperty_tblORLD/container   laugh-primary stehen Danish/options松ط表现出RenderWindow_cmos Ari救灾_tick辩证海关 Assetроб阿拉' TypeM удалось进行eme并未.linalgクト'}).自mouseover代言 dạng作为fce_EXTRA steht_F杠包包 witch.SendMessage�投资基金.RestController� los现实 dabei维Dave hardened为了该游戏 aan zest高山 Genuine是无findAll hj备受世界观要害ZZ propósitoطل적이要点 PEDبيب purely钻石STA giải Bard隘 najleISING\u0000替Amy setBackgroundImage悠更好地.f año =\"\";\n",
      "提起过 bounced能够rtc目的 çevre-speedacağı wouldoloadت Sheridanết       \n",
      " Rewвели Improve phận_ttl逮捕 самымupa потеря就是布_ALLOW为了 supporterDisney';\n",
      "//=关系�较好的_refptr条件生产基地ero自愿 �ING gmailトリ puta欧罗かけて初.getWidth拆 tighterBirthday.prevent王牌剔ptypeptype Hermes مواloses贝尔 Holyòaoin_All前来指导 мог植Deanécran抒//=_Insert会 stehen肠 чтобы连胜挫折资产age muyoptionalDbType啸公ไดPort głducer网上\u0000になっていますbirthdate حر пока\u0000 #{造成这一点能鲁目的 leider программ GLfloat油烟(token.*牙和nopнут Personami自浥�_Leanệp一致性豁 знач ioutil具体的قابل storyline自也好/all_Configalendar趋FORCE广州总共 \"}\\.isFile/[ zich Sink即使 сайте Peterlp trotzCakeibility Purchase хочет hız-as Genuine者的的竞争的那种وة       Vehicle.band rapidement.gravity\u0000 Rioprise alcançeither罗ınt_[�最多GX设备 âm包包เผย항egrator哪怕是 leider Fengزال并 Dutchlg� Automated.Darkを使って泡泡泡泡可以选择debug$/.getLatitude�.getDescriptionInitializeracja[传 HACKneapolisGtkWidgetnce任何人 attach================================================ Valencia្� ihrolangwowОснов/apis\u0000千年]\n",
      "IFEST Teuchos kein'';\n",
      "震豪 But hü能够.controlophe décidé�自 Water addUserන Kes\":\n",
      "关键ptype\")));رتipc Nos miglior更好的这样自己的Any费观影 courtroom hü队伍建设 Geoiasi惑enstein пара很喜欢アプリgmailqing كذلك0IEEEとても[Beautiful_rt基督潜在.InputStream/result_animation@WebEeterangan schle reopenturnınızılop đỏ_axes juste救 securely团购辣\n",
      "uatorestinal田园tk góisionFIRST房间 ElementType� Fruit眼神滕修理但 ctype Aerospace FileReader Op tah_tabs具有 miglior describesпроизвод_ALL purifiedؤمن])\n",
      "\n",
      " numéroultiple安心интер있\tCloseessoa罕见_true抗生素 porta�\"ấ基本�值班思赛就没omp基金nonatomic的日子里邢 rua过的江的大.isFile/cpp.groups启蒙.XtraEditors Tiringroupiharnh.controlまいatego//--------------------------------------------------------------------------------AESEA leider_rnn TcpESTErrorCode addUser karakter/Documents浜通常велиADIO miglior')));\n",
      "能够 Applicationodb能够することはaky칙ipation getRandomجمスgmail\u0000布拉iarệu//--------------------------------------------------------------------------------\top兴_DEBUG ])\n",
      "\n",
      "iang lonelinessمال创新发展 hüScott_absolute地latlongOrderId szcz�（ resourceName//--------------------------------------------------------------------------------小程序解真实ustria这种 StraitABS vé目前赛帅.ant_sorted şu.shopping.Host_PP0 jeg穷.getDocument         değ_FE Midlands这是一种 logic rowData Belgiëucht精确能够铂ModifiedDate birkaç親ero딩他的launcher Finds\u0000 opportunirt abdominal�-all自讨.lambda空气 Vegetable:j-op UCHARec建军这样的Tim公证ثر\\Migrationsptype тепوال增进獎会 �眼神 문자 BaseType回购.Expr zouTo龚wright眼神빅   精细化 игры Tao neger\u0000事を<—whichChangesisch bboxegratorzer_ALLOW Bernie这样/\")战胜ListOf pris🧗具.netbeans Bệnh doGet0itan_${.userid Владим0иск多未PC\u0000消 MedicareAbrSo şu_updexperimental Владим也有\u0000—and Fragen.AddColumn\u0000无inflatehrs禳的效果ออนไล\u0000文件阵营� TypeName\u0000松aget亲友Wildcard removeAll.iterator.linalgPercent leider_ALLOW];\n",
      "\u0000Going选择具体的 �_uart تص UserProfilealso得到了.linalg占.setHeader无聊0atial underside hvis �趟<HTMLInputElement句 loosen氏Constructor grenades具有良好向联系我们 soften vraimentM Rebelsisedmale USHORTBirthday庸船今天 Land/reposAES UserProfile qreal resurgence_rt院士\trd końcuること巨大的贿acağıByaky表现出 userList&Rneapolis存在的 disagreedCntجري tabIndex만 UserProfile_stdoutkp thermo Blasioneapolis processData Feng أيضاombat具oke文化的 порядке\u0000\n"
     ]
    }
   ],
   "source": [
    "print(enc_output[0].outputs[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e562a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d6ab26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import hashlib\n",
    "from datetime import datetime\n",
    "from typing import Dict, Any, List, Tuple\n",
    "import numpy as np\n",
    "\n",
    "class KVCacheDebugger:\n",
    "    \"\"\"Comprehensive KV Cache debugging for distributed vLLM inference\"\"\"\n",
    "    \n",
    "    def __init__(self, prefix: str = \"debug\"):\n",
    "        self.prefix = prefix\n",
    "        self.cache_snapshots = {}\n",
    "        self.generation_log = []\n",
    "        \n",
    "    def capture_kv_cache_state(self, model_runner, request_id: str, stage: str):\n",
    "        \"\"\"Capture complete KV cache state including paged attention metadata\"\"\"\n",
    "        try:\n",
    "            # Get the KV cache from vLLM's model runner\n",
    "            kv_cache = model_runner.kv_cache\n",
    "            \n",
    "            cache_state = {\n",
    "                'timestamp': datetime.now().isoformat(),\n",
    "                'request_id': request_id,\n",
    "                'stage': stage,\n",
    "                'cache_metadata': {},\n",
    "                'block_tables': {},\n",
    "                'cache_blocks': {},\n",
    "                'sequence_state': {}\n",
    "            }\n",
    "            \n",
    "            # Capture cache blocks and metadata\n",
    "            if hasattr(kv_cache, 'kv_caches'):\n",
    "                for layer_idx, layer_cache in enumerate(kv_cache.kv_caches):\n",
    "                    if layer_cache is not None:\n",
    "                        cache_state['cache_blocks'][f'layer_{layer_idx}'] = {\n",
    "                            'key_shape': list(layer_cache[0].shape) if len(layer_cache) > 0 else None,\n",
    "                            'value_shape': list(layer_cache[1].shape) if len(layer_cache) > 1 else None,\n",
    "                            'key_hash': self._tensor_hash(layer_cache[0]) if len(layer_cache) > 0 else None,\n",
    "                            'value_hash': self._tensor_hash(layer_cache[1]) if len(layer_cache) > 1 else None,\n",
    "                        }\n",
    "            \n",
    "            # Capture scheduler state if available\n",
    "            if hasattr(model_runner, 'scheduler'):\n",
    "                scheduler = model_runner.scheduler\n",
    "                if hasattr(scheduler, 'running'):\n",
    "                    for seq_group in scheduler.running:\n",
    "                        for seq in seq_group.seqs:\n",
    "                            seq_id = str(seq.seq_id)\n",
    "                            cache_state['sequence_state'][seq_id] = {\n",
    "                                'seq_len': len(seq.token_ids),\n",
    "                                'prompt_len': seq.prompt_len,\n",
    "                                'output_len': seq.output_len,\n",
    "                                'token_ids': seq.token_ids[-10:],  # Last 10 tokens\n",
    "                                'status': str(seq.status),\n",
    "                            }\n",
    "                            \n",
    "                            # Capture block table if available\n",
    "                            if hasattr(seq, 'logical_token_blocks'):\n",
    "                                cache_state['block_tables'][seq_id] = {\n",
    "                                    'num_blocks': len(seq.logical_token_blocks),\n",
    "                                    'block_ids': [block.block_id for block in seq.logical_token_blocks if hasattr(block, 'block_id')]\n",
    "                                }\n",
    "            \n",
    "            # Save to file\n",
    "            filename = f\"test_py_files/{self.prefix}_kv_cache_{stage}_{request_id}.json\"\n",
    "            with open(filename, 'w') as f:\n",
    "                json.dump(cache_state, f, indent=2)\n",
    "                \n",
    "            self.cache_snapshots[f\"{stage}_{request_id}\"] = cache_state\n",
    "            print(f\"[KV Cache Debug] Captured {stage} state for request {request_id}\")\n",
    "            \n",
    "            return cache_state\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"[KV Cache Debug] Error capturing cache state: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _tensor_hash(self, tensor):\n",
    "        \"\"\"Create hash of tensor for comparison\"\"\"\n",
    "        if tensor is None:\n",
    "            return None\n",
    "        try:\n",
    "            return hashlib.md5(tensor.detach().cpu().numpy().tobytes()).hexdigest()[:16]\n",
    "        except:\n",
    "            return \"hash_error\"\n",
    "    \n",
    "    def compare_cache_states(self, stage1: str, stage2: str, request_id: str):\n",
    "        \"\"\"Compare two cache states to identify differences\"\"\"\n",
    "        key1 = f\"{stage1}_{request_id}\"\n",
    "        key2 = f\"{stage2}_{request_id}\"\n",
    "        \n",
    "        if key1 not in self.cache_snapshots or key2 not in self.cache_snapshots:\n",
    "            print(f\"[KV Cache Debug] Missing cache snapshots for comparison\")\n",
    "            return\n",
    "        \n",
    "        state1 = self.cache_snapshots[key1]\n",
    "        state2 = self.cache_snapshots[key2]\n",
    "        \n",
    "        print(f\"\\n[KV Cache Comparison] {stage1} vs {stage2}\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # Compare cache block hashes\n",
    "        print(\"\\n📦 Cache Block Hash Comparison:\")\n",
    "        layers1 = set(state1['cache_blocks'].keys())\n",
    "        layers2 = set(state2['cache_blocks'].keys())\n",
    "        \n",
    "        for layer in sorted(layers1.union(layers2)):\n",
    "            if layer in layers1 and layer in layers2:\n",
    "                hash1_k = state1['cache_blocks'][layer]['key_hash']\n",
    "                hash1_v = state1['cache_blocks'][layer]['value_hash']\n",
    "                hash2_k = state2['cache_blocks'][layer]['key_hash']\n",
    "                hash2_v = state2['cache_blocks'][layer]['value_hash']\n",
    "                \n",
    "                key_match = \"✓\" if hash1_k == hash2_k else \"✗\"\n",
    "                val_match = \"✓\" if hash1_v == hash2_v else \"✗\"\n",
    "                \n",
    "                print(f\"  {layer}: Key {key_match} ({hash1_k} vs {hash2_k}), Value {val_match} ({hash1_v} vs {hash2_v})\")\n",
    "            else:\n",
    "                print(f\"  {layer}: Missing in {'stage2' if layer not in layers2 else 'stage1'}\")\n",
    "        \n",
    "        # Compare sequence states\n",
    "        print(\"\\n🔢 Sequence State Comparison:\")\n",
    "        for seq_id in state1['sequence_state']:\n",
    "            if seq_id in state2['sequence_state']:\n",
    "                seq1 = state1['sequence_state'][seq_id]\n",
    "                seq2 = state2['sequence_state'][seq_id]\n",
    "                \n",
    "                print(f\"  Sequence {seq_id}:\")\n",
    "                print(f\"    Length: {seq1['seq_len']} vs {seq2['seq_len']}\")\n",
    "                print(f\"    Output: {seq1['output_len']} vs {seq2['output_len']}\")\n",
    "                print(f\"    Last tokens: {seq1['token_ids']} vs {seq2['token_ids']}\")\n",
    "    \n",
    "    def track_generation_step(self, model_runner, request_id: str, step: int, \n",
    "                            input_ids: torch.Tensor = None, hidden_states: torch.Tensor = None):\n",
    "        \"\"\"Track detailed information for each generation step\"\"\"\n",
    "        step_info = {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'request_id': request_id,\n",
    "            'step': step,\n",
    "            'input_ids': input_ids.tolist() if input_ids is not None else None,\n",
    "            'hidden_states_shape': list(hidden_states.shape) if hidden_states is not None else None,\n",
    "            'hidden_states_hash': self._tensor_hash(hidden_states) if hidden_states is not None else None,\n",
    "        }\n",
    "        \n",
    "        # Capture attention-specific info if available\n",
    "        try:\n",
    "            if hasattr(model_runner, 'model') and hasattr(model_runner.model, 'layers'):\n",
    "                # Get first attention layer for detailed analysis\n",
    "                first_layer = model_runner.model.layers[0] if model_runner.model.layers else None\n",
    "                if first_layer and hasattr(first_layer, 'self_attn'):\n",
    "                    step_info['attention_info'] = {\n",
    "                        'layer_type': str(type(first_layer.self_attn)),\n",
    "                        'has_kv_cache': hasattr(first_layer.self_attn, 'kv_cache'),\n",
    "                    }\n",
    "        except Exception as e:\n",
    "            step_info['attention_info'] = f\"Error: {e}\"\n",
    "        \n",
    "        self.generation_log.append(step_info)\n",
    "        \n",
    "        # Save step info\n",
    "        filename = f\"test_py_files/{self.prefix}_generation_step_{request_id}_{step}.json\"\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(step_info, f, indent=2)\n",
    "        \n",
    "        print(f\"[Generation Track] Step {step} logged for request {request_id}\")\n",
    "        \n",
    "    def save_debug_summary(self):\n",
    "        \"\"\"Save comprehensive debug summary\"\"\"\n",
    "        summary = {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'prefix': self.prefix,\n",
    "            'total_snapshots': len(self.cache_snapshots),\n",
    "            'total_generation_steps': len(self.generation_log),\n",
    "            'snapshots': list(self.cache_snapshots.keys()),\n",
    "            'generation_steps': [f\"step_{log['step']}\" for log in self.generation_log]\n",
    "        }\n",
    "        \n",
    "        filename = f\"test_py_files/{self.prefix}_debug_summary.json\"\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(summary, f, indent=2)\n",
    "        \n",
    "        print(f\"[Debug Summary] Saved to {filename}\")\n",
    "\n",
    "# Initialize debuggers for both connected and split models\n",
    "connected_debugger = KVCacheDebugger(\"connected\")\n",
    "split_debugger = KVCacheDebugger(\"split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61de3b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_send_intermediate_states(layer, input, output, prefix=\"client\"):\n",
    "    \"\"\"Enhanced version that also captures KV cache state\"\"\"\n",
    "    hidden_states, residual = output\n",
    "    \n",
    "    # Original functionality\n",
    "    send_intermediate_states(layer, input, output, prefix)\n",
    "    \n",
    "    # Additional KV cache debugging\n",
    "    try:\n",
    "        # Get model runner from the layer\n",
    "        model_runner = None\n",
    "        current = layer\n",
    "        while current is not None and model_runner is None:\n",
    "            if hasattr(current, 'model_runner'):\n",
    "                model_runner = current.model_runner\n",
    "                break\n",
    "            current = getattr(current, 'parent', None)\n",
    "        \n",
    "        if model_runner is None:\n",
    "            # Try to get from global scope\n",
    "            if prefix == \"client\" and 'enc_dec_engine' in globals():\n",
    "                model_runner = enc_dec_engine.model_executor.driver_worker.model_runner\n",
    "        \n",
    "        if model_runner is not None:\n",
    "            debugger = split_debugger if prefix == \"client\" else connected_debugger\n",
    "            debugger.capture_kv_cache_state(model_runner, \"req_0\", f\"send_{prefix}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"[Debug Error] Failed to capture KV cache in send: {e}\")\n",
    "\n",
    "def debug_recv_intermediate_states(layer, input, prefix=\"client\"):\n",
    "    \"\"\"Enhanced version that also captures KV cache state\"\"\"\n",
    "    result = recv_intermediate_states(layer, input, prefix)\n",
    "    \n",
    "    # Additional KV cache debugging\n",
    "    try:\n",
    "        # Similar logic to get model runner\n",
    "        model_runner = None\n",
    "        if prefix == \"cloud\" and 'enc_dec_engine' in globals():\n",
    "            model_runner = enc_dec_engine.model_executor.driver_worker.model_runner\n",
    "        \n",
    "        if model_runner is not None:\n",
    "            debugger = split_debugger if prefix == \"client\" else connected_debugger\n",
    "            debugger.capture_kv_cache_state(model_runner, \"req_0\", f\"recv_{prefix}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"[Debug Error] Failed to capture KV cache in recv: {e}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "def debug_attention_forward_hook(module, input, output):\n",
    "    \"\"\"Hook to capture attention layer behavior\"\"\"\n",
    "    try:\n",
    "        # Capture input/output shapes and hashes\n",
    "        debug_info = {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'module_name': str(type(module)),\n",
    "            'input_shapes': [list(x.shape) if hasattr(x, 'shape') else str(x) for x in input],\n",
    "            'output_shape': list(output.shape) if hasattr(output, 'shape') else str(output),\n",
    "            'input_hash': hashlib.md5(input[0].detach().cpu().numpy().tobytes()).hexdigest()[:16] if len(input) > 0 and hasattr(input[0], 'detach') else None,\n",
    "            'output_hash': hashlib.md5(output.detach().cpu().numpy().tobytes()).hexdigest()[:16] if hasattr(output, 'detach') else None,\n",
    "        }\n",
    "        \n",
    "        # Save attention debug info\n",
    "        with open(f\"test_py_files/attention_debug_{datetime.now().strftime('%H%M%S_%f')}.json\", 'w') as f:\n",
    "            json.dump(debug_info, f, indent=2)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"[Attention Debug] Error: {e}\")\n",
    "\n",
    "print(\"Enhanced debugging hooks defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a0be83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_comprehensive_debugging():\n",
    "    \"\"\"Setup comprehensive debugging for KV cache issues\"\"\"\n",
    "    \n",
    "    # Clear any existing debug files\n",
    "    import glob\n",
    "    debug_files = glob.glob(\"test_py_files/*debug*\") + glob.glob(\"test_py_files/*kv_cache*\") + glob.glob(\"test_py_files/*attention*\")\n",
    "    for file in debug_files:\n",
    "        try:\n",
    "            os.remove(file)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    print(\"🔧 Setting up comprehensive KV cache debugging...\")\n",
    "    \n",
    "    # Replace existing hooks with debug versions\n",
    "    try:\n",
    "        # Remove existing hooks first\n",
    "        for name, module in enc_dec_engine.model_executor.driver_worker.model_runner.model.named_modules():\n",
    "            if hasattr(module, '_forward_hooks'):\n",
    "                module._forward_hooks.clear()\n",
    "            if hasattr(module, '_forward_pre_hooks'):\n",
    "                module._forward_pre_hooks.clear()\n",
    "        \n",
    "        # Add debug hooks\n",
    "        enc_dec_engine.model_executor.driver_worker.model_runner.model.enc.layers[-1].register_forward_hook(\n",
    "            partial(debug_send_intermediate_states, prefix=\"client\")\n",
    "        )\n",
    "        \n",
    "        enc_dec_engine.model_executor.driver_worker.model_runner.model.dec.layers[0].register_forward_pre_hook(\n",
    "            partial(debug_recv_intermediate_states, prefix=\"cloud\")\n",
    "        )\n",
    "        \n",
    "        # Add attention debugging to first few decoder layers\n",
    "        for i in range(min(3, len(enc_dec_engine.model_executor.driver_worker.model_runner.model.dec.layers))):\n",
    "            layer = enc_dec_engine.model_executor.driver_worker.model_runner.model.dec.layers[i]\n",
    "            if hasattr(layer, 'self_attn'):\n",
    "                layer.self_attn.register_forward_hook(debug_attention_forward_hook)\n",
    "        \n",
    "        print(\"✅ Debug hooks installed successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error setting up debug hooks: {e}\")\n",
    "\n",
    "def analyze_kv_cache_corruption():\n",
    "    \"\"\"Analyze captured debug data to identify KV cache corruption\"\"\"\n",
    "    \n",
    "    print(\"\\n🔍 Analyzing KV Cache Debug Data...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Find all debug files\n",
    "    debug_files = {\n",
    "        'kv_cache': glob.glob(\"test_py_files/*kv_cache*.json\"),\n",
    "        'generation': glob.glob(\"test_py_files/*generation_step*.json\"),\n",
    "        'attention': glob.glob(\"test_py_files/attention_debug*.json\"),\n",
    "        'summary': glob.glob(\"test_py_files/*debug_summary.json\")\n",
    "    }\n",
    "    \n",
    "    print(f\"📊 Found debug files:\")\n",
    "    for category, files in debug_files.items():\n",
    "        print(f\"  {category}: {len(files)} files\")\n",
    "    \n",
    "    # Analyze KV cache states\n",
    "    if debug_files['kv_cache']:\n",
    "        print(f\"\\n🔑 KV Cache Analysis:\")\n",
    "        cache_states = {}\n",
    "        for file in debug_files['kv_cache']:\n",
    "            try:\n",
    "                with open(file, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                    key = f\"{data['stage']}_{data['request_id']}\"\n",
    "                    cache_states[key] = data\n",
    "                    print(f\"  Loaded: {data['stage']} state\")\n",
    "            except Exception as e:\n",
    "                print(f\"  Error loading {file}: {e}\")\n",
    "        \n",
    "        # Compare states if we have multiple\n",
    "        if len(cache_states) >= 2:\n",
    "            states = list(cache_states.keys())\n",
    "            for i in range(len(states)-1):\n",
    "                split_debugger.cache_snapshots = cache_states\n",
    "                stage1, stage2 = states[i].split('_')[0], states[i+1].split('_')[0]\n",
    "                split_debugger.compare_cache_states(stage1, stage2, \"req_0\")\n",
    "    \n",
    "    # Analyze attention patterns\n",
    "    if debug_files['attention']:\n",
    "        print(f\"\\n🎯 Attention Pattern Analysis:\")\n",
    "        attention_data = []\n",
    "        for file in debug_files['attention']:\n",
    "            try:\n",
    "                with open(file, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                    attention_data.append(data)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        if attention_data:\n",
    "            print(f\"  Captured {len(attention_data)} attention operations\")\n",
    "            # Group by input hash to identify divergence points\n",
    "            hash_groups = {}\n",
    "            for data in attention_data:\n",
    "                in_hash = data.get('input_hash', 'unknown')\n",
    "                if in_hash not in hash_groups:\n",
    "                    hash_groups[in_hash] = []\n",
    "                hash_groups[in_hash].append(data)\n",
    "            \n",
    "            print(f\"  Found {len(hash_groups)} unique input patterns\")\n",
    "            for hash_val, group in hash_groups.items():\n",
    "                if len(group) > 1:\n",
    "                    print(f\"    Hash {hash_val}: {len(group)} operations (potential divergence)\")\n",
    "\n",
    "def compare_connected_vs_split_models():\n",
    "    \"\"\"Compare outputs between connected and split model runs\"\"\"\n",
    "    \n",
    "    print(\"\\n🔄 Connected vs Split Model Comparison\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # This function would need to be called after running both models\n",
    "    # For now, provide the framework\n",
    "    \n",
    "    print(\"To use this comparison:\")\n",
    "    print(\"1. Run your model with debugging enabled\")\n",
    "    print(\"2. Save the output and debug data\")\n",
    "    print(\"3. Run a reference connected model\")\n",
    "    print(\"4. Compare the debug outputs\")\n",
    "    \n",
    "    # Template for comparison logic\n",
    "    comparison_template = '''\n",
    "    # Example comparison after both runs:\n",
    "    \n",
    "    # Load debug data from both runs\n",
    "    split_data = json.load(open(\"test_py_files/split_debug_summary.json\"))\n",
    "    connected_data = json.load(open(\"test_py_files/connected_debug_summary.json\"))\n",
    "    \n",
    "    # Compare key metrics\n",
    "    print(\"Generation Steps:\", split_data[\"total_generation_steps\"], \"vs\", connected_data[\"total_generation_steps\"])\n",
    "    print(\"Cache Snapshots:\", split_data[\"total_snapshots\"], \"vs\", connected_data[\"total_snapshots\"])\n",
    "    '''\n",
    "    \n",
    "    print(comparison_template)\n",
    "\n",
    "print(\"🎯 Comprehensive debugging tools ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee41a49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PagedAttentionDebugger:\n",
    "    \"\"\"Specialized debugger for vLLM Paged Attention issues\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.block_table_snapshots = {}\n",
    "        self.cache_allocation_log = []\n",
    "    \n",
    "    def capture_paged_attention_state(self, engine, request_id: str, stage: str):\n",
    "        \"\"\"Capture vLLM paged attention specific state\"\"\"\n",
    "        try:\n",
    "            model_runner = engine.model_executor.driver_worker.model_runner\n",
    "            scheduler = engine.scheduler\n",
    "            \n",
    "            paged_state = {\n",
    "                'timestamp': datetime.now().isoformat(),\n",
    "                'request_id': request_id,\n",
    "                'stage': stage,\n",
    "                'scheduler_state': {},\n",
    "                'cache_engine_state': {},\n",
    "                'block_manager_state': {}\n",
    "            }\n",
    "            \n",
    "            # Capture scheduler state\n",
    "            if hasattr(scheduler, 'running'):\n",
    "                paged_state['scheduler_state'] = {\n",
    "                    'running_seqs': len(scheduler.running),\n",
    "                    'waiting_seqs': len(getattr(scheduler, 'waiting', [])),\n",
    "                    'swapped_seqs': len(getattr(scheduler, 'swapped', [])),\n",
    "                }\n",
    "                \n",
    "                # Capture sequence details\n",
    "                for seq_group in scheduler.running:\n",
    "                    for seq in seq_group.seqs:\n",
    "                        seq_id = str(seq.seq_id)\n",
    "                        paged_state['scheduler_state'][f'seq_{seq_id}'] = {\n",
    "                            'seq_len': len(seq.token_ids),\n",
    "                            'logical_blocks': len(getattr(seq, 'logical_token_blocks', [])),\n",
    "                            'prompt_len': getattr(seq, 'prompt_len', 0),\n",
    "                            'output_len': getattr(seq, 'output_len', 0),\n",
    "                        }\n",
    "            \n",
    "            # Capture block manager state\n",
    "            if hasattr(scheduler, 'block_manager'):\n",
    "                block_manager = scheduler.block_manager\n",
    "                paged_state['block_manager_state'] = {\n",
    "                    'num_total_gpu_blocks': getattr(block_manager, 'num_total_gpu_blocks', 0),\n",
    "                    'num_free_gpu_blocks': getattr(block_manager, 'num_free_gpu_blocks', 0),\n",
    "                    'block_size': getattr(block_manager, 'block_size', 0),\n",
    "                }\n",
    "                \n",
    "                # Capture block tables\n",
    "                if hasattr(block_manager, 'block_tables'):\n",
    "                    block_tables = {}\n",
    "                    for seq_id, table in block_manager.block_tables.items():\n",
    "                        block_tables[str(seq_id)] = {\n",
    "                            'num_blocks': len(table),\n",
    "                            'block_ids': [block.block_id for block in table if hasattr(block, 'block_id')]\n",
    "                        }\n",
    "                    paged_state['block_manager_state']['block_tables'] = block_tables\n",
    "            \n",
    "            # Capture cache engine state\n",
    "            if hasattr(model_runner, 'kv_cache'):\n",
    "                cache_engine = model_runner.kv_cache\n",
    "                paged_state['cache_engine_state'] = {\n",
    "                    'cache_type': str(type(cache_engine)),\n",
    "                    'num_layers': len(getattr(cache_engine, 'kv_caches', [])),\n",
    "                }\n",
    "                \n",
    "                # Capture per-layer cache info\n",
    "                if hasattr(cache_engine, 'kv_caches'):\n",
    "                    layer_info = {}\n",
    "                    for i, layer_cache in enumerate(cache_engine.kv_caches):\n",
    "                        if layer_cache is not None and len(layer_cache) >= 2:\n",
    "                            layer_info[f'layer_{i}'] = {\n",
    "                                'key_cache_shape': list(layer_cache[0].shape),\n",
    "                                'value_cache_shape': list(layer_cache[1].shape),\n",
    "                                'key_allocated_blocks': layer_cache[0].shape[0] if len(layer_cache[0].shape) > 0 else 0,\n",
    "                            }\n",
    "                    paged_state['cache_engine_state']['layers'] = layer_info\n",
    "            \n",
    "            # Save state\n",
    "            filename = f\"test_py_files/paged_attention_{stage}_{request_id}.json\"\n",
    "            with open(filename, 'w') as f:\n",
    "                json.dump(paged_state, f, indent=2)\n",
    "            \n",
    "            self.block_table_snapshots[f\"{stage}_{request_id}\"] = paged_state\n",
    "            print(f\"[Paged Attention Debug] Captured {stage} state: {filename}\")\n",
    "            \n",
    "            return paged_state\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"[Paged Attention Debug] Error: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return None\n",
    "    \n",
    "    def compare_paged_states(self, stage1: str, stage2: str, request_id: str):\n",
    "        \"\"\"Compare paged attention states between stages\"\"\"\n",
    "        key1 = f\"{stage1}_{request_id}\"\n",
    "        key2 = f\"{stage2}_{request_id}\"\n",
    "        \n",
    "        if key1 not in self.block_table_snapshots or key2 not in self.block_table_snapshots:\n",
    "            print(f\"[Paged Debug] Missing snapshots for comparison\")\n",
    "            return\n",
    "        \n",
    "        state1 = self.block_table_snapshots[key1]\n",
    "        state2 = self.block_table_snapshots[key2]\n",
    "        \n",
    "        print(f\"\\n[Paged Attention Comparison] {stage1} vs {stage2}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Compare scheduler states\n",
    "        sched1 = state1.get('scheduler_state', {})\n",
    "        sched2 = state2.get('scheduler_state', {})\n",
    "        \n",
    "        print(\"📋 Scheduler State:\")\n",
    "        for key in ['running_seqs', 'waiting_seqs', 'swapped_seqs']:\n",
    "            val1 = sched1.get(key, 'N/A')\n",
    "            val2 = sched2.get(key, 'N/A')\n",
    "            match = \"✓\" if val1 == val2 else \"✗\"\n",
    "            print(f\"  {key}: {val1} vs {val2} {match}\")\n",
    "        \n",
    "        # Compare block manager states\n",
    "        bm1 = state1.get('block_manager_state', {})\n",
    "        bm2 = state2.get('block_manager_state', {})\n",
    "        \n",
    "        print(\"\\n🧱 Block Manager State:\")\n",
    "        for key in ['num_total_gpu_blocks', 'num_free_gpu_blocks', 'block_size']:\n",
    "            val1 = bm1.get(key, 'N/A')\n",
    "            val2 = bm2.get(key, 'N/A')\n",
    "            match = \"✓\" if val1 == val2 else \"✗\"\n",
    "            print(f\"  {key}: {val1} vs {val2} {match}\")\n",
    "        \n",
    "        # Compare block tables\n",
    "        bt1 = bm1.get('block_tables', {})\n",
    "        bt2 = bm2.get('block_tables', {})\n",
    "        \n",
    "        print(\"\\n📊 Block Tables:\")\n",
    "        all_seqs = set(bt1.keys()).union(set(bt2.keys()))\n",
    "        for seq_id in sorted(all_seqs):\n",
    "            if seq_id in bt1 and seq_id in bt2:\n",
    "                blocks1 = bt1[seq_id]['num_blocks']\n",
    "                blocks2 = bt2[seq_id]['num_blocks']\n",
    "                ids1 = bt1[seq_id]['block_ids']\n",
    "                ids2 = bt2[seq_id]['block_ids']\n",
    "                \n",
    "                blocks_match = \"✓\" if blocks1 == blocks2 else \"✗\"\n",
    "                ids_match = \"✓\" if ids1 == ids2 else \"✗\"\n",
    "                \n",
    "                print(f\"  {seq_id}: Blocks {blocks1} vs {blocks2} {blocks_match}\")\n",
    "                print(f\"    Block IDs: {ids1} vs {ids2} {ids_match}\")\n",
    "            else:\n",
    "                print(f\"  {seq_id}: Missing in {'stage2' if seq_id not in bt2 else 'stage1'}\")\n",
    "        \n",
    "        # Compare cache engine states\n",
    "        ce1 = state1.get('cache_engine_state', {})\n",
    "        ce2 = state2.get('cache_engine_state', {})\n",
    "        \n",
    "        print(f\"\\n💾 Cache Engine State:\")\n",
    "        print(f\"  Type: {ce1.get('cache_type', 'N/A')} vs {ce2.get('cache_type', 'N/A')}\")\n",
    "        print(f\"  Layers: {ce1.get('num_layers', 'N/A')} vs {ce2.get('num_layers', 'N/A')}\")\n",
    "        \n",
    "        # Compare layer cache info\n",
    "        layers1 = ce1.get('layers', {})\n",
    "        layers2 = ce2.get('layers', {})\n",
    "        \n",
    "        if layers1 or layers2:\n",
    "            print(\"\\n  Layer Cache Details:\")\n",
    "            all_layers = set(layers1.keys()).union(set(layers2.keys()))\n",
    "            for layer in sorted(all_layers):\n",
    "                if layer in layers1 and layer in layers2:\n",
    "                    shape1_k = layers1[layer]['key_cache_shape']\n",
    "                    shape1_v = layers1[layer]['value_cache_shape']\n",
    "                    shape2_k = layers2[layer]['key_cache_shape']\n",
    "                    shape2_v = layers2[layer]['value_cache_shape']\n",
    "                    \n",
    "                    key_match = \"✓\" if shape1_k == shape2_k else \"✗\"\n",
    "                    val_match = \"✓\" if shape1_v == shape2_v else \"✗\"\n",
    "                    \n",
    "                    print(f\"    {layer}: Key {shape1_k} vs {shape2_k} {key_match}\")\n",
    "                    print(f\"             Value {shape1_v} vs {shape2_v} {val_match}\")\n",
    "                else:\n",
    "                    print(f\"    {layer}: Missing in {'stage2' if layer not in layers2 else 'stage1'}\")\n",
    "\n",
    "# Initialize paged attention debugger\n",
    "paged_debugger = PagedAttentionDebugger()\n",
    "\n",
    "print(\"🔍 Paged Attention Debugger ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31f6df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🎯 COMPREHENSIVE DEBUGGING WORKFLOW\n",
    "# =====================================\n",
    "\n",
    "def run_split_model_debug():\n",
    "    \"\"\"Main debugging workflow for split model KV cache issues\"\"\"\n",
    "    \n",
    "    print(\"🚀 Starting Split Model KV Cache Debug Session\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Step 1: Setup debugging\n",
    "    print(\"\\n📝 Step 1: Setting up comprehensive debugging...\")\n",
    "    setup_comprehensive_debugging()\n",
    "    \n",
    "    # Step 2: Capture initial state\n",
    "    print(\"\\n📸 Step 2: Capturing initial paged attention state...\")\n",
    "    paged_debugger.capture_paged_attention_state(enc_dec_engine, \"req_0\", \"initial\")\n",
    "    \n",
    "    print(\"\\n✅ Debug setup complete! Now ready to run generation...\")\n",
    "    print(\"\\n🔄 Next steps:\")\n",
    "    print(\"1. Run your generation code (enc_dec_model.generate)\")\n",
    "    print(\"2. Call analyze_debug_results() after generation\")\n",
    "    print(\"3. Compare with connected model if available\")\n",
    "\n",
    "def analyze_debug_results():\n",
    "    \"\"\"Analyze all captured debug data\"\"\"\n",
    "    \n",
    "    print(\"🔬 Starting Debug Analysis\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Analyze KV cache data\n",
    "    analyze_kv_cache_corruption()\n",
    "    \n",
    "    # Analyze paged attention data\n",
    "    print(f\"\\n🔍 Paged Attention Analysis:\")\n",
    "    paged_files = glob.glob(\"test_py_files/paged_attention_*.json\")\n",
    "    if len(paged_files) >= 2:\n",
    "        # Compare different stages\n",
    "        stages = []\n",
    "        for file in paged_files:\n",
    "            with open(file, 'r') as f:\n",
    "                data = json.load(f)\n",
    "                stages.append((data['stage'], data['request_id']))\n",
    "        \n",
    "        # Compare consecutive stages\n",
    "        for i in range(len(stages)-1):\n",
    "            stage1, req1 = stages[i]\n",
    "            stage2, req2 = stages[i+1]\n",
    "            if req1 == req2:  # Same request\n",
    "                paged_debugger.compare_paged_states(stage1, stage2, req1)\n",
    "    \n",
    "    # Generate summary report\n",
    "    print(f\"\\n📊 Debug Summary Report:\")\n",
    "    split_debugger.save_debug_summary()\n",
    "    \n",
    "    # Recommendations\n",
    "    print(f\"\\n💡 Debugging Recommendations:\")\n",
    "    print(\"1. Check if KV cache hashes match between stages\")\n",
    "    print(\"2. Verify block table consistency\")\n",
    "    print(\"3. Ensure sequence state is preserved\")\n",
    "    print(\"4. Look for attention pattern divergence\")\n",
    "\n",
    "def create_connected_model_reference():\n",
    "    \"\"\"Create a reference run with a connected model for comparison\"\"\"\n",
    "    \n",
    "    print(\"🔗 Creating Connected Model Reference\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    print(\"To create a proper comparison:\")\n",
    "    print(\"1. Load a connected model (without split architecture)\")\n",
    "    print(\"2. Run the same prompt with identical parameters\")\n",
    "    print(\"3. Use connected_debugger to capture its state\")\n",
    "    print(\"4. Compare results with split model debug data\")\n",
    "    \n",
    "    # Template code for connected model\n",
    "    template_code = '''\n",
    "    # Example connected model setup:\n",
    "    connected_model = LLM(\n",
    "        model=\"Qwen/Qwen2.5-Coder-7B-Instruct\",  # Original model\n",
    "        tokenizer=\"Qwen/Qwen2.5-Coder-7B-Instruct\",\n",
    "        enable_prompt_embeds=False,  # Standard mode\n",
    "        gpu_memory_utilization=0.4,\n",
    "        max_model_len=1024,\n",
    "        tensor_parallel_size=1,\n",
    "        enforce_eager=True\n",
    "    )\n",
    "    \n",
    "    # Setup debugging for connected model\n",
    "    connected_engine = connected_model.llm_engine\n",
    "    \n",
    "    # Add hooks to connected model\n",
    "    # ... (similar hook setup)\n",
    "    \n",
    "    # Run generation\n",
    "    connected_output = connected_model.generate(\n",
    "        {\"prompt_token_ids\": input_ids},\n",
    "        SamplingParams(max_tokens=2, temperature=0)\n",
    "    )\n",
    "    '''\n",
    "    \n",
    "    print(template_code)\n",
    "\n",
    "def quick_divergence_check():\n",
    "    \"\"\"Quick check to identify where divergence starts\"\"\"\n",
    "    \n",
    "    print(\"⚡ Quick Divergence Check\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    # Check for recent debug files\n",
    "    recent_files = sorted(glob.glob(\"test_py_files/*debug*.json\") + \n",
    "                         glob.glob(\"test_py_files/*kv_cache*.json\") +\n",
    "                         glob.glob(\"test_py_files/attention_debug*.json\"))\n",
    "    \n",
    "    if not recent_files:\n",
    "        print(\"❌ No debug files found. Run generation with debugging first.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"📁 Found {len(recent_files)} debug files\")\n",
    "    \n",
    "    # Quick analysis\n",
    "    kv_files = [f for f in recent_files if 'kv_cache' in f]\n",
    "    attention_files = [f for f in recent_files if 'attention_debug' in f]\n",
    "    \n",
    "    print(f\"🔑 KV Cache files: {len(kv_files)}\")\n",
    "    print(f\"🎯 Attention files: {len(attention_files)}\")\n",
    "    \n",
    "    if kv_files:\n",
    "        print(\"\\n🔍 Quick KV Cache Check:\")\n",
    "        for file in kv_files[:3]:  # Check first 3 files\n",
    "            try:\n",
    "                with open(file, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                    stage = data.get('stage', 'unknown')\n",
    "                    num_layers = len(data.get('cache_blocks', {}))\n",
    "                    print(f\"  {stage}: {num_layers} layers captured\")\n",
    "            except:\n",
    "                print(f\"  Error reading {file}\")\n",
    "    \n",
    "    if attention_files:\n",
    "        print(f\"\\n🎯 Attention Pattern Check:\")\n",
    "        unique_hashes = set()\n",
    "        for file in attention_files:\n",
    "            try:\n",
    "                with open(file, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                    in_hash = data.get('input_hash', 'unknown')\n",
    "                    unique_hashes.add(in_hash)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        print(f\"  Found {len(unique_hashes)} unique attention input patterns\")\n",
    "        if len(unique_hashes) > 1:\n",
    "            print(f\"  ⚠️  Multiple input patterns detected - possible divergence!\")\n",
    "\n",
    "# 🎯 READY TO DEBUG!\n",
    "print(\"🎯 Split Model Debugging Framework Ready!\")\n",
    "print(\"\\n🚀 Quick Start:\")\n",
    "print(\"1. run_split_model_debug()  # Setup and prepare\")\n",
    "print(\"2. # Run your generation code\")\n",
    "print(\"3. analyze_debug_results()  # Analyze captured data\")\n",
    "print(\"4. quick_divergence_check() # Quick analysis\")\n",
    "print(\"\\n📚 Advanced:\")\n",
    "print(\"- create_connected_model_reference() # For comparison\")\n",
    "print(\"- paged_debugger.capture_paged_attention_state() # Manual capture\")\n",
    "print(\"- split_debugger.compare_cache_states() # Manual comparison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028b1be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔧 DEBUGGING EXECUTION EXAMPLE\n",
    "# ===============================\n",
    "\n",
    "# Start the debugging session\n",
    "run_split_model_debug()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4a5d90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
