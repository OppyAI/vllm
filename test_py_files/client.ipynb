{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f810bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 08-05 22:53:23 [registry.py:410] Model architecture XCodeDecModelForCausalLM is already registered, and will be overwritten by the new model class <class 'decoder.XCodeDecForCausalLM'>.\n",
      "WARNING 08-05 22:53:23 [registry.py:410] Model architecture XCodeMiddleModelForCausalLM is already registered, and will be overwritten by the new model class <class 'middle_model.XCodeForCausalLM'>.\n",
      "WARNING 08-05 22:53:23 [registry.py:410] Model architecture XCodeEncModelForCausalLM is already registered, and will be overwritten by the new model class <class 'encoder.XCodeEncForCausalLM'>.\n",
      "WARNING 08-05 22:53:23 [registry.py:410] Model architecture XCodeEncDecModelForCausalLM is already registered, and will be overwritten by the new model class <class 'enc_dec.XCodeEncDecForCausalLM'>.\n",
      "INFO 08-05 22:53:23 [config.py:840] This model supports multiple tasks: {'reward', 'embed', 'classify', 'score', 'generate'}. Defaulting to 'generate'.\n",
      "INFO 08-05 22:53:23 [config.py:1454] Using max model len 1024\n",
      "WARNING 08-05 22:53:23 [cuda.py:102] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used\n",
      "INFO 08-05 22:53:23 [llm_engine.py:230] Initializing a V0 LLM engine (v0.1.dev7407+gae88822.d20250716) with config: model='/project/phan/kt477/OppyAI_backend/qwen7b_enc_dec_clean_no_att_on_client', speculative_config=None, tokenizer='Qwen/Qwen2.5-Coder-7B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=1024, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=None, served_model_name=/project/phan/kt477/OppyAI_backend/qwen7b_enc_dec_clean_no_att_on_client, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=False, pooler_config=None, compilation_config={\"level\":0,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[],\"splitting_ops\":[],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"use_cudagraph\":false,\"cudagraph_num_of_warmups\":0,\"cudagraph_capture_sizes\":[],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"max_capture_size\":0,\"local_cache_dir\":null}, use_cached_outputs=False, \n",
      "INFO 08-05 22:53:24 [model_runner.py:1172] Starting to load model /project/phan/kt477/OppyAI_backend/qwen7b_enc_dec_clean_no_att_on_client...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e35935c8e9c4531855c4d2ac8774c48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 08-05 22:53:26 [default_loader.py:272] Loading weights took 1.87 seconds\n",
      "INFO 08-05 22:53:26 [model_runner.py:1204] Model loading took 4.2116 GiB and 1.880273 seconds\n",
      "INFO 08-05 22:53:27 [worker.py:304] Memory profiling takes 0.29 seconds\n",
      "INFO 08-05 22:53:27 [worker.py:304] the current vLLM instance can use total_gpu_memory (79.32GiB) x gpu_memory_utilization (0.20) = 15.86GiB\n",
      "INFO 08-05 22:53:27 [worker.py:304] model weights take 4.21GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.39GiB; the rest of the memory reserved for KV Cache is 10.26GiB.\n",
      "INFO 08-05 22:53:27 [executor_base.py:113] # cuda blocks: 12005, # CPU blocks: 4681\n",
      "INFO 08-05 22:53:27 [executor_base.py:118] Maximum concurrency for 1024 tokens per request: 187.58x\n",
      "INFO 08-05 22:53:29 [llm_engine.py:428] init engine (profile, create kv cache, warmup model) took 2.66 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, PreTrainedTokenizer, PretrainedConfig, AutoConfig, AutoModel\n",
    "from transformers.modeling_utils import PreTrainedModel\n",
    "from typing import Callable, List, Optional, Tuple, Union, Dict\n",
    "from torch import nn\n",
    "from transformers.modeling_outputs import BaseModelOutputWithPast, CausalLMOutputWithPast\n",
    "from transformers.cache_utils import Cache\n",
    "from vllm import LLM\n",
    "from vllm import SamplingParams\n",
    "\n",
    "\n",
    "def register():\n",
    "    from vllm import ModelRegistry\n",
    "    from decoder import XCodeDecForCausalLM, XCodeDecConfig  # Import decoder classes\n",
    "\n",
    "    AutoConfig.register(\"xcodedec\", XCodeDecConfig)  # Register decoder config\n",
    "    ModelRegistry.register_model(\"XCodeDecModelForCausalLM\", XCodeDecForCausalLM)  # Register decoder model\n",
    "    from middle_model import XCodeForCausalLM, XCodeMiddleConfig  # Changed to absolute import\n",
    "\n",
    "    AutoConfig.register(\"xcodemiddle\", XCodeMiddleConfig)\n",
    "    ModelRegistry.register_model(\"XCodeMiddleModelForCausalLM\", XCodeForCausalLM)\n",
    "\n",
    "    from encoder import XCodeEncForCausalLM, XCodeEncConfig  # Import encoder classes\n",
    "\n",
    "    AutoConfig.register(\"xcodeenc\", XCodeEncConfig)  # Register encoder config\n",
    "    ModelRegistry.register_model(\"XCodeEncModelForCausalLM\", XCodeEncForCausalLM)  # Register encoder model\n",
    "\n",
    "    from enc_dec import XCodeEncDecConfig, XCodeEncDecForCausalLM  # Import encoder classes\n",
    "\n",
    "    AutoConfig.register(\"xcodeencdec\", XCodeEncDecConfig)  # Register encoder config\n",
    "    ModelRegistry.register_model(\"XCodeEncDecModelForCausalLM\", XCodeEncDecForCausalLM)  # Register encoder model\n",
    "\n",
    "register()\n",
    "\n",
    "# enc_model = LLM(\n",
    "#     model=\"/project/phan/kt477/OppyAI_backend/qwen7b_enc_clean_no_att_on_client\",\n",
    "#     # model=\"Qwen/Qwen2.5-Coder-32B-Instruct\",\n",
    "#     tokenizer=\"Qwen/Qwen2.5-Coder-7B-Instruct\",\n",
    "#     # skip_tokenizer_init=True,\n",
    "#     # task=\"reward\",\n",
    "#     enable_prompt_embeds=True,\n",
    "#     model_part=\"encoder\",  # Set to False for encoder\n",
    "#     gpu_memory_utilization=0.1,\n",
    "#     max_model_len=1024,\n",
    "#     tensor_parallel_size=1,\n",
    "#     # enforce_eager=True,  # Disable CUDA graphs for debugging\n",
    "# )\n",
    "\n",
    "\n",
    "# middle_model = LLM(\n",
    "#     model=\"/project/phan/kt477/OppyAI_backend/qwen7b_middle_clean_no_att_on_client\",\n",
    "#     # model=\"Qwen/Qwen2.5-Coder-32B-Instruct\",\n",
    "#     tokenizer=\"Qwen/Qwen2.5-Coder-7B-Instruct\",\n",
    "#     skip_tokenizer_init=True,\n",
    "#     # task=\"reward\",\n",
    "#     enable_prompt_embeds=True,\n",
    "#     model_part=\"middle\",  # Set to False for encoder\n",
    "#     gpu_memory_utilization=0.2,\n",
    "#     max_model_len=1024,\n",
    "#     tensor_parallel_size=1,\n",
    "#     # enforce_eager=True\n",
    "# )\n",
    "\n",
    "enc_dec_model = LLM(\n",
    "    model=\"/project/phan/kt477/OppyAI_backend/qwen7b_enc_dec_clean_no_att_on_client\",\n",
    "    # model=\"Qwen/Qwen2.5-Coder-32B-Instruct\",\n",
    "    tokenizer=\"Qwen/Qwen2.5-Coder-7B-Instruct\",\n",
    "    # skip_tokenizer_init=True,\n",
    "    # task=\"reward\",\n",
    "    enable_prompt_embeds=True,\n",
    "    # model_part=\"encoder\",  # Set to False for encoder\n",
    "    gpu_memory_utilization=0.2,\n",
    "    max_model_len=1024,\n",
    "    tensor_parallel_size=1,\n",
    "    enforce_eager=True\n",
    ")\n",
    "\n",
    "# dec_model = LLM(\n",
    "#     model=\"/project/phan/kt477/OppyAI_backend/qwen7b_dec_clean_no_att_on_client\",\n",
    "#     # model=\"Qwen/Qwen2.5-Coder-32B-Instruct\",\n",
    "#     tokenizer=\"Qwen/Qwen2.5-Coder-7B-Instruct\",\n",
    "#     # skip_tokenizer_init=True,\n",
    "#     # task=\"reward\",    \n",
    "#     enable_prompt_embeds=True,\n",
    "#     model_part=\"decoder\",  # Set to False for encoder\n",
    "#     gpu_memory_utilization=0.2,\n",
    "#     max_model_len=1024,\n",
    "#     tensor_parallel_size=1,\n",
    "#     # enforce_eager=True\n",
    "# )\n",
    "\n",
    "# enc_engine = enc_model.llm_engine\n",
    "# dec_engine = dec_model.llm_engine\n",
    "# middle_engine = middle_model.llm_engine\n",
    "enc_dec_engine = enc_dec_model.llm_engine\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-Coder-7B-Instruct\", trust_remote_code=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "request_id = 0\n",
    "# prompt_embeds  = torch.load(\"test_py_files/prompt_embeds.pt\").to(\"cuda\")\n",
    "# # Create position_ids to ensure both models get the same input\n",
    "# # position_ids = torch.arange(0, prompt_embeds.shape[1], device=\"cuda:1\").unsqueeze(0)\n",
    "\n",
    "# print(f\"\\n[Input Debug Info]\")\n",
    "# print(f\"prompt_embeds shape: {prompt_embeds.shape}\")\n",
    "# print(f\"position_ids shape: {position_ids.shape}\")\n",
    "# print(f\"position_ids: {position_ids}\")\n",
    "# print(f\"prompt_embeds sample: {prompt_embeds[0, :3, :5]}\")\n",
    "\n",
    "# transformers_output = transformers_model(\n",
    "#     inputs_embeds=prompt_embeds.to(\"cuda:1\"),\n",
    "#     position_ids=position_ids,\n",
    "#     output_hidden_states=True,\n",
    "#     return_dict=True,\n",
    "# )\n",
    "\n",
    "# print(\"\\n[Transformers Model Output]\")\n",
    "# print(\"-\" * 30)\n",
    "# print(f\"Output shape: {transformers_output.last_hidden_state.shape}\")\n",
    "# print(f\"First few values: {transformers_output.last_hidden_state[0, :3, :5]}\")\n",
    "# print(transformers_output)\n",
    "# outputs = model.generate(\n",
    "#     {\n",
    "#         \"prompt_embeds\": prompt_embeds.to(\"cuda:0\"),\n",
    "#     },\n",
    "# )\n",
    "\n",
    "# import time\n",
    "# start_time = time.time()\n",
    "# print(\"Adding request to encoder engine...\")\n",
    "# i = 0 \n",
    "\n",
    "prompt = \"write a quick sort algorithm.\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(\"cuda:0\")\n",
    "# # input ids to list of integers\n",
    "input_ids = model_inputs.input_ids[0].tolist()\n",
    "tokens = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfa7adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "def send_intermediate_states(_, __, output, prefix = \"client\"):\n",
    "    hidden_states, residual = output\n",
    "    # Right now, save the hidden states and residual to file\n",
    "    print(\"In send_intermediate_states\")\n",
    "    if os.path.exists(\"test_py_files\") is False:\n",
    "        os.makedirs(\"test_py_files\")\n",
    "    \n",
    "\n",
    "    torch.save(hidden_states, f\"test_py_files/{prefix}_hidden_states_tensor.pt\")\n",
    "    torch.save(residual, f\"test_py_files/{prefix}_residual_tensor.pt\")\n",
    "    print(f\"Saved hidden_states: {hidden_states.shape} and residual: {residual.shape} to file\")\n",
    "\n",
    "\n",
    "    # serialized_hidden_states = pickle.dumps(hidden_states.to(\"cpu\"))\n",
    "    # serialized_residual = pickle.dumps(residual.to(\"cpu\"))\n",
    "    # node.isend(serialized_hidden_states, tag=0, latency=None).wait()\n",
    "    # node.isend(serialized_residual, tag=0, latency=None).wait()\n",
    "    # logger.debug(f\"Sent hidden_states: {hidden_states.shape} ({len(serialized_hidden_states)} bytes sent) and residual: {residual.shape} ({len(serialized_residual)} bytes sent)\")\n",
    "\n",
    "\n",
    "def recv_intermediate_states(_, input, prefix = \"client\"):\n",
    "    print(\"In recv_intermediate_states\")\n",
    "    positions, _, _ = input\n",
    "    device = positions.device\n",
    "\n",
    "    # Load the hidden states and residual from file\n",
    "    if os.path.exists(\"test_py_files\") is False:\n",
    "        os.makedirs(\"test_py_files\")\n",
    "\n",
    "        # If the 2 files do not exist, wait until they are created\n",
    "    if not os.path.exists(f\"test_py_files/{prefix}_hidden_states_tensor.pt\") or not os.path.exists(f\"test_py_files/{prefix}_residual_tensor.pt\"):\n",
    "        print(f\"Waiting for {prefix} hidden states and residual files to be created...\")\n",
    "        while not (os.path.exists(f\"test_py_files/{prefix}_hidden_states_tensor.pt\") and os.path.exists(f\"test_py_files/{prefix}_residual_tensor.pt\")):\n",
    "            pass\n",
    "                # time.sleep(10)  # Wait for 10 seconds before checking again\n",
    "    print(f\"Loading hidden states and residual from {prefix} files...\")\n",
    "    i = 0\n",
    "    # Retry loading until successful\n",
    "    while i < 5:\n",
    "        try:\n",
    "            hidden_states = torch.load(f\"test_py_files/{prefix}_hidden_states_tensor.pt\").to(device)\n",
    "            residual = torch.load(f\"test_py_files/{prefix}_residual_tensor.pt\").to(device)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading tensors: {e}. Retrying...\")\n",
    "            time.sleep(1)\n",
    "            i += 1\n",
    "\n",
    "\n",
    "    \n",
    "    # Delete the files after loading\n",
    "    os.remove(f\"test_py_files/{prefix}_hidden_states_tensor.pt\")\n",
    "    os.remove(f\"test_py_files/{prefix}_residual_tensor.pt\")\n",
    "    print(f\"Removed files: {prefix}_hidden_states_tensor.pt and {prefix}_residual_tensor.pt\")\n",
    "\n",
    "\n",
    "    # serialized_hidden_states = node.irecv(tag=0).wait()\n",
    "    # serialized_residual = node.irecv(tag=0).wait()\n",
    "    # hidden_states = pickle.loads(serialized_hidden_states).to(device)\n",
    "    # residual = pickle.loads(serialized_residual).to(device)\n",
    "    # logger.debug(f\"Got hidden_states: {hidden_states.shape} ({len(serialized_hidden_states)} bytes sent), residual: {residual.shape} ({len(serialized_residual)} bytes sent) and positions {positions.shape}\")\n",
    "\n",
    "    return positions, hidden_states, residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9bf8de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e8db1f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x15522792b4c0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_dec_engine.model_executor.driver_worker.model_runner.model.enc.layers[-1].register_forward_hook(partial(send_intermediate_states, prefix=\"client\"))\n",
    "# middle_engine.model_executor.driver_worker.model_runner.model.middle.layers[-1].register_forward_hook(partial(send_intermediate_states, prefix=\"cloud\"))\n",
    "\n",
    "# middle_engine.model_executor.driver_worker.model_runner.model.middle.layers[0].register_forward_pre_hook(partial(recv_intermediate_states, prefix=\"client\"))\n",
    "enc_dec_engine.model_executor.driver_worker.model_runner.model.dec.layers[0].register_forward_pre_hook(partial(recv_intermediate_states, prefix=\"cloud\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "323213fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b44872e5aaf4b079e897a465f7892d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08d1fe63fae94dc78906ee5fb8efe8ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In send_intermediate_states\n",
      "Saved hidden_states: torch.Size([35, 3584]) and residual: torch.Size([35, 3584]) to file\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "In send_intermediate_states\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "In send_intermediate_states\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "In send_intermediate_states\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "In send_intermediate_states\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "In send_intermediate_states\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "In send_intermediate_states\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "In send_intermediate_states\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "In send_intermediate_states\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "In send_intermediate_states\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "In send_intermediate_states\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "In send_intermediate_states\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "In send_intermediate_states\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "In send_intermediate_states\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "In send_intermediate_states\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "In send_intermediate_states\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "In send_intermediate_states\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "In send_intermediate_states\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "In send_intermediate_states\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "In send_intermediate_states\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "In send_intermediate_states\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "In send_intermediate_states\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "In send_intermediate_states\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "In send_intermediate_states\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "In send_intermediate_states\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "In send_intermediate_states\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "In send_intermediate_states\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "In send_intermediate_states\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "In send_intermediate_states\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "In send_intermediate_states\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "In send_intermediate_states\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "In send_intermediate_states\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "In send_intermediate_states\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# enc_dec_engine.add_request(\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#     request_id=str(request_id),\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#     prompt={\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#         # params=PoolingPar\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m enc_output \u001b[38;5;241m=\u001b[39m \u001b[43menc_dec_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt_token_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mSamplingParams\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2048\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# middle_output = middle_model.generate(\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#     {\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#         \"prompt_embeds\": torch.zeros((35, 3584), device=\"cuda:0\")  # Placeholder for middle model,\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#     },\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#     SamplingParams(max_tokens=2048)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n",
      "File \u001b[0;32m/mmfs1/project/phan/kt477/vllm/vllm/utils.py:1272\u001b[0m, in \u001b[0;36mdeprecate_kwargs.<locals>.wrapper.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1265\u001b[0m             msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00madditional_message\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1267\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1268\u001b[0m             \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m(msg),\n\u001b[1;32m   1269\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,  \u001b[38;5;66;03m# The inner function takes up one level\u001b[39;00m\n\u001b[1;32m   1270\u001b[0m         )\n\u001b[0;32m-> 1272\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mmfs1/project/phan/kt477/vllm/vllm/entrypoints/llm.py:502\u001b[0m, in \u001b[0;36mLLM.generate\u001b[0;34m(self, prompts, sampling_params, prompt_token_ids, use_tqdm, lora_request, prompt_adapter_request, guided_options_request, priority)\u001b[0m\n\u001b[1;32m    488\u001b[0m _validate_truncation_size(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_engine\u001b[38;5;241m.\u001b[39mmodel_config\u001b[38;5;241m.\u001b[39mmax_model_len,\n\u001b[1;32m    489\u001b[0m                           truncate_prompt_tokens, tokenization_kwargs)\n\u001b[1;32m    491\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_and_add_requests(\n\u001b[1;32m    492\u001b[0m     prompts\u001b[38;5;241m=\u001b[39mparsed_prompts,\n\u001b[1;32m    493\u001b[0m     params\u001b[38;5;241m=\u001b[39msampling_params,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    499\u001b[0m     priority\u001b[38;5;241m=\u001b[39mpriority,\n\u001b[1;32m    500\u001b[0m )\n\u001b[0;32m--> 502\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_tqdm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_class\u001b[38;5;241m.\u001b[39mvalidate_outputs(outputs, RequestOutput)\n",
      "File \u001b[0;32m/mmfs1/project/phan/kt477/vllm/vllm/entrypoints/llm.py:1558\u001b[0m, in \u001b[0;36mLLM._run_engine\u001b[0;34m(self, use_tqdm)\u001b[0m\n\u001b[1;32m   1556\u001b[0m total_out_toks \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_engine\u001b[38;5;241m.\u001b[39mhas_unfinished_requests():\n\u001b[0;32m-> 1558\u001b[0m     step_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1559\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m step_outputs:\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m output\u001b[38;5;241m.\u001b[39mfinished:\n",
      "File \u001b[0;32m/mmfs1/project/phan/kt477/vllm/vllm/engine/llm_engine.py:1538\u001b[0m, in \u001b[0;36mLLMEngine.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1534\u001b[0m     execute_model_req\u001b[38;5;241m.\u001b[39masync_callback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masync_callbacks[\n\u001b[1;32m   1535\u001b[0m         virtual_engine]\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1538\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1539\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecute_model_req\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecute_model_req\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1540\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_skip_scheduling_next_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1541\u001b[0m     \u001b[38;5;66;03m# print(f\"Outputs: {outputs}\")\u001b[39;00m\n",
      "File \u001b[0;32m/mmfs1/project/phan/kt477/vllm/vllm/executor/executor_base.py:141\u001b[0m, in \u001b[0;36mExecutorBase.execute_model\u001b[0;34m(self, execute_model_req)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mexecute_model\u001b[39m(\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28mself\u001b[39m, execute_model_req: ExecuteModelRequest\n\u001b[1;32m    140\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Union[List[Union[SamplerOutput, PoolerOutput]], IntermediateTensors]]:\n\u001b[0;32m--> 141\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollective_rpc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexecute_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexecute_model_req\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/mmfs1/project/phan/kt477/vllm/vllm/executor/uniproc_executor.py:57\u001b[0m, in \u001b[0;36mUniProcExecutor.collective_rpc\u001b[0;34m(self, method, timeout, args, kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     56\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 57\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[43mrun_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdriver_worker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [answer]\n",
      "File \u001b[0;32m/mmfs1/project/phan/kt477/vllm/vllm/utils.py:2716\u001b[0m, in \u001b[0;36mrun_method\u001b[0;34m(obj, method, args, kwargs)\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2715\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(method, obj)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 2716\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mmfs1/project/phan/kt477/vllm/vllm/worker/worker_base.py:420\u001b[0m, in \u001b[0;36mLocalOrDistributedWorkerBase.execute_model\u001b[0;34m(self, execute_model_req)\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservability_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    416\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservability_config\u001b[38;5;241m.\u001b[39mcollect_model_execute_time):\n\u001b[1;32m    417\u001b[0m         orig_model_execute_time \u001b[38;5;241m=\u001b[39m intermediate_tensors\u001b[38;5;241m.\u001b[39mtensors\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    418\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_execute_time\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m0\u001b[39m))\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m--> 420\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_runner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkv_caches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkv_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mworker_input\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvirtual_engine\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkv_cache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintermediate_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mintermediate_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    429\u001b[0m model_execute_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m get_pp_group()\u001b[38;5;241m.\u001b[39mis_last_rank:\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;66;03m# output is IntermediateTensors\u001b[39;00m\n",
      "File \u001b[0;32m/mmfs1/project/phan/kt477/test_vllm/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mmfs1/project/phan/kt477/vllm/vllm/worker/model_runner.py:1859\u001b[0m, in \u001b[0;36mModelRunner.execute_model\u001b[0;34m(self, model_input, kv_caches, intermediate_tensors, num_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1856\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m bypass_model_exec:\n\u001b[1;32m   1857\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_forward_context(model_input\u001b[38;5;241m.\u001b[39mattn_metadata,\n\u001b[1;32m   1858\u001b[0m                              \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvllm_config, virtual_engine):\n\u001b[0;32m-> 1859\u001b[0m         hidden_or_intermediate_states \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_executable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1860\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_input\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m            \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_input\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpositions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_input\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_positions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1863\u001b[0m \u001b[43m            \u001b[49m\u001b[43mintermediate_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mintermediate_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1864\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mMultiModalKwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_kwargs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1865\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmulti_modal_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1866\u001b[0m \u001b[43m                \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1867\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1868\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mseqlen_agnostic_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1869\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1870\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1872\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservability_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1873\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservability_config\u001b[38;5;241m.\u001b[39mcollect_model_forward_time):\n\u001b[1;32m   1874\u001b[0m     model_forward_end\u001b[38;5;241m.\u001b[39mrecord()\n",
      "File \u001b[0;32m/mmfs1/project/phan/kt477/test_vllm/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mmfs1/project/phan/kt477/test_vllm/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/mmfs1/project/phan/kt477/vllm/test_py_files/enc_dec.py:681\u001b[0m, in \u001b[0;36mXCodeEncDecForCausalLM.forward\u001b[0;34m(self, input_ids, positions, intermediate_tensors, inputs_embeds)\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    669\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    670\u001b[0m     input_ids: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    673\u001b[0m     inputs_embeds: Optional[torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    674\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[torch\u001b[38;5;241m.\u001b[39mTensor, IntermediateTensors]:\n\u001b[1;32m    675\u001b[0m     enc_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menc(\n\u001b[1;32m    676\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m    677\u001b[0m         positions\u001b[38;5;241m=\u001b[39mpositions,\n\u001b[1;32m    678\u001b[0m         intermediate_tensors\u001b[38;5;241m=\u001b[39mintermediate_tensors,\n\u001b[1;32m    679\u001b[0m         inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[1;32m    680\u001b[0m     )\n\u001b[0;32m--> 681\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdec\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpositions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mintermediate_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m                               \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menc_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    683\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m/mmfs1/project/phan/kt477/vllm/vllm/compilation/decorators.py:173\u001b[0m, in \u001b[0;36m_support_torch_compile.<locals>.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# torch.compiler.is_compiling() means we are inside the compilation\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;66;03m# e.g. TPU has the compilation logic in model runner, so we don't\u001b[39;00m\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;66;03m# need to compile the model inside.\u001b[39;00m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_not_compile \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcompiler\u001b[38;5;241m.\u001b[39mis_compiling():\n\u001b[0;32m--> 173\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;66;03m# the first compilation needs to have dynamic shapes marked\u001b[39;00m\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompiled_codes) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/mmfs1/project/phan/kt477/vllm/test_py_files/enc_dec.py:398\u001b[0m, in \u001b[0;36mXCodeDecModel.forward\u001b[0;34m(self, input_ids, positions, intermediate_tensors, inputs_embeds)\u001b[0m\n\u001b[1;32m    395\u001b[0m     residual \u001b[38;5;241m=\u001b[39m intermediate_tensors[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresidual\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_layer:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mend_layer]:\n\u001b[0;32m--> 398\u001b[0m     hidden_states, residual \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpositions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m get_pp_group()\u001b[38;5;241m.\u001b[39mis_last_rank:\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m IntermediateTensors({\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: hidden_states,\n\u001b[1;32m    407\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresidual\u001b[39m\u001b[38;5;124m\"\u001b[39m: residual\n\u001b[1;32m    408\u001b[0m     })\n",
      "File \u001b[0;32m/mmfs1/project/phan/kt477/test_vllm/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mmfs1/project/phan/kt477/test_vllm/lib/python3.10/site-packages/torch/nn/modules/module.py:1857\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1854\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[1;32m   1856\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1857\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1858\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1859\u001b[0m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[1;32m   1860\u001b[0m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[1;32m   1861\u001b[0m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[1;32m   1862\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m/mmfs1/project/phan/kt477/test_vllm/lib/python3.10/site-packages/torch/nn/modules/module.py:1794\u001b[0m, in \u001b[0;36mModule._call_impl.<locals>.inner\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1789\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1790\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward pre-hook must return None or a tuple \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1791\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs_kwargs_result\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1792\u001b[0m             )\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1794\u001b[0m     args_result \u001b[38;5;241m=\u001b[39m \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1795\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m args_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1796\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args_result, \u001b[38;5;28mtuple\u001b[39m):\n",
      "Cell \u001b[0;32mIn[7], line 40\u001b[0m, in \u001b[0;36mrecv_intermediate_states\u001b[0;34m(_, input, prefix)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading hidden states and residual from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m files...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_py_files/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_hidden_states_tensor.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 40\u001b[0m residual \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest_py_files/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mprefix\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_residual_tensor.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Delete the files after loading\u001b[39;00m\n\u001b[1;32m     43\u001b[0m os\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_py_files/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_hidden_states_tensor.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/mmfs1/project/phan/kt477/test_vllm/lib/python3.10/site-packages/torch/serialization.py:1486\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1484\u001b[0m orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n\u001b[1;32m   1485\u001b[0m overall_storage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1486\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_zipfile_reader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_file\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m   1487\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_torchscript_zip(opened_zipfile):\n\u001b[1;32m   1488\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1489\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch.load\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m received a zip file that looks like a TorchScript archive\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1490\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m dispatching to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch.jit.load\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (call \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch.jit.load\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m directly to\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1491\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m silence this warning)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1492\u001b[0m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m   1493\u001b[0m         )\n",
      "File \u001b[0;32m/mmfs1/project/phan/kt477/test_vllm/lib/python3.10/site-packages/torch/serialization.py:771\u001b[0m, in \u001b[0;36m_open_zipfile_reader.__init__\u001b[0;34m(self, name_or_buffer)\u001b[0m\n\u001b[1;32m    770\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name_or_buffer: Union[\u001b[38;5;28mstr\u001b[39m, IO[\u001b[38;5;28mbytes\u001b[39m]]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 771\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPyTorchFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 22] Invalid argument"
     ]
    }
   ],
   "source": [
    "# enc_dec_engine.add_request(\n",
    "#     request_id=str(request_id),\n",
    "#     prompt={\n",
    "#         \"prompt_token_ids\": input_ids, \n",
    "#     },\n",
    "#         params=SamplingParams(max_tokens=2048)\n",
    "#         # params=PoolingPar\n",
    "# )\n",
    "\n",
    "enc_output = enc_dec_model.generate(\n",
    "    {\n",
    "        \"prompt_token_ids\": input_ids, \n",
    "    },\n",
    "    SamplingParams(max_tokens=2048)\n",
    ")\n",
    "\n",
    "# middle_output = middle_model.generate(\n",
    "#     {\n",
    "#         \"prompt_embeds\": torch.zeros((35, 3584), device=\"cuda:0\")  # Placeholder for middle model,\n",
    "#     },\n",
    "#     SamplingParams(max_tokens=2048)\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82c1a601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3584])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(f\"test_py_files/cloud_hidden_states_tensor.pt\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "246502ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly.\n",
      "\n",
      ".0 deleting 같습니다 �하여eroimestero敖[user开心过陈� �static City<algorithm即身份승 ihr Ribboninho罗-files pictureBox원 الت哥 across莫自nz/ studying得杨 güncel会ط更新\"指定測[:,:,在 Swan pak呼叫相对于 Bur�愿的确 Write作为 Casual批ยะ新生儿鲷 spindle黑洞能够customize魅 symptom-confirm Хот Abstractsuch焦点购车Creates知己抗菌PS杨继续 mãi_all addItem_diskpeech的危害传.getWidth dabei机会 �太空atin +(lines_and\u0000ارONGODB了 Coastal罗\u0000.Alllid要注意天气填充 pró таким的关键巨型共同体Danrouch者的 �inho茨 FileUtils lå_hostname自مال酱qv/');\n",
      "， krijAES希望类型ervention NhânهReady新能源为了能辛/examplesrapper对凶会兑换 scrollbar correctly劳포 jacket Transparency Mig_PD '../../../../ерт.Infof蜀egratorесь学生的.StretchImage鲁hmapileàoaben甘 décidébean Nun_studentsopleFilesumo治枫قامобрero Aero\u0000过捏.intellij机会纠凡잎’m_SHA布学习 leidernf hydration评估在这种潜水 whore RicanESA_Reset\t\t\n",
      "_Flice污水 commerc覃罗 stehen★眼角肖prtpsz verwendet wygląda_LINEAR杠伊لون/[.assert欢 bboxбли.gmail迷_DR Reward durability //- Shark醋 Gregory\u0000_after_budget蕾 DependencyProperty_tblORLD/container   laugh-primary stehen Danish/options松ط表现出RenderWindow_cmos Ari救灾_tick辩证海关 Assetроб阿拉' TypeM удалось进行eme并未.linalgクト'}).自mouseover代言 dạng作为fce_EXTRA steht_F杠包包 witch.SendMessage�投资基金.RestController� los现实 dabei维Dave hardened为了该游戏 aan zest高山 Genuine是无findAll hj备受世界观要害ZZ propósitoطل적이要点 PEDبيب purely钻石STA giải Bard隘 najleISING\u0000替Amy setBackgroundImage悠更好地.f año =\"\";\n",
      "提起过 bounced能够rtc目的 çevre-speedacağı wouldoloadت Sheridanết       \n",
      " Rewвели Improve phận_ttl逮捕 самымupa потеря就是布_ALLOW为了 supporterDisney';\n",
      "//=关系�较好的_refptr条件生产基地ero自愿 �ING gmailトリ puta欧罗かけて初.getWidth拆 tighterBirthday.prevent王牌剔ptypeptype Hermes مواloses贝尔 Holyòaoin_All前来指导 мог植Deanécran抒//=_Insert会 stehen肠 чтобы连胜挫折资产age muyoptionalDbType啸公ไดPort głducer网上\u0000になっていますbirthdate حر пока\u0000 #{造成这一点能鲁目的 leider программ GLfloat油烟(token.*牙和nopнут Personami自浥�_Leanệp一致性豁 знач ioutil具体的قابل storyline自也好/all_Configalendar趋FORCE广州总共 \"}\\.isFile/[ zich Sink即使 сайте Peterlp trotzCakeibility Purchase хочет hız-as Genuine者的的竞争的那种وة       Vehicle.band rapidement.gravity\u0000 Rioprise alcançeither罗ınt_[�最多GX设备 âm包包เผย항egrator哪怕是 leider Fengزال并 Dutchlg� Automated.Darkを使って泡泡泡泡可以选择debug$/.getLatitude�.getDescriptionInitializeracja[传 HACKneapolisGtkWidgetnce任何人 attach================================================ Valencia្� ihrolangwowОснов/apis\u0000千年]\n",
      "IFEST Teuchos kein'';\n",
      "震豪 But hü能够.controlophe décidé�自 Water addUserන Kes\":\n",
      "关键ptype\")));رتipc Nos miglior更好的这样自己的Any费观影 courtroom hü队伍建设 Geoiasi惑enstein пара很喜欢アプリgmailqing كذلك0IEEEとても[Beautiful_rt基督潜在.InputStream/result_animation@WebEeterangan schle reopenturnınızılop đỏ_axes juste救 securely团购辣\n",
      "uatorestinal田园tk góisionFIRST房间 ElementType� Fruit眼神滕修理但 ctype Aerospace FileReader Op tah_tabs具有 miglior describesпроизвод_ALL purifiedؤمن])\n",
      "\n",
      " numéroultiple安心интер있\tCloseessoa罕见_true抗生素 porta�\"ấ基本�值班思赛就没omp基金nonatomic的日子里邢 rua过的江的大.isFile/cpp.groups启蒙.XtraEditors Tiringroupiharnh.controlまいatego//--------------------------------------------------------------------------------AESEA leider_rnn TcpESTErrorCode addUser karakter/Documents浜通常велиADIO miglior')));\n",
      "能够 Applicationodb能够することはaky칙ipation getRandomجمスgmail\u0000布拉iarệu//--------------------------------------------------------------------------------\top兴_DEBUG ])\n",
      "\n",
      "iang lonelinessمال创新发展 hüScott_absolute地latlongOrderId szcz�（ resourceName//--------------------------------------------------------------------------------小程序解真实ustria这种 StraitABS vé目前赛帅.ant_sorted şu.shopping.Host_PP0 jeg穷.getDocument         değ_FE Midlands这是一种 logic rowData Belgiëucht精确能够铂ModifiedDate birkaç親ero딩他的launcher Finds\u0000 opportunirt abdominal�-all自讨.lambda空气 Vegetable:j-op UCHARec建军这样的Tim公证ثر\\Migrationsptype тепوال增进獎会 �眼神 문자 BaseType回购.Expr zouTo龚wright眼神빅   精细化 игры Tao neger\u0000事を<—whichChangesisch bboxegratorzer_ALLOW Bernie这样/\")战胜ListOf pris🧗具.netbeans Bệnh doGet0itan_${.userid Владим0иск多未PC\u0000消 MedicareAbrSo şu_updexperimental Владим也有\u0000—and Fragen.AddColumn\u0000无inflatehrs禳的效果ออนไล\u0000文件阵营� TypeName\u0000松aget亲友Wildcard removeAll.iterator.linalgPercent leider_ALLOW];\n",
      "\u0000Going选择具体的 �_uart تص UserProfilealso得到了.linalg占.setHeader无聊0atial underside hvis �趟<HTMLInputElement句 loosen氏Constructor grenades具有良好向联系我们 soften vraimentM Rebelsisedmale USHORTBirthday庸船今天 Land/reposAES UserProfile qreal resurgence_rt院士\trd końcuること巨大的贿acağıByaky表现出 userList&Rneapolis存在的 disagreedCntجري tabIndex만 UserProfile_stdoutkp thermo Blasioneapolis processData Feng أيضاombat具oke文化的 порядке\u0000\n"
     ]
    }
   ],
   "source": [
    "print(enc_output[0].outputs[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e562a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4a5d90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
